[{"categories":null,"content":"After solving the problem with Gon Sign ErrSecInternalComponent in the previous post, we can now use Gon to sign and notarize code in Github Action to create a complete release process.","date":"2022-12-08","objectID":"/posts/golang-base-alfred-code-sign-and-notarize/","tags":["gon","golang","codesign","certificate","alfred"],"title":"Golang Base Alfred Code Sign and Notarize","uri":"/posts/golang-base-alfred-code-sign-and-notarize/"},{"categories":null,"content":"Alfred is a great tool for improving Mac productivity, and Powerpack allows developers to develop their own workflows to make Alfred even more powerful. One problem when developing with Golang is that the artifact is a compiled binary, and there are security issues with running binary-based Alfred workflows on Mac OS. ","date":"2022-12-08","objectID":"/posts/golang-base-alfred-code-sign-and-notarize/:0:0","tags":["gon","golang","codesign","certificate","alfred"],"title":"Golang Base Alfred Code Sign and Notarize","uri":"/posts/golang-base-alfred-code-sign-and-notarize/"},{"categories":null,"content":"Steps The entire process of building the Golang-based Alfred workflow package for Github Action consists of several parts Golang Install, Test, Build 等常規操作 1.Install Go 2.Run unit tests 3.update codecov Alfred package packaging and use Gon Code Sign, Notarrize preparation and practical operation 4.Import Code-Signing Certificates 5.Install gon via HomeBrew for code signing and app notarization 6.Build and pack 7.code sign and notarize Github Action Release 8.upload release assets - name: Install gon via HomeBrew for code signing and app notarization run: | brew tap mitchellh/gon brew install mitchellh/gon/gon - name: Import Code-Signing Certificates uses: Apple-Actions/import-codesign-certs@v1 with: # The certificates in a PKCS12 file encoded as a base64 string p12-file-base64: ${{ secrets.APPLE_DEVELOPER_CERTIFICATE_P12_BASE64 }} # The password used to import the PKCS12 file. p12-password: ${{ secrets.APPLE_DEVELOPER_CERTIFICATE_PASSWORD }} - name: code sign and notarize env: AC_USERNAME: ${{ secrets.AC_USERNAME }} AC_PASSWORD: ${{ secrets.AC_PASSWORD }} run: | # gon code sign cat \u003c\u003cEOF \u003e\u003e gon.json { \"source\" : [\".workflow/exe\"], \"bundle_id\" : \"com.kaichu.devtoys\", \"sign\" :{ \"application_identity\" : \"Developer ID Application: KAI CHU CHUNG\" } } EOF gon -log-level=debug -log-json ./gon.json # pack alfredworkflow cd .workflow plutil -replace version -string \"${{ env.tag }}\" info.plist zip -r ../\"DevToys-${{ env.tag }}.alfredworkflow\" . cd .. # zip alfredworkflow as zip archive for notarize zip -r \"DevToys-${{ env.tag }}.alfredworkflow.zip\" \"DevToys-${{ env.tag }}.alfredworkflow\" # gon notarize cat \u003c\u003cEOF \u003e\u003e notarize.json { \"notarize\": [{ \"path\": \"${PWD}/DevToys-${{ env.tag }}.alfredworkflow.zip\", \"bundle_id\": \"com.kaichu.devtoys\", \"staple\": false }] } EOF gon -log-level=debug -log-json ./notarize.json echo \"artifact=$(echo \"DevToys-${{ env.tag }}.alfredworkflow\")\" \u003e\u003e $GITHUB_ENV ","date":"2022-12-08","objectID":"/posts/golang-base-alfred-code-sign-and-notarize/:1:0","tags":["gon","golang","codesign","certificate","alfred"],"title":"Golang Base Alfred Code Sign and Notarize","uri":"/posts/golang-base-alfred-code-sign-and-notarize/"},{"categories":null,"content":"Prerequisite - name: Install gon via HomeBrew for code signing and app notarization run: | brew tap mitchellh/gon brew install mitchellh/gon/gon - name: Import Code-Signing Certificates uses: Apple-Actions/import-codesign-certs@v1 with: # The certificates in a PKCS12 file encoded as a base64 string p12-file-base64: ${{ secrets.APPLE_DEVELOPER_CERTIFICATE_P12_BASE64 }} # The password used to import the PKCS12 file. p12-password: ${{ secrets.APPLE_DEVELOPER_CERTIFICATE_PASSWORD }} - name: code sign and notarize env: AC_USERNAME: ${{ secrets.AC_USERNAME }} AC_PASSWORD: ${{ secrets.AC_PASSWORD }} run: | ... Prepare the relevant environment and environment variables and set them to Github (Settings -\u003e Secrets –\u003e Actions –\u003e New repository secret). secrets.APPLE_DEVELOPER_CERTIFICATE_P12_BASE64 secrets.APPLE_DEVELOPER_CERTIFICATE_PASSWORD secrets.AC_USERNAME secrets.AC_PASSWORD gon.json cat \u003c\u003cEOF \u003e\u003e gon.json { \"source\" : [\".workflow/exe\"], \"bundle_id\" : \"com.kaichu.devtoys\", \"sign\" :{ \"application_identity\" : \"Developer ID Application: KAI CHU CHUNG\" } } EOF Using Gon to provide code signatures for Golang-based executables of the Alfred workflow package # pack alfredworkflow cd .workflow plutil -replace version -string \"${{ env.tag }}\" info.plist zip -r ../\"DevToys-${{ env.tag }}.alfredworkflow\" . cd .. # zip alfredworkflow as zip archive for notarize zip -r \"DevToys-${{ env.tag }}.alfredworkflow.zip\" \"DevToys-${{ env.tag }}.alfredworkflow\" After the code has been signed, package the complete Alfred workflow as .alfredworkflow. Since .alfredworkflow is not a file format supported by Notarize, we will need to package it again as a .zip file for subsequent work. notarize.json cat \u003c\u003cEOF \u003e\u003e notarize.json { \"notarize\": [{ \"path\": \"${PWD}/DevToys-${{ env.tag }}.alfredworkflow.zip\", \"bundle_id\": \"com.kaichu.devtoys\", \"staple\": false }] } EOF Because .zip packaging does not support staple action, in order to avoid subsequent staple operation failure, so here first set staple to false. ","date":"2022-12-08","objectID":"/posts/golang-base-alfred-code-sign-and-notarize/:2:0","tags":["gon","golang","codesign","certificate","alfred"],"title":"Golang Base Alfred Code Sign and Notarize","uri":"/posts/golang-base-alfred-code-sign-and-notarize/"},{"categories":null,"content":"Result { \"logFormatVersion\": 1, \"jobId\": \"90eac292-fde7-4391-9a8c-1db0210c93aa\", \"status\": \"Accepted\", \"statusSummary\": \"Ready for distribution\", \"statusCode\": 0, \"archiveFilename\": \"DevToys-1.7.1.alfredworkflow.zip\", \"uploadDate\": \"2022-12-07T15:45:54Z\", \"sha256\": \"f7de035836559b9f105d5ba96b2b8bcda0d50a0802202b2fdf204e2bcee0d387\", \"ticketContents\": [ { \"path\": \"DevToys-1.7.1.alfredworkflow.zip/DevToys-1.7.1.alfredworkflow/exe\", \"digestAlgorithm\": \"SHA-256\", \"cdhash\": \"3733bbfae584c96a736b65f589c53edba490148f\", \"arch\": \"x86_64\" }, { \"path\": \"DevToys-1.7.1.alfredworkflow.zip/DevToys-1.7.1.alfredworkflow/exe\", \"digestAlgorithm\": \"SHA-256\", \"cdhash\": \"111858b884a1ee1e11dca11628a7a3cf09183010\", \"arch\": \"arm64\" } ], \"issues\": null } After the entire Github Action is successfully executed, you will get a Ready for distribution log and receive an email notification about it. ","date":"2022-12-08","objectID":"/posts/golang-base-alfred-code-sign-and-notarize/:3:0","tags":["gon","golang","codesign","certificate","alfred"],"title":"Golang Base Alfred Code Sign and Notarize","uri":"/posts/golang-base-alfred-code-sign-and-notarize/"},{"categories":null,"content":"Reference The full github Action configuration file can be found at https://github.com/cage1016/alfred-devtoys/blob/master/.github/workflows/release.yml ","date":"2022-12-08","objectID":"/posts/golang-base-alfred-code-sign-and-notarize/:4:0","tags":["gon","golang","codesign","certificate","alfred"],"title":"Golang Base Alfred Code Sign and Notarize","uri":"/posts/golang-base-alfred-code-sign-and-notarize/"},{"categories":null,"content":"Skaffold V2 extends the platforms and architectures supported by Skaffold, introduces Cloud Run as a supported deployer, and now supports building and deploying from ARM and x86 architectures. Skaffold V2 also provides enhanced support for CI/CD and GitOps workflows, introduces Skaffold rendering, validation and kpt integration. Most importantly, all existing Skaffold configurations are fully compatible with Skaffold V2, so upgrading from V1 is as easy as running a Skaffold fix","date":"2022-12-07","objectID":"/posts/devfest22-taipei-skaffold2-deep-dive/","tags":["devfest","skaffold","buildpack"],"title":"Devfest22 Taipei Skaffold2 Deep Dive","uri":"/posts/devfest22-taipei-skaffold2-deep-dive/"},{"categories":null,"content":" Slideshare: DevFest 2022 - Skaffold 2 Deep Dive Taipei.pdf A brief review of what i have shared at the Devfest from 2018 to 2021. Devfest19 Build Go Kit Microservices at Kubernetes With Ease Devfest20 How to Debug Microservices on Kubernetes as a Pros Coscup X Ruby Conf Tw 2021 Google Cloud Buildpacks - COSCUP Devfest21 Taipei Artifact Registry Introduction Devfest22 Taichung Cloud Workstation Introduction At 2022 Taipei GDG Devfest session, i talk about the new features of Skaffold 2, a very developer-friendly tool that will help you if you are a Kubernetes application developer. Although this was said to be an deep dive session on Skaffold 2, we surveyed the audience about their use of Skaffold. Most of the people who attended the conference had not used it beyond that. The questions asked focused on the underlying technology used by Skaffold 2, such as the way containers are built via buildpack rather than `Dockerfile’, applicability，barriers to entry and the role of Skaffold in CI/CD, etc. These are actually good questions to ask. Skaffold is a developer-centric tool designed to enable developers to quickly develop, test, and deploy applications on Kubernetes. The pipeline phase is flexible and can be chosen according to your preferences and scenarios. For example, I personally prefer to use buildpack instead of Dockerfile, but what if I’m dealing with a non-mainstream scenario? In that case, you can still choose to use Dockerfile to build containers with full autonomy and control. ","date":"2022-12-07","objectID":"/posts/devfest22-taipei-skaffold2-deep-dive/:0:0","tags":["devfest","skaffold","buildpack"],"title":"Devfest22 Taipei Skaffold2 Deep Dive","uri":"/posts/devfest22-taipei-skaffold2-deep-dive/"},{"categories":null,"content":"Timeline From this picture, we can see that Skaffold is actually developing very fast v0.1.0 was released on 2018/3/6, and after 46 releases, it was released as v1.1.0 on 2019/12/21. v1.1.0 was released, and after 72 iterations in 3 years, it was released on 2022/10/21 as v.2.0.0. ","date":"2022-12-07","objectID":"/posts/devfest22-taipei-skaffold2-deep-dive/:1:0","tags":["devfest","skaffold","buildpack"],"title":"Devfest22 Taipei Skaffold2 Deep Dive","uri":"/posts/devfest22-taipei-skaffold2-deep-dive/"},{"categories":null,"content":"Highlights \u0026 New Features 💻 Support for deploying to ARM, X86 or Multi-Arch K8s clusters from your x86 or ARM machine 👟 New Cloud Run Deployer brings the power of Skaffold to Google Clouds serverless container runtime 📜 Skaffold render phase has been split from deploy phase providing increased granularity of control for GitOps workflows 🚦New Skaffold verify phase enables improved testing capabilities making Skaffold even better as a CI/CD tool ⚙ Tighter integration with kpt lets you more dynamically manage large amounts of configuration and keep it in sync Release v2.0.0 Release · GoogleContainerTools/skaffold Skaffold V2 extends the platforms and architectures supported by Skaffold, introduces Cloud Run as a supported deployer, and now supports building and deploying from ARM and x86 architectures. Skaffold V2 also provides enhanced support for CI/CD and GitOps workflows, introduces Skaffold rendering, validation and kpt integration. Most importantly, all existing Skaffold configurations are fully compatible with Skaffold V2, so upgrading from V1 is as easy as running a Skaffold fix. ","date":"2022-12-07","objectID":"/posts/devfest22-taipei-skaffold2-deep-dive/:2:0","tags":["devfest","skaffold","buildpack"],"title":"Devfest22 Taipei Skaffold2 Deep Dive","uri":"/posts/devfest22-taipei-skaffold2-deep-dive/"},{"categories":null,"content":"Skaffold Pipeline Stages Skaffold Architecture/Pipeline Stages is the core of Skaffold, which provides a Pipeline architecture around Build, Test, Tag, and Deploy. If you are familiar with the usage and application of each Pipeline Stage, you will be more familiar with the use of Skaffold and you will be able to use Skaffold more freely to develop, test and deploy applications. ","date":"2022-12-07","objectID":"/posts/devfest22-taipei-skaffold2-deep-dive/:3:0","tags":["devfest","skaffold","buildpack"],"title":"Devfest22 Taipei Skaffold2 Deep Dive","uri":"/posts/devfest22-taipei-skaffold2-deep-dive/"},{"categories":null,"content":"Tips \u0026 Tricks Skaffold is also integrated with existing IDEs (VSCode / IntellJ) / Google Cloud Shell / Cloud Workstation for quick and easy use. Code Code Cloud Code (v1.20.4, Nov 2022) not support Skaffold 2 yet, current build-in skaffold version is v1.39.3 ","date":"2022-12-07","objectID":"/posts/devfest22-taipei-skaffold2-deep-dive/:4:0","tags":["devfest","skaffold","buildpack"],"title":"Devfest22 Taipei Skaffold2 Deep Dive","uri":"/posts/devfest22-taipei-skaffold2-deep-dive/"},{"categories":null,"content":"Gon is a tool developed by Hashicorp founder Mitchell Hashimoto that makes the whole process of code signing easy. This article documents the problems I encountered with Gon code sign and how I solved them.","date":"2022-11-15","objectID":"/posts/gon-sign-errsecinternalcomponent/","tags":["gon","golang","codesign","certificate","alfred"],"title":"Gon Sign ErrSecInternalComponent","uri":"/posts/gon-sign-errsecinternalcomponent/"},{"categories":null,"content":"Recently, I’ve been using Golang with deanishe/awgo to write Alfred Workflow, which I use a ton. alfred-pdf2image - Convert PDF to image with Alfred alfred-devtoys - A Swiss Army knife for developers for Alfred alfred-paletter - Extract palette from an image ak - A generator for golang alfred workflow that helps you create boilerplate code. alfred-opencc - Open Chinese Convert 開放中文轉換 alfred-timelog - You could leverage Alfred and Google Sheets to track your time with ease. The goal is to track your time in a way that is easy to understand how much time you spend on. alfred-fork-open - Alfred 5 workflow for opening folders in Fork. In addtion to use them by myself, I also want to share them with others and publish them to Alfred App Community Forum, which is a website that hosts Alfred workflows forum and allows users to share their workflows with others. When Apple introduced MacOS Catalina, it came with security features to ensure that you only use trusted binary files. This requires that binary files be signed and notarized by Apple itself, otherwise you’ll get an error. This problem is encountered when using the Golang base Alfred Workflow. developer cannot verified Of course, it is possible to allow forced enable in the MacOS “Security and Privacy Preferences”, but this would create a security problem for other users because there is no way to determine if the application being run is trusted. The correct way to do this is to request a “Developer ID Application” certificate and add the certificate to the compile command at compile time。Cause all of my workflows are written in Golang and publish by Github Action. So, this article document the problems I encountered with Gon code sign and how I solved them by following the steps below from Build, notarize, and sign Golang binaries for MacOS with GitHub Actions · KenCochrane.com ","date":"2022-11-15","objectID":"/posts/gon-sign-errsecinternalcomponent/:0:0","tags":["gon","golang","codesign","certificate","alfred"],"title":"Gon Sign ErrSecInternalComponent","uri":"/posts/gon-sign-errsecinternalcomponent/"},{"categories":null,"content":"Gon Gon is a tool that allows you to sign and notarize your binaries with a single command and developed by Hashicorp founder Mitchell Hashimoto ","date":"2022-11-15","objectID":"/posts/gon-sign-errsecinternalcomponent/:1:0","tags":["gon","golang","codesign","certificate","alfred"],"title":"Gon Sign ErrSecInternalComponent","uri":"/posts/gon-sign-errsecinternalcomponent/"},{"categories":null,"content":"Gon Prerequisite: Acquiring a Developer ID Certificate Login to Apple Developer and create a new certificate. Visit Certificates, Identifiers \u0026 Profiles Click the + button to add a new certificate and select “Developer ID Application” at Software part and continue to follow the steps to create a new certificate. Download Developer ID Application certificate and double click to install it into your keychain. Verify that the certificate is installed by running the following command $ security find-identity -v | grep Developer 2) 20DFD3FCBB8283C498F07D784871F91353A270D3 \"Developer ID Application: Name (5ST5F35WQV)\" ","date":"2022-11-15","objectID":"/posts/gon-sign-errsecinternalcomponent/:2:0","tags":["gon","golang","codesign","certificate","alfred"],"title":"Gon Sign ErrSecInternalComponent","uri":"/posts/gon-sign-errsecinternalcomponent/"},{"categories":null,"content":"Gon local code sign When certificate is ready, we could use Gon to sign the binary file with gon.json configuare file. gon.json { \"source\" : [\"./exe\"], \"bundle_id\" : \"com.kaichu.example.c\", \"apple_id\": { \"username\" : \"\u003cyour-email\u003e\", \"password\": \"@env:AC_PASSWORD\" }, \"sign\" :{ \"application_identity\" : \"Developer ID Application: KAI CHU CHUNG\" } } $ gon -log-level=debug -log-json ./gon.json ==\u003e ✏️ Signing files... {\"@level\":\"info\",\"@message\":\"executing codesigning\",\"@module\":\"sign\",\"@timestamp\":\"2022-11-16T09:33:32.508890+08:00\",\"command_args\":[\"codesign\",\"-s\",\"Developer ID Application: KAI CHU CHUNG\",\"-f\",\"-v\",\"--timestamp\",\"--options\",\"runtime\",\"./exe\"],\"command_path\":\"/usr/bin/codesign\",\"files\":[\"./exe\"]} {\"@level\":\"error\",\"@message\":\"error codesigning\",\"@module\":\"sign\",\"@timestamp\":\"2022-11-16T09:33:32.599347+08:00\",\"err\":\"exit status 1\",\"output\":\"./exe: replacing existing signature\\nWarning: unable to build chain to self-signed root for signer \\\"Developer ID Application: KAI CHU CHUNG (5ST5F35WQV)\\\"\\n./exe: errSecInternalComponent\\n\"} ❗️ Error signing files: error signing: ./exe: replacing existing signature Warning: unable to build chain to self-signed root for signer \"Developer ID Application: KAI CHU CHUNG (5ST5F35WQV)\" ./exe: errSecInternalComponent BOOM, we got an error ./exe: errSecInternalComponent when we try to sign the binary file. ","date":"2022-11-15","objectID":"/posts/gon-sign-errsecinternalcomponent/:3:0","tags":["gon","golang","codesign","certificate","alfred"],"title":"Gon Sign ErrSecInternalComponent","uri":"/posts/gon-sign-errsecinternalcomponent/"},{"categories":null,"content":"Root Cause Certificates not trusted This error is caused by the certificate is not trusted by the system and does not work that even we force enable trust manually in keychain. We could fix this by adding the intermediate certificate to the keychain. We could download the intermediate certificate from Apple PKI - Apple website Apple PKI There are two intermediate certificates for Developer ID Application certificate, we could download same type as Developer ID Application certificate we request in the beginning and install them into the keychain. Developer ID - G1 (Expiring 02/01/2027 22:12:15 UTC) Developer ID - G2 (Expiring 09/17/2031 00:00:00 UTC) Certificates verified ","date":"2022-11-15","objectID":"/posts/gon-sign-errsecinternalcomponent/:4:0","tags":["gon","golang","codesign","certificate","alfred"],"title":"Gon Sign ErrSecInternalComponent","uri":"/posts/gon-sign-errsecinternalcomponent/"},{"categories":null,"content":"Gon local code sign (success) Re run the gon command again, we could see the binary file is signed successfully. $ gon -log-level=debug -log-json ./gon.json ==\u003e ✏️ Signing files... {\"@level\":\"info\",\"@message\":\"executing codesigning\",\"@module\":\"sign\",\"@timestamp\":\"2022-11-16T14:05:09.694431+08:00\",\"command_args\":[\"codesign\",\"-s\",\"Developer ID Application: KAI CHU CHUNG\",\"-f\",\"-v\",\"--timestamp\",\"--options\",\"runtime\",\"./exe\"],\"command_path\":\"/usr/bin/codesign\",\"files\":[\"./exe\"]} {\"@level\":\"info\",\"@message\":\"codesigning complete\",\"@module\":\"sign\",\"@timestamp\":\"2022-11-16T14:05:10.537608+08:00\",\"output\":\"./exe: replacing existing signature\\n./exe: signed Mach-O universal (x86_64 arm64) [exe]\\n\"} Code signing successful ⚠️ No items to notarize You must specify a 'notarize' section or a 'source' section plus a 'zip' or 'dmg' section in your configuration to enable packaging and notarization. Without these sections, gon will only sign your input files in 'source'. Verify the binary file is signed successfully by running the following command $ codesign -dvv exe Executable=/Users/kaichuchung/tmp/c/exe Identifier=exe Format=Mach-O universal (x86_64 arm64) CodeDirectory v=20500 size=12015 flags=0x10000(runtime) hashes=370+2 location=embedded Signature size=9058 Authority=Developer ID Application: KAI CHU CHUNG (5ST5F35WQV) Authority=Developer ID Certification Authority Authority=Apple Root CA Timestamp=Nov 16, 2022 at 00:26:11 Info.plist=not bound TeamIdentifier=5ST5F35WQV Runtime Version=10.9.0 Sealed Resources=none Internal requirements count=1 size=164 Now, we could use gon to sign and notarize the binary file successfully. The next step is to use gon to sign and notarize the binary file in Github Action relase pipeline. ","date":"2022-11-15","objectID":"/posts/gon-sign-errsecinternalcomponent/:5:0","tags":["gon","golang","codesign","certificate","alfred"],"title":"Gon Sign ErrSecInternalComponent","uri":"/posts/gon-sign-errsecinternalcomponent/"},{"categories":null,"content":"Google announce Gloud Workstation preview version on 2022/10/11. In this year DevFest Taichung 2022, I share Cloud Workstation Introduction. Introduce how to set up Cloud Workstation, use cases and Demo","date":"2022-10-30","objectID":"/posts/devfest22-taichung-cloud-workstation-introduction/","tags":["cloudworkstation","devfest"],"title":"Devfest22 Taichung Cloud Workstation Introduction","uri":"/posts/devfest22-taichung-cloud-workstation-introduction/"},{"categories":null,"content":" Slideshare: DevFest 2022 - Cloud Workstation Introduction TaiChung Google announce Gloud Workstation preview version on 2022/10/11. In this year DevFest Taichung 2022, I share Cloud Workstation Introduction. Introduce how to set up Cloud Workstation, use cases and Demo. ","date":"2022-10-30","objectID":"/posts/devfest22-taichung-cloud-workstation-introduction/:0:0","tags":["cloudworkstation","devfest"],"title":"Devfest22 Taichung Cloud Workstation Introduction","uri":"/posts/devfest22-taichung-cloud-workstation-introduction/"},{"categories":null,"content":"Simple Tips It’s quick easy to create workstation cluster, configuration and workstation. We could leverage Open VSX Registry to install extension on basic editor Code-OSS. In reality, we might not found all extension we userd before on Open VSX Registry. Although both of them are open source project, but still quick different a little bit. Due to Cloud Workation is containerization, so it retains some flexibility in terms of scalability. For instance. Cloud Workstation has alredy integrate with Cloud Code, basically it’s a plugin for VSCode with few cli tool like gcloud, skaffold but helm. Therefore, we could use Dockerfile to build our own image with helm. In this way, we could use helm in Cloud Workstation container base on our own image. In ecosytem, Cloud Workstation intergrate with Jetbrain IDEs. We could get same development experience as local workstation base on pre defined Jetrain base container image with JetBrains Gateway but few knows issues still not support for now. Debug on Kubernetes Debug a locally running Cloud Run service Finally, due to Cloud Workstation is preview version now, all of them are subject to change. We could expect more features and better experience in the future. Basically, it’s a good start for those developer who want to seprarate development environment from local workstation. ","date":"2022-10-30","objectID":"/posts/devfest22-taichung-cloud-workstation-introduction/:0:1","tags":["cloudworkstation","devfest"],"title":"Devfest22 Taichung Cloud Workstation Introduction","uri":"/posts/devfest22-taichung-cloud-workstation-introduction/"},{"categories":null,"content":"The preconfigured base images provided by Cloud Workstations contain only a minimal environment with IDE, basic Linux terminal and language tools and a sshd server. To expedite the environment setup of specific development use cases, you can create custom container images that extend these base images to pre-install tools and dependencies and that run automation scripts.","date":"2022-10-25","objectID":"/posts/cloud-workstation-with-hugo-env/","tags":["workstation","docker","hugo"],"title":"Cloud Workstation With Hugo Env","uri":"/posts/cloud-workstation-with-hugo-env/"},{"categories":null,"content":"The preconfigured base images provided by Cloud Workstations contain only a minimal environment with IDE, basic Linux terminal and language tools and a sshd server. To expedite the environment setup of specific development use cases, you can create custom container images that extend these base images to pre-install tools and dependencies and that run automation scripts. Base container image provided by Cloud Worksation Image Description us-central1-docker.pkg.dev/cloud-workstations-images/predefined/code-oss:latest Cloud Workstations base editor based on Code-OSS. (Default). us-central1-docker.pkg.dev/cloud-workstations-images/predefined/base:latest Base image with no IDE installed. us-central1-docker.pkg.dev/cloud-workstations-images/predefined/clion:latest CLion IDE. Accessible only through JetBrains Gateway us-central1-docker.pkg.dev/cloud-workstations-images/predefined/goland:latest GoLand IDE. Accessible only through JetBrains Gateway. us-central1-docker.pkg.dev/cloud-workstations-images/predefined/intellij-ultimate:latest IntelliJ IDEA Ultimate IDE. Accessible only through JetBrains Gateway. us-central1-docker.pkg.dev/cloud-workstations-images/predefined/phpstorm:latest PhpStorm IDE. Accessible only through JetBrains Gateway. us-central1-docker.pkg.dev/cloud-workstations-images/predefined/pycharm:latest PyCharm Professional IDE. Accessible only through JetBrains Gateway. us-central1-docker.pkg.dev/cloud-workstations-images/predefined/rider:latest Rider IDE. Accessible only through JetBrains Gateway. us-central1-docker.pkg.dev/cloud-workstations-images/predefined/rubymine:latest RubyMine IDE. Accessible only through JetBrains Gateway. us-central1-docker.pkg.dev/cloud-workstations-images/predefined/webstorm:latest WebStorm IDE. Accessible only through JetBrains Gateway. ","date":"2022-10-25","objectID":"/posts/cloud-workstation-with-hugo-env/:0:0","tags":["workstation","docker","hugo"],"title":"Cloud Workstation With Hugo Env","uri":"/posts/cloud-workstation-with-hugo-env/"},{"categories":null,"content":"Hugo env Build Hugo development environment by GCP cloud workstation Use us-central1-docker.pkg.dev/cloud-workstations-images/predefined/code-oss:latest base container image Install Hugo Install Code-OSS Open VSX Registry extenions better-toml vscode-markdownlint change-case FROM us-central1-docker.pkg.dev/cloud-workstations-images/predefined/code-oss:latest RUN sudo apt update # VARIANT can be either 'hugo' for the standard version or 'hugo_extended' for the extended version. ARG VARIANT=hugo # VERSION can be either 'latest' or a specific version number ARG VERSION=latest # Download Hugo RUN apt-get update \u0026\u0026 apt-get install -y ca-certificates openssl git curl \u0026\u0026 \\ rm -rf /var/lib/apt/lists/* \u0026\u0026 \\ case ${VERSION} in \\ latest) \\ export VERSION=$(curl -s https://api.github.com/repos/gohugoio/hugo/releases/latest | grep \"tag_name\" | awk '{print substr($2, 3, length($2)-4)}') ;;\\ esac \u0026\u0026 \\ echo ${VERSION} \u0026\u0026 \\ wget -O ${VERSION}.tar.gz https://github.com/gohugoio/hugo/releases/download/v${VERSION}/${VARIANT}_${VERSION}_Linux-64bit.tar.gz \u0026\u0026 \\ tar xf ${VERSION}.tar.gz \u0026\u0026 \\ mv hugo /usr/bin/hugo # Download Extension RUN wget https://open-vsx.org/api/bungcip/better-toml/0.3.2/file/bungcip.better-toml-0.3.2.vsix \u0026\u0026 \\ unzip bungcip.better-toml-0.3.2.vsix \"extension/*\" \u0026\u0026\\ mv extension /opt/code-oss/extensions/better-toml RUN wget https://open-vsx.org/api/DavidAnson/vscode-markdownlint/0.48.1/file/DavidAnson.vscode-markdownlint-0.48.1.vsix \u0026\u0026 \\ unzip DavidAnson.vscode-markdownlint-0.48.1.vsix \"extension/*\" \u0026\u0026\\ mv extension /opt/code-oss/extensions/markdownlint RUN wget https://open-vsx.org/api/wmaurer/change-case/1.0.0/file/wmaurer.change-case-1.0.0.vsix \u0026\u0026 \\ unzip wmaurer.change-case-1.0.0.vsix \"extension/*\" \u0026\u0026\\ mv extension /opt/code-oss/extensions/change-case # Hugo dev server port EXPOSE 1313 # [Optional] Uncomment this section to install additional OS packages you may want. # RUN apt-get update \u0026\u0026 export DEBIAN_FRONTEND=noninteractive \\ \u0026\u0026 apt-get -y install --no-install-recommends webp $ docker build -t cage1016/hugo-evn . ","date":"2022-10-25","objectID":"/posts/cloud-workstation-with-hugo-env/:0:1","tags":["workstation","docker","hugo"],"title":"Cloud Workstation With Hugo Env","uri":"/posts/cloud-workstation-with-hugo-env/"},{"categories":null,"content":"Workstation Setup workation base container image at workstation configuration docker.io/cage1016/hugo-env:latest We could let Service Account field empty if base container image is public. Create workstation by previous configuration Start workstaion and luanch it. Clone git repo from https://github.com/526avijitgupta/gokarna.git Develop Hugo $ cd exampleSite/ $ hugo server -D We need to enable gcloud cli port-forward for local live preview Visit http://localhost:1313 Enjoying Hugo development. ","date":"2022-10-25","objectID":"/posts/cloud-workstation-with-hugo-env/:0:2","tags":["workstation","docker","hugo"],"title":"Cloud Workstation With Hugo Env","uri":"/posts/cloud-workstation-with-hugo-env/"},{"categories":null,"content":"Since Mac OS finally removed support for Python2 in 12.3, the workflows written in Python2 in Alfred 4 are no longer available. The amowu/alfred-chinese-converter I was using before is also no longer updated (it's still in Alfred 2). So I built one with Golang + awgo + opencc, eliminating the dependency on Python, and Alfred upgrades no longer run into Python version problems.","date":"2022-07-10","objectID":"/posts/alfred-open-chinese-convert/","tags":["alfred","alfred4-workflow","opencc","golang","awgo"],"title":"Alfred Open Chinese Convert","uri":"/posts/alfred-open-chinese-convert/"},{"categories":null,"content":"Introduction Since Mac OS finally removed support for Python2 in 12.3, the workflows written in Python2 in Alfred 4 are no longer available. The amowu/alfred-chinese-converter I was using before is also no longer updated (it’s still in Alfred 2). So I built one with Golang + deanishe/awgo + longbridgeapp/opencc, eliminating the dependency on Python, and Alfred upgrades no longer run into Python version problems. ","date":"2022-07-10","objectID":"/posts/alfred-open-chinese-convert/:1:0","tags":["alfred","alfred4-workflow","opencc","golang","awgo"],"title":"Alfred Open Chinese Convert","uri":"/posts/alfred-open-chinese-convert/"},{"categories":null,"content":"alfred-opencc default keyword occ launch alfred-opencc Total support 8 translation methods. Be able to enable/disable for each translation method indvidual. Simplified Chinese to Traditional Chinese Traditional Chinese to Simplified Chinese Simplified Chinese to Traditional Chinese (Taiwan Standard) Traditional Chinese (Taiwan Standard) to Simplified Chinese Simplified Chinese to Traditional Chinese (Hong Kong variant) Traditional Chinese (Hong Kong variant) to Simplified Chinese Simplified Chinese to Traditional Chinese (Taiwan Standard) with Taiwanese idiom Traditional Chinese (Taiwan Standard) to Simplified Chinese with Mainland Chinese idiom Please visit Releases · cage1016/alfred-opencc to download latest version alfred-opencc workflow ","date":"2022-07-10","objectID":"/posts/alfred-open-chinese-convert/:2:0","tags":["alfred","alfred4-workflow","opencc","golang","awgo"],"title":"Alfred Open Chinese Convert","uri":"/posts/alfred-open-chinese-convert/"},{"categories":null,"content":"gokit-todo, gokit-todo-frontend are applications developed with low dependencies on code suites and simple tasks on Kubernetes. We can easily migrate to Google App Engine for CI/CD development process using Google Cloud Build and Github repo.","date":"2022-03-27","objectID":"/posts/deploy-gokit-todo-to-gae-with-cloud-build-from-github-repo/","tags":["gokit","todomvc","gcp","gae","postgres","cloudsql"],"title":"Deploy Gokit Todo to GAE With Cloud Build From Github Repo","uri":"/posts/deploy-gokit-todo-to-gae-with-cloud-build-from-github-repo/"},{"categories":null,"content":"gokit-todo https://github.com/cage1016/gokit-todo todomvc full stack demo project. react + backend API by gokit microservice toolkit. include unit test, integration test, e2e test, github action ci https://github.com/cage1016/gokit-todo-frontend gokit todo frotnend: React todomvc gokit-doto (Microservices backend API with Postgres database) and gokit-todo-frontend (React todomvc) are demo applications developed for Kubernetes with Ingress (Istio/Nginx-ingress). You can also quickly start an entire application with a database via docker-compose. Feel free to try it out by following the guide in the repo. ","date":"2022-03-27","objectID":"/posts/deploy-gokit-todo-to-gae-with-cloud-build-from-github-repo/:1:0","tags":["gokit","todomvc","gcp","gae","postgres","cloudsql"],"title":"Deploy Gokit Todo to GAE With Cloud Build From Github Repo","uri":"/posts/deploy-gokit-todo-to-gae-with-cloud-build-from-github-repo/"},{"categories":null,"content":"migrate gokit-todo gokit-todo-frontent to Google App Engine with Cloud SQL Before we migrated our Kubernetes application to Google App Engine. We first need to have some understanding of Google App Engine. Make sure our ideas work. Google App Engine is a Pass (Platform as a Service) service, which means we only need to focus on application development. So we can reuse gokit-todo, gokit-todo-frontend source code and deploy to Google App Engine through app.yaml configuration ✅ Google App Engine support standard-runtime (Python, Java, Node.js, PHP, Ruby, Go) and flexible-runtime (Go, Java 8, PHP 5/7, Python 2.7/3.6, .NET, Node.js, Ruby, Custom runtime) Choose standard runtime Go 1.16 for gokit-todo as it is a pure backend API microservice ✅ Chosee standard-runtime Node.js 16 for gokit-todo-frontentd as it is React frontend application ✅ We can choose Cloud SQL (Postgres) as our database to gokit-todo application in Google App Engine environment. You must use Cloud SQL proxy postgres driver cloudsqlpostgres to connect to Cloud SQL cause Cloud SQL will handle the connection authentication and authorization automatically. ✅ We can choose Google Cloud Build to handle CI/CD pipeline workflow and fully integrate with Github repo. There is most important things is you need to grant project default Google Cloud service account project-number@cloudbuild.gserviceaccount.com with enough permissions to build and deploy your application. ✅ Architecture Above is the whole architecture of our application gokit-todo-gae leverage with gokit-todo and gokit-todo-frontend as git submodule. Using a project with git submodules avoids the overhead of interfering with the application source code. ","date":"2022-03-27","objectID":"/posts/deploy-gokit-todo-to-gae-with-cloud-build-from-github-repo/:2:0","tags":["gokit","todomvc","gcp","gae","postgres","cloudsql"],"title":"Deploy Gokit Todo to GAE With Cloud Build From Github Repo","uri":"/posts/deploy-gokit-todo-to-gae-with-cloud-build-from-github-repo/"},{"categories":null,"content":"Google App Engine It’s very basic setup for our demo scenario. Just enable Google App Engine service in Google Cloud project and we will leverage Google Cloud Build to handle all depoyment jobs gcloud app create --region=asia-east1 ","date":"2022-03-27","objectID":"/posts/deploy-gokit-todo-to-gae-with-cloud-build-from-github-repo/:3:0","tags":["gokit","todomvc","gcp","gae","postgres","cloudsql"],"title":"Deploy Gokit Todo to GAE With Cloud Build From Github Repo","uri":"/posts/deploy-gokit-todo-to-gae-with-cloud-build-from-github-repo/"},{"categories":null,"content":"Cloud SQL You can create a Cloud SQL instance in Google Cloud Console or gcloud sql instances create command. The following gcloud command will create a Cloud SQL. gcloud sql instances create todo --database-version=POSTGRES_11 --cpu=1 --memory=3840MiB --region=asia-east1 --root-password=password --storage-size=10GB --storage-type=SSD When Cloud SQL instance is created then we need to crate a demo database. gcloud sql databases create todo -i todo It’s quick simple step to create a Cloud SQL instance and a demo database via gcloud command. Cloud SQL instance setup with Public IP address as default and you can also setup with Private IP address as your want. Make sure you enable VPC network for your private IP address Cloud SQL instance. ","date":"2022-03-27","objectID":"/posts/deploy-gokit-todo-to-gae-with-cloud-build-from-github-repo/:4:0","tags":["gokit","todomvc","gcp","gae","postgres","cloudsql"],"title":"Deploy Gokit Todo to GAE With Cloud Build From Github Repo","uri":"/posts/deploy-gokit-todo-to-gae-with-cloud-build-from-github-repo/"},{"categories":null,"content":"Google Cloud Build As previous mentioned that all CI/CD jobs are handled by Google Cloud Build. We need to create a bunch of Cloud Build configurations to build and deploy our application. We added gokit-todo and gokit-todo-frontend application as project git submodule. We create a Cloud Build configuration for gokit-todo and gokit-todo-frontend and each of them could trigger another cloud build trigger to deploy application. It’s useful tips to trigger Cloud Build trigger by RESTful API in one Cloud Build steps. curl -d '{\"branchName\":\"master\"}' -X POST -H \"Content-type: application/json\" \\ -H \"Authorization: Bearer $(gcloud config config-helper --format='value(credential.access_token)')\" \\ https://cloudbuild.googleapis.com/v1/projects/\u003cgcp-project\u003e/triggers/\u003ccloudbuild-trigger-id\u003e:run Trigger trigger gokit-todo and gokit-todo-frontend by cloudbuild.api.yaml 及 cloudbuild.default.yaml It’s also to deploy Google App Engine dispatch router dispatch.yaml settings through cloudbuild.dispatch.yaml All of Cloud Build settings ","date":"2022-03-27","objectID":"/posts/deploy-gokit-todo-to-gae-with-cloud-build-from-github-repo/:5:0","tags":["gokit","todomvc","gcp","gae","postgres","cloudsql"],"title":"Deploy Gokit Todo to GAE With Cloud Build From Github Repo","uri":"/posts/deploy-gokit-todo-to-gae-with-cloud-build-from-github-repo/"},{"categories":null,"content":"gokit-todo-gae cage1016/gokit-todo-gae . ├── api // gokit-todo submodule as api service ├── default // gokit-todo-frontend as default service ├── .gitmodules ├── cloudbuild.api.yaml // deploy api service (Manual) ├── cloudbuild.default.yaml // deploy default service (Manual) ├── cloudbuild.dispatch.yaml // deploy dispatch.yaml └── dispatch.yaml // gokit-todo-gae dispatch yaml You can see above project file structure (gokit-todo-gae) is same as previous architecture diagram. The operation process is as follows Frontend developer push code to Github repo gokit-todo-frontend 👉 trigger gokit-todo-frontend will be triggered and do their steps job and trigger gokit-todo-gae-deploy-default trigger by RESTFul API at last step 👉 trigger gokit-todo-gae-deploy-default will build and deploy gokit-todo-frontend application to Google App Engine. cloudbuild.yaml cloudbuild.default.yaml Backend developer push code to Github repo gokit-todo 👉 trigger gokit-todo will be triggered and do their steps job (application testing) and trigger gokit-todo-gae-deploy-api trigger by RESTFul API at last step 👉 trigger gokit-todo-gae-deploy-api will build and deploy gokit-todo application to Google App Engine. cloudbuild.yaml cloudbuild.api.yaml It’s also easy to update Google App Engine dispatch routing setting by push dispatch.yaml changed to Github repo gokit-todo-gae 👉 trigger gokit-todo-gae-deploy-dispatch will update dispatch routing to Google App Engine cloudbuild.dispatch.yaml ","date":"2022-03-27","objectID":"/posts/deploy-gokit-todo-to-gae-with-cloud-build-from-github-repo/:6:0","tags":["gokit","todomvc","gcp","gae","postgres","cloudsql"],"title":"Deploy Gokit Todo to GAE With Cloud Build From Github Repo","uri":"/posts/deploy-gokit-todo-to-gae-with-cloud-build-from-github-repo/"},{"categories":null,"content":"summary Google App Engine is easy to get started with. In particular, for simple applications like this demo, the Google App Engine standard-runtime offers a free tier of 28 instance-hours per day. We can migrate pre Kubernetes application gokit-todo and gokit-todo-frontend to Google App Engine without any code modified, just leverage with requirement app.yaml and Google App Engine could collaborate with GitHub Repo and Google Cloud Build well. Q Why don’t we use Github build-in CI/CD Github action instead of Google Cloud Build ? A Yes, You could do HTTP request to trigger Google Cloud Build trigger in Github Action but have to handle request authentication by yourself. Google Cloud Build will auto handle those request authentication automatically source code gokit-todo https://github.com/cage1016/gokit-todo gokit-todo-frontend https://github.com/cage1016/gokit-todo-frontend gokit-todo-gae https://github.com/cage1016/gokit-todo-gae ","date":"2022-03-27","objectID":"/posts/deploy-gokit-todo-to-gae-with-cloud-build-from-github-repo/:7:0","tags":["gokit","todomvc","gcp","gae","postgres","cloudsql"],"title":"Deploy Gokit Todo to GAE With Cloud Build From Github Repo","uri":"/posts/deploy-gokit-todo-to-gae-with-cloud-build-from-github-repo/"},{"categories":null,"content":"Recently, I have encountered the need of document localization in my work environment, and the commonly used Google Translate, DeepL Translate, and Wason Language Translator all provide document translation. Wason Language Translator provides a free Lite solution, so I use Wason Language Translator offers a free Lite solution, so use Golang to package Language Translator - IBM Cloud API for cli to make it easier to use.","date":"2022-03-06","objectID":"/posts/wason-language-translator-cli/","tags":["wason","translator","cli","golang"],"title":"Wason Language Translator CLI","uri":"/posts/wason-language-translator-cli/"},{"categories":null,"content":"Using text translation is a common situation in daily life, such as Google Translate、DeepL Translate, Wason Language Translator and other frequently used services. All of the above services basically support the translation of documents (docx, pptx, pdf, etc.), but the difference is the cost and accuracy of translation. Cloud Translation | Google Cloud: Google Cloud Translator provides full document translation, the overall translation effect is better, but there is no free quota, you need to bind a settlement account to use. Wason Language Translator Demo: IBM Cloud also provides file translation. After applying for an account, there is a free plan of 2 MB per file. The overall translation effect is worse than Google Cloud Translate. This article basically encapsulates Language Translator - IBM Cloud API Docs into cli to facilitate file translation ","date":"2022-03-06","objectID":"/posts/wason-language-translator-cli/:0:0","tags":["wason","translator","cli","golang"],"title":"Wason Language Translator CLI","uri":"/posts/wason-language-translator-cli/"},{"categories":null,"content":"Wason Language Translator Lite Plan Language Translator - IBM Cloud(https://cloud.ibm.com/apidocs/language-translator) The Lite plan gets you started with 1,000,000 characters per month at no cost and includes the default translation models. When you upgrade to a paid plan, you can create custom models. ","date":"2022-03-06","objectID":"/posts/wason-language-translator-cli/:1:0","tags":["wason","translator","cli","golang"],"title":"Wason Language Translator CLI","uri":"/posts/wason-language-translator-cli/"},{"categories":null,"content":"Usage Visit 👉 releases to download latest binary file Visit 👉 Language Translator - IBM Cloud apply an IBM Cloud account, create Language Translator instance. copy apiKey 及 url API_KEY=\u003creplace-your-api-key\u003e URL=\u003creplace-url\u003e cat \u003c\u003cEOF \u003e\u003e $HOME/.wason-translator-cli.yaml api_key: ${API_KEY} url: ${URL} version: 2018-05-01 EOF Translat document by cli and the supported formats are .doc, .docx, .ppt, .pptx, .xls, .xlsx, .rtf, .odt, .odp, .ods, .pdf, .htm, .html, .xml, .json, .txt Upload document to translate download translted docuemt file delete translted docuemt file ","date":"2022-03-06","objectID":"/posts/wason-language-translator-cli/:2:0","tags":["wason","translator","cli","golang"],"title":"Wason Language Translator CLI","uri":"/posts/wason-language-translator-cli/"},{"categories":null,"content":"Source Code cage1016/wason-translator-cli: IBM Cloud Language Translator CLI (document translate) ","date":"2022-03-06","objectID":"/posts/wason-language-translator-cli/:3:0","tags":["wason","translator","cli","golang"],"title":"Wason Language Translator CLI","uri":"/posts/wason-language-translator-cli/"},{"categories":null,"content":"2022 第一場 Taiwan Hong Kong Cloud Study Jam 已經開始, 時間從 2022/1/19 - 2022/2/7。GDG Cloud Taipei 也舉辦了 Taiwan \u0026 Hong Kong Cloud Study Jam Together 邀請大家在 2022/1/25 19:30 - 21:30 上線一起完成 Cloud Study Jam, 在 Meetup 活動開立之後有朋友寫信來問開通的問題，所以還是整理了一下資料來幫助新朋友順利通開取得30 天免費的Google Cloud Skills Boost 訂閱","date":"2022-01-23","objectID":"/posts/taiwan-hong-kong-cloud-study-jam-guide/","tags":["GloudStudyJam","meetup","gdg"],"title":"Taiwan Hong Kong Cloud Study Jam Guide","uri":"/posts/taiwan-hong-kong-cloud-study-jam-guide/"},{"categories":null,"content":"Taiwan Hong Kong Cloud Study Jam (Google offical) 邀請台灣與港澳的開發人員一起學習 Google Cloud 的相關技術。 Cloud Study Jam 是一項在線自學計劃，為台灣及港澳的開發人員提供操作與學習 Google Cloud Lab的機會，同時提供與在地 Google 開發者社群一起學習的機會。 2022 第一場 Taiwan Hong Kong Cloud Study Jam 已經開始 Taiwan \u0026 Hong Kong Cloud Study Jam - 活動首頁 活動時間: Jan. 19, 2022 17:00 - Feb. 9, 2022 23:59 ","date":"2022-01-23","objectID":"/posts/taiwan-hong-kong-cloud-study-jam-guide/:1:0","tags":["GloudStudyJam","meetup","gdg"],"title":"Taiwan Hong Kong Cloud Study Jam Guide","uri":"/posts/taiwan-hong-kong-cloud-study-jam-guide/"},{"categories":null,"content":"Taiwan \u0026 Hong Kong Cloud Study Jam Together (GDG Cloud Taipei) GDG Cloud Taipei 也開了一個線上的 Meetup，邀請大家一起上線完成 Cloud Study Jam Lab Meetup event link 👈 請上 GDG Cloud Taipei 的活動頁面報名 活動時間: 2022/1/25 19:30 - 21:30 ","date":"2022-01-23","objectID":"/posts/taiwan-hong-kong-cloud-study-jam-guide/:2:0","tags":["GloudStudyJam","meetup","gdg"],"title":"Taiwan Hong Kong Cloud Study Jam Guide","uri":"/posts/taiwan-hong-kong-cloud-study-jam-guide/"},{"categories":null,"content":"Guide GDG Cloud Taipei Meetup 活動開立之後，也有朋友寫信來問 Qwiklab 的問題，再來官方的使用手冊是 2021 的版本，對於參加過 Cloud Study Jam 的朋友應該沒有太大的問題，不過寫信來的朋友問的朋友看起來比較是沒有參加過 Cloud Study Jam，所以 GDG Cloud Taipei 就 fork 了一份更新了一些內容 Cloud Study Jam 2022 TW/HK User Guide - GDG Cloud Taipei Updated - Google Slides 👇 這個連結內容跟上面是一至的 這邊有幾點說明一下 活動是 Google 官方舉辦的，請依照官方的活動報名頁面，如果報名了沒有收到 Email，請連絡 support@qwiklabs.com or 至 2022 TWHK Cloud Study Jam - Google Groups (mailing list) 發問請求協助 報名成功登入後，Qwiklabs 會預先給你 9 個 credit (不過我老闆反應他只有 5 個 credit 😅)。原則上就是拿這 9 個 credit 去完成 Quest list starter 👇 其中一個 Lab 來換 30 天免費的Google Cloud Skills Boost 訂閱, 記得 Start Lab 的時間要 \u003e 5 分鐘 Create and Manage Cloud Resources Set Up and Configure a Cloud Environment in Google Cloud Implement DevOps in Google Cloud 在選點任何一個 Quest list starter ☝ 連結都會帶有一個 qlcampaign 的值 👇 ，開通當下不要亂點切換 URL，這個值不見了會導至開通失敗 (非常重要) 使用無痕視窗來操作，直接在 Open Google Console 按鈕右鍵開啟無痕視窗即可，UserName 會直接帶過去 這一次指定的 QWIKLABS QUESTS Introductory Create and Manage Cloud Resources Perform Foundational Infrastructure Tasks in Google Cloud Fundamental Build a Website on Google Cloud Automating Infrastructure on Google Cloud with Terraform Implement DevOps in Google Cloud Monitor and Log with Google Cloud Operations Suite Ensure Access \u0026 Identity in Google Cloud Service Serverless Cloud Run Development Cloud Architecture Networking in Google Cloud DevOps Essentials Understanding Your Google Cloud Costs Advanced Cloud Architecture: Design, Implement, and Manage Deploy to Kubernetes in Google Cloud Set Up and Configure a Cloud Environment in Google Cloud Build and Secure Networks in Google Cloud Secure Workloads in Google Kubernetes Engine Optimize Costs for Google Kubernetes Engine Migrate MySQL data to Cloud SQL using Database Migration VM Migration Migrating MySQL data to Cloud SQL using Database Migration Service Anthos Service Mesh Network Performance and Optimization Expert Deploy and Manage Cloud Environments with Google Cloud ","date":"2022-01-23","objectID":"/posts/taiwan-hong-kong-cloud-study-jam-guide/:3:0","tags":["GloudStudyJam","meetup","gdg"],"title":"Taiwan Hong Kong Cloud Study Jam Guide","uri":"/posts/taiwan-hong-kong-cloud-study-jam-guide/"},{"categories":null,"content":"身為一個工程師，日常使用 Markdown 來記錄各種東西已經是很習慣的方式。在過往經驗找工作必備的 Resume 是否也可以使用 Markdown 來編寫? 把 Resume 弄的簡單乾淨美觀是一件不太容易的事。之前剛好找到一個不錯的開源專案， fork 了一份來修改一下自己所需的部份, cage1016/react-resume-site 木及簡歷 | 一款用 Markdown 就能寫出好看簡歷(resume)的在線工具","date":"2022-01-22","objectID":"/posts/react-resume-site-write-resume-by-markdown/","tags":["react","vscode","markdown","devcontainer","buildpacks","nginx"],"title":"React Resume Site - Write Resume by Markdown","uri":"/posts/react-resume-site-write-resume-by-markdown/"},{"categories":null,"content":"在之前找工作的經驗當中，有被要求過只收 104 格式的 Resume，找個工作還要填寫一些沒有相關的欄位，那個年代只好忍一下 ","date":"2022-01-22","objectID":"/posts/react-resume-site-write-resume-by-markdown/:0:0","tags":["react","vscode","markdown","devcontainer","buildpacks","nginx"],"title":"React Resume Site - Write Resume by Markdown","uri":"/posts/react-resume-site-write-resume-by-markdown/"},{"categories":null,"content":"resumeworkshop 前幾天的 Vscode Channel 剛好有看到教你如果使用 Github dev + Github Page 的方式給自己搭一個簡易的 Resume 網頁 (Full workshop 👉 https://aka.ms/resumeworkshop)。簡單來說就是使用 HTML + CSS 來呈現，搭配 Github Dev + CodeSwing Extension 來讓工作流程容易一點 Pros: 快速 CodeSwing 加快工作效率 Cons: 簡單的模版 想增加美觀需要花很多時間調整 HTML + CSS ","date":"2022-01-22","objectID":"/posts/react-resume-site-write-resume-by-markdown/:1:0","tags":["react","vscode","markdown","devcontainer","buildpacks","nginx"],"title":"React Resume Site - Write Resume by Markdown","uri":"/posts/react-resume-site-write-resume-by-markdown/"},{"categories":null,"content":"React resume site 身為一個工程師，日常使用 Markdown 來記錄各種東西已經是很習慣的方式。在過往經驗找工作必備的 Resume 是否也可以使用 Markdown 來編寫? 把 Resume 弄的簡單乾淨美觀是一件不太容易的事。之前剛好找到一個不錯的開源專案， fork 了一份來修改一下自己所需的部份, cage1016/react-resume-site: 木及简历|一款用 Markdown就能写出好看简历(resume)的在线工具。 加入的 vscode devcontainer - 開發時可以有效的隔離系統環境，Container 是好物 增加了 linkedIn 及 slideshare 的 fontawesome Icon 使用 Github Action 透過 Buildpack 來打包成 Container image: react-resume-site/release.yml 使用 Markdown 來編寫 可以 embed 圖片。如：Github Readme status anuraghazra/github-readme-stats: Dynamically generated stats for your github readmes 很容易豐富頁面 可以 import/export Markdown 檔案 可以輸出 PDF 檔 (很重要的功能) Docker run 立即享有 🤘 ","date":"2022-01-22","objectID":"/posts/react-resume-site-write-resume-by-markdown/:2:0","tags":["react","vscode","markdown","devcontainer","buildpacks","nginx"],"title":"React Resume Site - Write Resume by Markdown","uri":"/posts/react-resume-site-write-resume-by-markdown/"},{"categories":null,"content":"知識點 身為一個一直推薦大家使用 Cloud Native Buildpacks 的人，本次打包 Container Image 當然也要用一下。React resume site 是一個 Node.js 的應用程式。現在大家常用前後端架構分離的條件下，前端自己的 CI/CD Pipeline 最終產物是一堆 HTML + CSS + JS 等等的靜態檔案，上 Container Image 時就可以搭配 Nginx 使用。相較專案本身使用的 Dockerfile 單純把整個專案直接放在 Container 上執行的作法是比較少用的 前置作業就是透過 npm run build 產出最後的靜態檔案 使用 gcr.io/paketo-buildpacks/nginx buildpack 來 Serving 這些靜態檔案 Builder 的部份配合 gcr.io/paketo-buildpacks/nginx，使用 paketobuildpacks/builder:base 準備 react-resume-site/nginx.conf Nginx Config 準備 react-resume-site/mime.types mime.types 準備 react-resume-site/project.toml 在打包 Container Image 可以排除一些不需要的檔案 (Optional) pack build ghcr.io/cage1016/react-resume-site:0.1.0 --buildpack gcr.io/paketo-buildpacks/nginx --builder paketobuildpacks/builder:base ... ===\u003e DETECTING paketo-buildpacks/nginx 0.5.2 ===\u003e ANALYZING Previous image with name \"ghcr.io/cage1016/react-resume-site:0.1.0\" not found ===\u003e RESTORING ===\u003e BUILDING Paketo Nginx Server Buildpack 0.5.2 Resolving Nginx Server version Candidate version sources (in priority order): buildpack.toml -\u003e \"1.21.*\" Selected Nginx Server version (using buildpack.toml): 1.21.4 Executing build process Installing Nginx Server 1.21.4 Completed in 222ms Configuring build environment PATH -\u003e \"$PATH:/layers/paketo-buildpacks_nginx/nginx/sbin\" Configuring launch environment PATH -\u003e \"$PATH:/layers/paketo-buildpacks_nginx/nginx/sbin\" Writing profile.d/configure.sh Calls executable that parses templates in nginx conf ===\u003e EXPORTING Adding layer 'paketo-buildpacks/nginx:nginx' Adding 1/1 app layer(s) Adding layer 'launcher' Adding layer 'config' Adding layer 'process-types' Adding label 'io.buildpacks.lifecycle.metadata' Adding label 'io.buildpacks.build.metadata' Adding label 'io.buildpacks.project.metadata' Setting default process type 'web' Saving ghcr.io/cage1016/react-resume-site:0.1.0... *** Images (sha256:cfe7259ffd44b824ab32146427ea06186c8dc2185c44a0125f035572a0125b96): ghcr.io/cage1016/react-resume-site:0.1.0 Successfully built image ghcr.io/cage1016/react-resume-site:0.1.0 ","date":"2022-01-22","objectID":"/posts/react-resume-site-write-resume-by-markdown/:2:1","tags":["react","vscode","markdown","devcontainer","buildpacks","nginx"],"title":"React Resume Site - Write Resume by Markdown","uri":"/posts/react-resume-site-write-resume-by-markdown/"},{"categories":null,"content":"Usage Pull Container Image docker pull ghcr.io/cage1016/react-resume-site:0.1.0 Run Container Image docker run --rm --env PORT=8080 -p 8080:8080 ghcr.io/cage1016/react-resume-site:0.1.0 Visit http://localhost:8080 ","date":"2022-01-22","objectID":"/posts/react-resume-site-write-resume-by-markdown/:3:0","tags":["react","vscode","markdown","devcontainer","buildpacks","nginx"],"title":"React Resume Site - Write Resume by Markdown","uri":"/posts/react-resume-site-write-resume-by-markdown/"},{"categories":null,"content":"木及简历 https://www.mujicv.com/ 這邊還有更多的模版可以下載 ","date":"2022-01-22","objectID":"/posts/react-resume-site-write-resume-by-markdown/:4:0","tags":["react","vscode","markdown","devcontainer","buildpacks","nginx"],"title":"React Resume Site - Write Resume by Markdown","uri":"/posts/react-resume-site-write-resume-by-markdown/"},{"categories":null,"content":"最近工作上有使用 [Apache JMeter](https://jmeter.apache.org/) 的需求，使用的情境很簡單，在硬體有支援的情況下進行靜態 website 的壓力測試，所以記錄一下最近的工作內容","date":"2021-12-23","objectID":"/posts/build-jmeter-docker-with-plugins/","tags":["jmeter","docker","s390x","ghcr.io"],"title":"Build Jmeter Docker With Plugins","uri":"/posts/build-jmeter-docker-with-plugins/"},{"categories":null,"content":"最近工作上有使用 Apache JMeter 的需求，使用的情境很簡單，在硬體有支援的情況下進行靜態 website 的壓力測試，所以記錄一下最近的工作內容 static website: cage1016/static-website-example: Static website to use with Cloud Academy labs Nginx: nginx:1.20.2-alpine Jmeter with Plugins: cage1016/docker-jmeter Jmeter Test Plan Usage ","date":"2021-12-23","objectID":"/posts/build-jmeter-docker-with-plugins/:0:0","tags":["jmeter","docker","s390x","ghcr.io"],"title":"Build Jmeter Docker With Plugins","uri":"/posts/build-jmeter-docker-with-plugins/"},{"categories":null,"content":"Static website To be used with Cloud Academy labs. 這是一個取自 Cloud Academy labs 建立的靜態網頁，剛好可以拿來作為 Jmeter 壓力測試的網頁，搭配 Nginx 一起使用 Dockerfile FROM nginx:1.20.2-alpine COPY health /usr/share/nginx/html COPY default.conf /etc/nginx/conf.d/default.conf COPY assets /usr/share/nginx/html/assets COPY error /usr/share/nginx/html/error COPY images /usr/share/nginx/html/images COPY index.html /usr/share/nginx/html docker build -t ghcr.io/cage1016/nginx-website-gz:0.1.0 . Container images ghcr.io/cage1016/nginx-website:0.1.0 ghcr.io/cage1016/nginx-website-gz:0.1.0 ","date":"2021-12-23","objectID":"/posts/build-jmeter-docker-with-plugins/:1:0","tags":["jmeter","docker","s390x","ghcr.io"],"title":"Build Jmeter Docker With Plugins","uri":"/posts/build-jmeter-docker-with-plugins/"},{"categories":null,"content":"Jmeter 在進行 Jmeter 部份時，考慮到測試環境以 command line 工具進行為主比較方便，所以選擇了 Jmeter 的 Docker 版本 justb4/jmeter，不過遇到這個版本不支援 IBM s390x 的架構。另外在 azure devops - Using JMeter plugins with justb4/jmeter Docker image results in error - Stack Overflow 有看到 justb4/jmeter 使用 Plugin 報出一些問題，所以就自己包啦 找到相關的 Dockerfile 下載 Jmeter 及額外所需的 Plugins 找到相關的 Dockerfile 感謝 Google / Github。linux-on-ibm-z/dockerfile-examples 雖然沒有在維護了，不過可以讓我們大至知道需要那些部件，基本架構可以使用 (Base image、openjdk 等等) 下載 Jmeter 及額外所需的 Plugins 所需的 Jmeter 及額外所需的 Plugins 都可以透過 Central Repository: kg/apc 這個網站得 Dockerfile ... # Download from git and build RUN mkdir -p /tmp/dependencies \\ \u0026\u0026 wget https://archive.apache.org/dist/jmeter/binaries/apache-jmeter-$JMETER_VER.tgz -O /tmp/dependencies/apache-jmeter-$JMETER_VER.tgz \\ \u0026\u0026 mkdir -p /opt \\ \u0026\u0026 tar -xvzf /tmp/dependencies/apache-jmeter-$JMETER_VER.tgz -C /opt \\ ; # plugins RUN wget ${JMETER_PLUGINS_DOWNLOAD_URL}/jmeter-plugins-manager/${JMETER_PLUGINS_MANAGER_VERSION}/jmeter-plugins-manager-${JMETER_PLUGINS_MANAGER_VERSION}.jar -O $JMETER_HOME/lib/ext/jmeter-plugins-manager-${JMETER_PLUGINS_MANAGER_VERSION}.jar \\ \u0026\u0026 wget ${JMETER_PLUGINS_DOWNLOAD_URL}/cmdrunner/$CMDRUNNER_VERSION/cmdrunner-$CMDRUNNER_VERSION.jar -O $JMETER_HOME/lib/cmdrunner-$CMDRUNNER_VERSION.jar \\ \u0026\u0026 java -cp $JMETER_HOME/lib/ext/jmeter-plugins-manager-${JMETER_PLUGINS_MANAGER_VERSION}.jar org.jmeterplugins.repository.PluginManagerCMDInstaller \\ \u0026\u0026 cd ${JMETER_HOME}/bin \u0026\u0026 ./PluginsManagerCMD.sh install jpgc-mergeresults \\ \u0026\u0026 cd ${JMETER_HOME}/bin \u0026\u0026 ./PluginsManagerCMD.sh install jpgc-synthesis \\ \u0026\u0026 cd ${JMETER_HOME}/bin \u0026\u0026 ./PluginsManagerCMD.sh install jpgc-cmd \\ \u0026\u0026 cd ${JMETER_HOME}/bin \u0026\u0026 ./PluginsManagerCMD.sh install jpgc-casutg \\ \u0026\u0026 cd ${JMETER_HOME}/bin \u0026\u0026 ./PluginsManagerCMD.sh install jpgc-json \\ \u0026\u0026 cd ${JMETER_HOME}/bin \u0026\u0026 ./PluginsManagerCMD.sh install jpgc-graphs-additional \\ \u0026\u0026 cd ${JMETER_HOME}/bin \u0026\u0026 ./PluginsManagerCMD.sh status \\ ... Dockerfile docker-jmeter/Dockerfile docker-jmeter/Dockerfile.s390x Container images ghcr.io/cage1016/jmeter:5.4.1 ","date":"2021-12-23","objectID":"/posts/build-jmeter-docker-with-plugins/:2:0","tags":["jmeter","docker","s390x","ghcr.io"],"title":"Build Jmeter Docker With Plugins","uri":"/posts/build-jmeter-docker-with-plugins/"},{"categories":null,"content":"Jmeter Test Plan 在準備好了靜態網站及 Docker 版本的 Jmeter 之後，接下來就是決定 Jmeter Test Plan，由於最終測試會有硬體加速支援的部份，情境就是針對 Nginx + Nginx 啟用 gzip 功能來對比，因此 Test Plan 就會是以 HTTP Request 為主 Jmeter 中也提供了 Test Script Recorder 的工具，可以搭配 Jmeter Proxy + Firefox 一起使用，這樣就可以省去手動建立那些 HTTP Request 繁鎖的動作，非常的方便 docker-jmeter-s390x/ap.jmx ","date":"2021-12-23","objectID":"/posts/build-jmeter-docker-with-plugins/:3:0","tags":["jmeter","docker","s390x","ghcr.io"],"title":"Build Jmeter Docker With Plugins","uri":"/posts/build-jmeter-docker-with-plugins/"},{"categories":null,"content":"Usage 在準備好 Test Plan 之後就可以透過 Docker 版本的 Jmeter 直接執行 Pull Docker image for x86 or x390x $ docker pull ghcr.io/cage1016/nginx-website-gz:0.1.0 $ docker pull ghcr.io/cage1016/nginx-website:0.1.0 $ docker pull ghcr.io/cage1016/jmeter:5.4.1 Dowonload jmeter.sh and test jmx ap.jmx $ wget https://raw.githubusercontent.com/cage1016/docker-jmeter/master/jmeter.sh \u0026\u0026 chmod +x jmeter.sh $ wget https://raw.githubusercontent.com/cage1016/docker-jmeter/master/ap.jmx Start Nginx with gz $ docker run --rm -d -p 8080:80 ghcr.io/cage1016/nginx-website-gz:0.1.0 #or $ podman run --rm -d -p 8080:80 ghcr.io/cage1016/nginx-website-gz:0.1.0 Run Jmeter with Docker $ ./jmeter.sh Error: Please specify JMX using -f. Usage: jmeter.sh [-d \u003cdeamon\u003e] [-i \u003cjmeter_docker_image\u003e] [-f \u003cjmx_file\u003e] [-t \u003ctest_folder\u003e] [-z \u003cenable_tar_html\u003e] [-l \u003cjmeterVariablesList\u003e] -d : Deamon, docker/podman (default: docker) -t : Test directory (default: ./tmp) -i : Jmeter docker image -f : Specify JMX file -l : Specify env list of Jmeter in following format: prop01=XXX,bbb=YYY,ccc=ZZZ -z : Enable tar html report (default: false) Example1: jmeter.sh -f ap.jmx Example2: jmeter.sh -i ghcr.io/cage1016/jmeter:5.4.1 -f ap.jmx Example3: jmeter.sh -i ghcr.io/cage1016/jmeter:5.4.1 -f ap.jmx -l prop01=XXX,prop02=YYY Run test ap.jmx $ ./jmeter.sh -i ghcr.io/cage1016/jmeter:5.4.1 -f ap.jmx -t ap -z true -l TARGET_HOST=localhost,TARGET_PORT=8080,THREADS=1,RAMD_UP=1,DURATION=10 docker run --rm --name jmeter --network host -i -v ${PWD}:${PWD} -w ${PWD} ghcr.io/cage1016/jmeter:5.4.1 ap.jmx -l ap/jmeter.jtl -j ap/jmeter.log -JTARGET_HOST=localhost -JTARGET_PORT=8080 -JTHREADS=1 -JRAMD_UP=1 -JDURATION=10 -o ap/report -e Creating summariser \u003csummary\u003e Created the tree successfully using ap.jmx Starting standalone test @ Wed Dec 29 08:39:40 GMT 2021 (1640767180391) Waiting for possible Shutdown/StopTestNow/HeapDump/ThreadDump message on port 4445 Warning: Nashorn engine is planned to be removed from a future JDK release summary = 8157 in 00:00:10 = 812.8/s Avg: 1 Min: 0 Max: 36 Err: 0 (0.00%) Tidying up ... @ Wed Dec 29 08:39:50 GMT 2021 (1640767190744) ... end of run ==== jmeter.log ==== See jmeter log in ap/jmeter.log ==== Raw Test Report ==== See Raw test report in ap/ap.jmx.jtl ==== HTML Test Report ==== See HTML test report in ap/report/index.html ==== Tar report ==== See Tar file in ap/1640767193.tar.gz 檢視產出 ./ap/jmeter.log: Jmeter 執行的 Log 檔案 ./ap/jmeter.jtl: Jmeter UI Linstern 載入資料 ./ap/report/index.html: HTLM 報表 ","date":"2021-12-23","objectID":"/posts/build-jmeter-docker-with-plugins/:4:0","tags":["jmeter","docker","s390x","ghcr.io"],"title":"Build Jmeter Docker With Plugins","uri":"/posts/build-jmeter-docker-with-plugins/"},{"categories":null,"content":"Jmeter Youtube toturial ","date":"2021-12-23","objectID":"/posts/build-jmeter-docker-with-plugins/:5:0","tags":["jmeter","docker","s390x","ghcr.io"],"title":"Build Jmeter Docker With Plugins","uri":"/posts/build-jmeter-docker-with-plugins/"},{"categories":null,"content":"Alfred 是一個在 Mac 上面增加生產力的工具，舉凡工程師常用的 Github、Google Drive 搜尋到 LeetCode Search 等原都可以在 Alfred 完成，簡直就是太方便了。自己也有曾經想要開發自己的 Alfred 應用，直到遇到 deanishe/awgo 之後就像撿到寶一樣，作為一個 Gopher 也找到適合的工具來開發自己的 Alfred 應用。","date":"2021-12-07","objectID":"/posts/alfred-change-case/","tags":["awgo","alfred","vscode","pyenv","githubaction"],"title":"Alfred Change Case","uri":"/posts/alfred-change-case/"},{"categories":null,"content":"Alfred 4 for Mac Alfred is an award-winning app for macOS which boosts your efficiency with hotkeys, keywords, text expansion and more. Search your Mac and the web, and be more productive with custom actions to control your Mac. Alfred - Productivity App for macOS Alfred 是一個在 Mac 上面增加生產力的工具，舉凡工程師常用的 Github、Google Drive 搜尋到 LeetCode Search 等原都可以在 Alfred 完成，簡直就是太方便了。自己也有曾經想要開發自己的 Alfred 應用，直到遇到 deanishe/awgo: Go library for Alfred 3 + 4 workflows 之後就像撿到寶一樣，作為一個 Gopher 也找到適合的工具來開發自己的 Alfred 應用。 ","date":"2021-12-07","objectID":"/posts/alfred-change-case/:1:0","tags":["awgo","alfred","vscode","pyenv","githubaction"],"title":"Alfred Change Case","uri":"/posts/alfred-change-case/"},{"categories":null,"content":"Change case alfred workflow This is change case tools inspired by change-case - Visual Studio Marketplace and wrapper by ku/go-change-case. Quickly change the case of a string or latest clipboard string and copy it to the clipboard. ","date":"2021-12-07","objectID":"/posts/alfred-change-case/:2:0","tags":["awgo","alfred","vscode","pyenv","githubaction"],"title":"Alfred Change Case","uri":"/posts/alfred-change-case/"},{"categories":null,"content":"Select Change Case options ","date":"2021-12-07","objectID":"/posts/alfred-change-case/:2:1","tags":["awgo","alfred","vscode","pyenv","githubaction"],"title":"Alfred Change Case","uri":"/posts/alfred-change-case/"},{"categories":null,"content":"Change Case by specific option directly 由於自己平常對於文串轉換的需求不小，在 vscode 中可以依賴 change-case - Visual Studio Marketplace 來完成需求；不過若在 vscode 環境之外就沒有那麼方便，也就是這一次 slide project - cage1016/alfred-change-case 的由來 ","date":"2021-12-07","objectID":"/posts/alfred-change-case/:2:2","tags":["awgo","alfred","vscode","pyenv","githubaction"],"title":"Alfred Change Case","uri":"/posts/alfred-change-case/"},{"categories":null,"content":"alfred-change-case 本次有使用到下面的知識點 deanishe/awgo: Go library for Alfred 3 + 4 workflows: Go library for Alfred 3 + 4 workflows ku/go-change-case: a golang port of npm package change-case pyenv + virtualenv + pip 準備 Python 環境 + workflow-install.py 來將 .workflow 所需的檔案動態安裝至 Alfred 中，在 vscode 的環境中搭配 vscode 的 tasks 來執行非常方便 go build prepare-info.plist install Github action 使用 runs-on: macOS-latest 來打包整個 .alfredworkflow 並上傳至 Github release asset 中，建立一個 Release 就可以完成發佈的動作 ","date":"2021-12-07","objectID":"/posts/alfred-change-case/:2:3","tags":["awgo","alfred","vscode","pyenv","githubaction"],"title":"Alfred Change Case","uri":"/posts/alfred-change-case/"},{"categories":null,"content":"心得 這一次的 cage1016/alfred-change-case 的字串轉換基本封裝 ku/go-change-case 為基礎轉換成 Alfred 的 workflow。在 deanishe/awgo: Go library for Alfred 3 + 4 workflows 上單純進行簡單的流程操作，作為一個 Gopher 來說是覺得開發過程很流暢，這一次的開發經驗可以很快的複製到其他的 Alfred workflow 專案 Source code: cage1016/alfred-change-case Download: change-case-1.0.0.alfredworkflow ","date":"2021-12-07","objectID":"/posts/alfred-change-case/:3:0","tags":["awgo","alfred","vscode","pyenv","githubaction"],"title":"Alfred Change Case","uri":"/posts/alfred-change-case/"},{"categories":null,"content":"Artifact Registry 可以說是 Container Registry 的進化版，可讓貴機構集中管理容器映像檔和語言套件 (例如 Maven 和 npm)。Artifact Registry 與 Google Cloud 的工具和執行階段全方位整合，並且支援原生構件通訊協定，讓您輕鬆與持續整合/持續推送軟體更新 (CI/CD) 工具整合，進而設定自動化管道。 Slideshare Devfest 2021’ - Artifact Registry Introduction (Taipei) ","date":"2021-11-30","objectID":"/posts/devfest21-taipei-artifact-registry-introduction/:0:0","tags":["devfest","container","registry","helm","artifact"],"title":"Devfest21 Taipei Artifact Registry Introduction","uri":"/posts/devfest21-taipei-artifact-registry-introduction/"},{"categories":null,"content":"功能性 作為 Container Registry 下一代通用解決方案的繼任者 Artifact Registry 除了延續原有的功能之外增加了對 Package 類型的支持 Container images: Docker, Helm Language packages: Java, Node.js, Python OS packages (Preview): Debian, RPM Aritfact Registry 在 Container image 的支持了 Docker V2, OCI Image Format 二種格式。在 Aritfact Registry 實作了 OCI Specification + Helm 3 支持了 chart packages in OCI format 的功能，也因為我們可以把 Helm chart 儲存在 Artifact registry 之中，這個也解決了上一代，我們的 Container image 可以放在 Container Registry 而我們的私有的 Helm chart 卻需要使用 Helm + GCS plugin 來搭配使用 Container Registry + Helm + GCS plugin Artifact Registry This is a tip 想把 Helm chart 儲存在 Artifact Registry 時，需要注意 Helm 的版本，Helm 在 Release Helm 3.7.0 · helm/helm 把對於 oci experimental 相關的 subcommand 移除了，所以 3.7.0 以上的版本就必需先透過 helm package 產出 tgz 檔案，再將 tgz 推送至 Artifact Registry ","date":"2021-11-30","objectID":"/posts/devfest21-taipei-artifact-registry-introduction/:1:0","tags":["devfest","container","registry","helm","artifact"],"title":"Devfest21 Taipei Artifact Registry Introduction","uri":"/posts/devfest21-taipei-artifact-registry-introduction/"},{"categories":null,"content":"靈活性 Multiple repositories Artifact Registry 增加了在同一個 GCP Project 可以建立出個 Repository，可以分別對應到不同的屬性 (Container images / Language packages / OS packages)，單一 Repository 可以指定至特別的 Zone 或是 Region，其中一個特點是被指派的每一個 Region 都相隔 100 英里以上。好處是有異地備援的概念，壞處會反應在 Billing 上面，跨 Region Egress 是會收費的 總之多了搭配的可能性，大家可以依照使用場景來選擇自己適合的組合 ","date":"2021-11-30","objectID":"/posts/devfest21-taipei-artifact-registry-introduction/:2:0","tags":["devfest","container","registry","helm","artifact"],"title":"Devfest21 Taipei Artifact Registry Introduction","uri":"/posts/devfest21-taipei-artifact-registry-introduction/"},{"categories":null,"content":"安全性 IAM Role 安全性一直是很重要的題目。在上一代想把 Helm Chart 部署在 GCP 平台上就會使用 Helm + GCS plugin。在這種組合之下權限控管就會變成 GCS 檔案的儲取權 roles/storage.objectViewer roles/storage.legacyBucketWriter roles/storage.admin 而 Aritfact Registry 在安全性管控這一塊提供更細粒度的彈性，讓我們可以跟據使用場景指派適合的權限來降低安全風險 Project Owner roles/artifactregistry.repoAdmin roles/artifactregistry.admin Project Editor roles/artifactregistry.writer Project Viewer roles/artifactregistry.reader ","date":"2021-11-30","objectID":"/posts/devfest21-taipei-artifact-registry-introduction/:3:0","tags":["devfest","container","registry","helm","artifact"],"title":"Devfest21 Taipei Artifact Registry Introduction","uri":"/posts/devfest21-taipei-artifact-registry-introduction/"},{"categories":null,"content":"Summary Summary Info Artifact Registry is the recommended service for managing container images. Container Registry is still supported but will only receive critical security fixes Artifact Registry 作為 Container Registry 的進化版，除了保留 Container Registry 原有的功能之外，我們可以看到從 功能性 靈活性 安全性 上面的加強。而官方也有聲名, Container Registry 除了安全性修復之外不會再有新功能的計劃，說明文件也有遷移的教學文件可以參考 最後還是再強調，大家還是需要針對自己的使用場景來選擇組合，才會用的開心，看到 Billing 也開心 ","date":"2021-11-30","objectID":"/posts/devfest21-taipei-artifact-registry-introduction/:4:0","tags":["devfest","container","registry","helm","artifact"],"title":"Devfest21 Taipei Artifact Registry Introduction","uri":"/posts/devfest21-taipei-artifact-registry-introduction/"},{"categories":null,"content":"因為 Covid-19 的原因，去年 Cloud Next 20' 臨時改成線上活動 (7 月 14 日 – 9 月 8 日) 持續了2個月。今年 Cloud Next 21' 就如同以前為期 3 天 (10月 12 日 – 10 月 14 日)的活動，只是改為線上。本次 Meetup ?就在正式活動前跟大家介紹一下如何該安排自己的 Session","date":"2021-10-13","objectID":"/posts/cloud-next-21-pre-event/","tags":["GoogleCloudNext"],"title":"Cloud Next 21 Pre Event","uri":"/posts/cloud-next-21-pre-event/"},{"categories":null,"content":"因為 Covid-19 的原因，去年 Cloud Next 20’ 臨時改成線上活動 (7 月 14 日 – 9 月 8 日) 持續了2個月。今年 Cloud Next 21’ 就如同以前為期 3 天 (10月 12 日 – 10 月 14 日)的活動，只是改為線上。本次 Meetup ?就在正式活動前跟大家介紹一下如何該安排自己的 Session ","date":"2021-10-13","objectID":"/posts/cloud-next-21-pre-event/:0:0","tags":["GoogleCloudNext"],"title":"Cloud Next 21 Pre Event","uri":"/posts/cloud-next-21-pre-event/"},{"categories":null,"content":"Top five things to experience at Next ’21 Kick off each morning with a keynote Customize your content Engage with experts Dive into demos Explore the impact of DEI ","date":"2021-10-13","objectID":"/posts/cloud-next-21-pre-event/:1:0","tags":["GoogleCloudNext"],"title":"Cloud Next 21 Pre Event","uri":"/posts/cloud-next-21-pre-event/"},{"categories":null,"content":"在開發 Kubernetes 應用程式時常使用 NATS 來作為內部 Pub/Sub 傳遞非同步訊息時使用，有時候也有對外開放的需求。而在本地機器開發時會採用輕量的 k8s cluster 解決方案，如 Kind, k3s, minikube 等來減輕本地開發資原的壓力，不過基於 container 的方式還是有一些限制，本篇文章以 k3s 為基礎來搭設開啟 TLS 的 NATS 服務器在本地的使用方式。","date":"2021-08-11","objectID":"/posts/k3s-nats-tls-openssl/","tags":["k3s","tls","nats","k8s"],"title":"K3s Nats tls by openssl","uri":"/posts/k3s-nats-tls-openssl/"},{"categories":null,"content":" 透過 k3d 建立本地 k3s cluster。因為 \u0008k3s 也是透過 docker 來摸擬 k8s cluster，所以透過 k3s 本身 port mapping 的配置來對外開放 8080:80 及 4222:31400 二個 port。 8080:80 給 hashicorp/http-echo 用。而 4222:31400 是對應 NATS nodeport 用 k3d cluster create dev -p 8080:80@loadbalancer -p 8443:443@loadbalancer -p \"4222:31400@server[0]\" 建立 hashicorp/http-echo。等待所有的 Pod 及服務就緒後，就可以透過 http://localhost:8080 來讀取 hashicorp/http-echo kubectl run --image hashicorp/http-echo --port 80 echo -- -listen=:80 --text=\"Hello from echo\" kubectl expose pod echo --port 80 --target-port 80 --type NodePort --name echo cat \u003c\u003cEOF | kubectl apply -f - apiVersion: extensions/v1beta1 kind: Ingress metadata: name: echo-ingress annotations: kubernetes.io/ingress.class: traefik spec: rules: - http: paths: - path: / pathType: Prefix backend: serviceName: echo servicePort: 80 EOF 下一個步驟就是建立 NATS。因為這一次我們要建立的是有啟用 TLS 的 NATS 服務器。而 TLS 的部份我們採用 self signed 的方式來建立，實際使用就看最終部署的情況來決定是誰來產出 cluster 有需的 TLS，而本 Demo 就方便的方式自建 首先建立所需的 certificate.conf 檔案。其中 IP 及 DNS 可以依照需求進行修改 cat \u003c\u003cEOF \u003e\u003e certificate.conf [req] default_bits = 2048 prompt = no default_md = sha256 req_extensions = req_ext distinguished_name = dn [dn] C = TW ST = New Taipei City O = Your organization CN = localhost [req_ext] subjectAltName = @alt_names [alt_names] DNS.1 = kubernetes DNS.2 = kubernetes.default DNS.3 = kubernetes.default.svc DNS.4 = kubernetes.default.svc.cluster DNS.5 = kubernetes.default.svc.cluster.local DNS.6 = localhost IP.1 = 127.0.0.1 IP.2 = 172.17.34.52 IP.3 = 192.168.0.15 [v3_ext] authorityKeyIdentifier=keyid,issuer:always basicConstraints=CA:FALSE keyUsage=keyEncipherment,dataEncipherment extendedKeyUsage=serverAuth,clientAuth subjectAltName=@alt_names EOF 產生 NATS 服務器有需的 TLS 檔，及之後提供給 Client 使用的 client1.crt client1.key ca.crt client2.crt client2.key ca.crt。這邊使用的方式是透過 openssl，有效日期也是 demo 方便先設為 1000 天。另外我們將啟用 NATS tls verifyAndMap 的功能。所以我們在 certificate.conf 的 Subject Alternative Name (SAN) 會指定 email，當 NATS 有開啟 verifyAndMap 就會檢查 Subject Alternative Name (SAN) cat \u003c\u003cEOF \u003e\u003e gen.sh #!/bin/bash # Move to root directory... mkdir -p keys cd keys # Generate the Certificate Files openssl genrsa -out ca.key 2048 openssl req -x509 -new -nodes -key ca.key -subj \"/CN=localhost\" -days 1000 -out ca.crt # server openssl genrsa -out server.key 2048 openssl req -new -key server.key -out server.csr -config ../certificate.conf openssl x509 -req -in server.csr -CA ca.crt -CAkey ca.key \\ -CAcreateserial -out server.crt -days 1000 \\ -extensions v3_ext -extfile ../certificate.conf # client1 openssl genrsa -out client1.key 2048 openssl req -new -key client1.key -out client1.csr -config ../certificate.conf openssl x509 -req -in client1.csr -CA ca.crt -CAkey ca.key \\ -CAcreateserial -out client1.crt -days 1000 \\ -extensions v3_ext -extfile \u003c(cat $(PWD)/certificate.conf | sed 's/IP.3 = 192.168.0.15/\u0026\\nemail.1 = client1@example.com/') echo $(PWD) # client2 openssl genrsa -out client2.key 2048 openssl req -new -key client2.key -out client2.csr -config ../certificate.conf openssl x509 -req -in client2.csr -CA ca.crt -CAkey ca.key \\ -CAcreateserial -out client2.crt -days 1000 \\ -extensions v3_ext -extfile ../certificate.conf EOF chmod +x ./gen.sh ./gen.sh 我們產生了二組 client tls keypair。我們在產生 client1 的 tls 檔案時加入額外的 Subject Alternative Name (SAN) 資訊 email:client1@example.com step: A zero trust swiss army knife for working with X509, OAuth, JWT, OATH OTP, etc. step-cli | Automate Certificates \u0026 Common Cryptography Primitives step certificate inspect keys/client1.crt Certificate: Data: Version: 3 (0x2) Serial Number: 11938605982689757523 (0xa5ae72e347938953) Signature Algorithm: SHA1-RSA Issuer: CN=localhost Validity Not Before: Aug 19 03:20:51 2021 UTC Not After : May 15 03:20:51 2024 UTC Subject: C=TW,ST=New Taipei City,O=Your organization,CN=localhost Subject Public Key Info: Public Key Algorithm: RSA Public-Key: (2048 bit) Modulus: ... Exponent: 65537 (0x10001) X509v3 extensions: X509v3 Authority Key Identifier: keyid X509v3 Basic Constraints: CA:FALSE X509v3 Key Usage: K","date":"2021-08-11","objectID":"/posts/k3s-nats-tls-openssl/:0:0","tags":["k3s","tls","nats","k8s"],"title":"K3s Nats tls by openssl","uri":"/posts/k3s-nats-tls-openssl/"},{"categories":null,"content":"TR409-1 Google 技術 x 公共參與 x 開源 Google Cloud Buildpacks 剖析與實踐 - COSCUP 2021 | Conference for Open Source Coders, Users, and Promoters CNCF 的 Cloud Native Buildpacks 專案已經在 2020 已經從 Sandbox 項目變成成了 Incubation 項目。Cloud Native Buildpacks (CNB) 的出現定義了轉換程式碼至 OCI 的標準，可以讓開發人員專注在本身功能上面，將安全性及依賴套件打包相關的部份交由 CNB 負責。 Google 也依照了CNB 的規範開源了 Google 版的 Google Cloud Buildpacks，也在 2019 Google Cloud Next 上宣布 Cloud Run (Cloud Run Button), GKE, Anthos, App Engine, Cloud functions 等服務支援使用 Google Cloud Buildpacks。 本場次會介紹 CNB 的發展歷史及 Google 開源的 Google Cloud Buildpacks 剖析與實踐 Q\u0026A buildpack 的 runtime image 是不可以被更改的是只在 local 需要 Reproducible 的限制，單純的使用者需要了解的是怎麼使用這個工具? 之前分享跟 Buildpack 相關的主題 Buildpack Tips and Tricks - KaiChu Build Your Buildpack - KaiChu Github Assets Cnb - KaiChu Pack 0.19.0 Solved Invalid Cross Device Link at Google Cloud Build - KaiChu 總的來說 Buildpack 的出現，提供了一個從 Source to container image 的方式，讓開發人員可以從 Dockerfile 中解放，專注在商業邏輯的部份，將 container image 的安全性、每一層怎麼堆疊等部份交給 Buildpack 所規範的方式去作。Dockerfile 在某些場景還是很好用，在適合的場景時機引入 Buildpack 可以讓工作流程更為簡化 Google Cloud Buildpacks 是一個 100% 相容 Cloud Native Buildpacks 的一個實作。類似有實作的還有 Paketo 及 Heroku 所提供的版本，當然各家實作出來的 Builder 除了相容規範之外還會加上自家獨有的東西，如 Google Cloud Buildpacks 就增加了 Google Cloud Platfrom 中特有的 Cloud Function 入級: 每一個 Builder 的參數不盡相同，使用前需參考使用說明。Google Cloud Buildpacks 已經支持 Cloud Run, GKE, Anthos, App Engine, Cloud Function。言話部份也有 Go, Node.js, Python, Java, Net Core 等，在開發工具鍊中也有 skaffold, pack, tekton, kpack 也可以搭配 gcloud 及 Google Cloud Build 一起使用。 初級: 依照 Cloud Native Buildpacks 的規範實作自己的 Buildpack (shell 版本) 中級: 使用第三方工具來建構 Buildpack, 如 paketo-buildpacks/packit。在閱讀 Google Cloud Buildpacks 的開收源始碼後，你會發現這個專案也是使用同樣的方式來建構出 Google 版的 Builpack，不過用的是 Google 自己寫 Library，最終透過 Bazel 打包成相容 Cloud Native Buildpacks 的格式。 ","date":"2021-08-02","objectID":"/posts/coscup-x-ruby-conf-tw-2021-google-cloud-buildpacks/:0:1","tags":["pack","buildpacks","google","coscup"],"title":"Coscup X Ruby Conf Tw 2021 Google Cloud Buildpacks","uri":"/posts/coscup-x-ruby-conf-tw-2021-google-cloud-buildpacks/"},{"categories":null,"content":"記錄如何在本機端使用 KIND/K3d 開發 Kubernetes 應用程式時如果需要使用 NATS 時，在不使用 Ingress 時快速 Expose NTAS 給 Client 使用","date":"2021-07-30","objectID":"/posts/nats-quick-expose-for-local-test/","tags":["nats","k3d","kind","kubernetes"],"title":"NATS quick expose for local test","uri":"/posts/nats-quick-expose-for-local-test/"},{"categories":null,"content":"bitnami/nats https://github.com/bitnami/charts/tree/master/bitnami/nats/#installing-the-chart 為了本機端使用 KIND/K3d 為基礎開發 Kubernetes 有 NATS 介接需求時，可以透過 Helm 來快速部署且只有開發需求，就可以使用 bitnami/nats 的版本來使用。所以在 NATS 的 Expose 方式使用 NodePort 將 NATS client 4222 指定給 31400 helm install nats \\ --set auth.enabled=false \\ --set client.service.type=NodePort \\ --set client.service.nodePort=31400 \\ bitnami/nats --create-namespace --namespace nats 待 Helm 安裝完 bitnami/nats 可以檢視 nats-client $ k -n nats get svc NAME TYPE CLUSTER-IP EXTERNAL-IP PORT(S) AGE nats-client NodePort 10.96.104.5 \u003cnone\u003e 4222:31400/TCP 20m nats-cluster ClusterIP 10.96.97.123 \u003cnone\u003e 6222/TCP 20m nats-headless ClusterIP None \u003cnone\u003e 4222/TCP,6222/TCP 20m nats-monitoring ClusterIP 10.96.124.235 \u003cnone\u003e 8222/TCP 20m ","date":"2021-07-30","objectID":"/posts/nats-quick-expose-for-local-test/:1:0","tags":["nats","k3d","kind","kubernetes"],"title":"NATS quick expose for local test","uri":"/posts/nats-quick-expose-for-local-test/"},{"categories":null,"content":"Kubernetes Cluster ","date":"2021-07-30","objectID":"/posts/nats-quick-expose-for-local-test/:2:0","tags":["nats","k3d","kind","kubernetes"],"title":"NATS quick expose for local test","uri":"/posts/nats-quick-expose-for-local-test/"},{"categories":null,"content":"KIND KIND_NATS_PORT=4222 cat \u003c\u003cEOF \u003e\u003e kind-config.yaml kind: Cluster apiVersion: kind.x-k8s.io/v1alpha4 name: kind-testbed nodes: - role: control-plane # port forward 80 on the host to 80 on this node extraPortMappings: - containerPort: 31400 hostPort: ${KIND_NATS_PORT} # optional: set the bind address on the host # 0.0.0.0 is the current default # optional: set the protocol to one of TCP, UDP, SCTP. # TCP is the default protocol: TCP EOF # create local kind cluster kind create cluster --config kind-config.yaml ","date":"2021-07-30","objectID":"/posts/nats-quick-expose-for-local-test/:2:1","tags":["nats","k3d","kind","kubernetes"],"title":"NATS quick expose for local test","uri":"/posts/nats-quick-expose-for-local-test/"},{"categories":null,"content":"K3d K3D_NATS_PORT=4223 cat \u003c\u003cEOF \u003e\u003e k3d-config.yaml apiVersion: k3d.io/v1alpha2 name: k3d-testbed kind: Simple servers: 1 ports: - port: ${K3D_NATS_PORT}:31400 nodeFilters: - server[*] EOF # create local k3d cluster k3d cluster create --config k3d-config.yaml ","date":"2021-07-30","objectID":"/posts/nats-quick-expose-for-local-test/:2:2","tags":["nats","k3d","kind","kubernetes"],"title":"NATS quick expose for local test","uri":"/posts/nats-quick-expose-for-local-test/"},{"categories":null,"content":"Docker 這時候我們就可以輕鬆透過 :::4223 及 0.0.0.0:4222 來連接二個 k8s 內部的 NATS 服務 $ docker ps ... PORTS NAMES ... 0.0.0.0:4223-\u003e31400/tcp, :::4223-\u003e31400/tcp k3d-k3d-testbed-server-0 ... 127.0.0.1:65264-\u003e6443/tcp, 0.0.0.0:4222-\u003e31400/tcp kind-testbed-control-plane ","date":"2021-07-30","objectID":"/posts/nats-quick-expose-for-local-test/:2:3","tags":["nats","k3d","kind","kubernetes"],"title":"NATS quick expose for local test","uri":"/posts/nats-quick-expose-for-local-test/"},{"categories":null,"content":"Pack 0.19.0 終於發佈了，這一個版本包含了解決在 Google Cloud Build 上執行 Pack 會遇到 Invalid Cross Device Link 的錯誤。這篇文章詳細說明了遇到的問題、回報 Issue 及解決的方式","date":"2021-06-17","objectID":"/posts/pack-solved-invalid-cross-device-link-at-google-cloud-build/","tags":["pack","cloudbuild","buildpacks"],"title":"Pack 0.19.0 Solved Invalid Cross Device Link at Google Cloud Build","uri":"/posts/pack-solved-invalid-cross-device-link-at-google-cloud-build/"},{"categories":null,"content":"在前幾篇介紹 Pack 時就有提供 Google Cloud Build 使用 Pack 來建構 Container image 時因為 Pack 的 Cached 預設目錄設置的方式導至 Google Cloud Build 過程中遇到 Google Cloud Build 的錯誤訊息，當時就有回報這個問題 cloudb build gcr.io/k8s-skaffold/pack got invalid cross-device link ERROR with custom buildpack · Issue #135 · GoogleCloudPlatform/buildpacks Create temporary registry cache alongside intended destination by briandealwis · Pull Request #1183 · buildpacks/pack 雖然是使用 GoogleCloudPlatform/buildpacks 中遇到的問題，不過實際上底層也是去呼叫 buildpacks/pack，所以這個 invalid cross-device link 只能等到 pack 發佈 0.19.0 才能解決(當時的 Roadmap 就排定這個版本會包含) 終於 Release pack v0.19.0 · buildpacks/pack 在 19 天前發佈了，我們在 Google Cloud Build 上使用 Pack 來建構 Container image 就不需要使用 workaround 的方式，也可以享受 Google Cloud Build parallel 減少整體執行時間的好處 ","date":"2021-06-17","objectID":"/posts/pack-solved-invalid-cross-device-link-at-google-cloud-build/:0:0","tags":["pack","cloudbuild","buildpacks"],"title":"Pack 0.19.0 Solved Invalid Cross Device Link at Google Cloud Build","uri":"/posts/pack-solved-invalid-cross-device-link-at-google-cloud-build/"},{"categories":null,"content":"Before steps: - name: gcr.io/k8s-skaffold/pack entrypoint: sh env: - TMPDIR=/builder/home/.pack args: - -exc - | pack build --builder=gcr.io/buildpacks/builder:v1 --env=GOOGLE_BUILDABLE=cmd/streamsvc/main.go --descriptor=project-asset.toml 100 pack build --builder=gcr.io/buildpacks/builder:v1 --path=internal/app/apitest 101 - name: gcr.io/k8s-skaffold/pack entrypoint: sh args: - -exc - | pack build --builder=gcr.io/buildpacks/builder:v1 --env=GOOGLE_BUILDABLE=cmd/ws/main.go --descriptor=project-default.toml 200 ","date":"2021-06-17","objectID":"/posts/pack-solved-invalid-cross-device-link-at-google-cloud-build/:0:1","tags":["pack","cloudbuild","buildpacks"],"title":"Pack 0.19.0 Solved Invalid Cross Device Link at Google Cloud Build","uri":"/posts/pack-solved-invalid-cross-device-link-at-google-cloud-build/"},{"categories":null,"content":"After steps: - name: gcr.io/retailbase-dev/pack:v0.19.0 entrypoint: sh args: - -exc - | pack build --builder=gcr.io/buildpacks/builder:v1 --env=GOOGLE_BUILDABLE=cmd/streamsvc/main.go --descriptor=project-asset.toml 100 pack build --builder=gcr.io/buildpacks/builder:v1 --path=internal/app/apitest 101 - name: gcr.io/retailbase-dev/pack:v0.19.0 entrypoint: sh args: - -exc - | pack build --builder=gcr.io/buildpacks/builder:v1 --env=GOOGLE_BUILDABLE=cmd/ws/main.go --descriptor=project-default.toml 200 Pack 0\u0008.19.0 就不需要特別指定 TMPDIR=/builder/home/.pack 參數，這樣我們可以依照需求來配置適合的步驟 gcr.io/k8s-skaffold/pack Skaffold team 維護的 gcr.io/k8s-skaffold/pack 版本還沒有更新至 v0.19.0。gcr.io/k8s-skaffold/pack 0.19.0 support · Issue #6028 · GoogleContainerTools/skaffold，在官方還沒有更新之前大家可以參考 官方的方式自行打包 ","date":"2021-06-17","objectID":"/posts/pack-solved-invalid-cross-device-link-at-google-cloud-build/:0:2","tags":["pack","cloudbuild","buildpacks"],"title":"Pack 0.19.0 Solved Invalid Cross Device Link at Google Cloud Build","uri":"/posts/pack-solved-invalid-cross-device-link-at-google-cloud-build/"},{"categories":null,"content":"在上一篇文章 Ｖelero 初探與實踐中我們看到了作為一個開源的 Kubernetes 集群備份和遷移工具定義了那些 CRD 來達成備份遷移的動作。在之後就對內作了一份簡報基於 Velero 1.6 版本的文件從介紹/安裝/基本使用到 Demo 的實作當中的心得，文篇文章就是簡報的摘要","date":"2021-06-15","objectID":"/posts/velero-research-report/","tags":["velero","restic","kind","minio","gke","kubernetes","rocketchat"],"title":"Velero 初探簡報","uri":"/posts/velero-research-report/"},{"categories":null,"content":" Velero 初探與實踐 - KaiChu Velero 初探與實踐是研究 Velero 的一些心得，及使用 Velero + Restic 進行跨 Provider 遷移集群的原理、注意事項及操作的過程，成功的將 Mac 本地的 KIND k8s 中的 Rocketchat workload 無縫的遷移到 GKE 中，中間的過程還算是簡單方便(如果沒有跨 Provider 有 Cloud Provider 的原生支援會更快速)，算是一個開源友好的集群遷移工具，不過魔鬼總是藏在細節中，官方文件最好是好好的看一看，要了解其中的限制 本份簡報就是基於這個前提之下產生的，在整個 Velero 的研究過程中反饋的心得。從 Velero 介紹/安裝/基本使用方式/實踐。簡報的內容也同時發佈在 Velero search \u0026 practice 20210609，另外再補充幾種 Kubernetes 遷移類型操作的說明 ","date":"2021-06-15","objectID":"/posts/velero-research-report/:0:0","tags":["velero","restic","kind","minio","gke","kubernetes","rocketchat"],"title":"Velero 初探簡報","uri":"/posts/velero-research-report/"},{"categories":null,"content":"Backup from KIND and Restore to KIND Backup from KIND and Restore to KIND KIND 是一個使用 Docker container 在本地跑 Kubernetes 集群的一個決解方案，適合作一些測試用。在我們提到 Velero 備份時包含了二個部份，一是 Kubernetes 範圍內的資源(會 tar 起來儲放在 bucket 中)，另一種就是永久磁碟區 Velero 會備份所有類型的永久磁碟區(hostpath 除外)。我們在本地使用 KIND 部署 Kubernetes 也沒有如雲端供應商一樣有自動永久磁碟區佈建的功能，所以我們必需如上圖所示，手動在 KIND Kuberneretes 中配置本地永久磁碟區(綁定 KIND node) 前置作業完成之後，就可以搭配 Restic + Minio 一起完成在本地 Kuberetes 中對 Rocketchat 備份及復原的操作 ","date":"2021-06-15","objectID":"/posts/velero-research-report/:1:0","tags":["velero","restic","kind","minio","gke","kubernetes","rocketchat"],"title":"Velero 初探簡報","uri":"/posts/velero-research-report/"},{"categories":null,"content":"Backup from GKE and Restore to GKE Backup from GKE and Restore to GKE 雲端供應商提供的 Kubernetes 集群對於永久磁碟區都有自動佈建的功能，所以開發者只需要聲明相關的 PVC 即可，對於三大雲端應商 (AWS, GCP, Azure) 都有 Velero 維護提供對應的 Plugin 及對接說明，且三大雲端應商的 Kubernetes 集群也都有支援原生的永久磁碟區快照功能。如果備份及遷移在同一個雲端供應商的情境，整個操作過程更為輕鬆 ","date":"2021-06-15","objectID":"/posts/velero-research-report/:2:0","tags":["velero","restic","kind","minio","gke","kubernetes","rocketchat"],"title":"Velero 初探簡報","uri":"/posts/velero-research-report/"},{"categories":null,"content":"Migrate KIND to GKE Migrate KIND to GKE 跨供應商的 Velero 備份及遷移情境就會複雜一些。在本地 KIND Kubernetes 集群因為基本的限制就需要使用手動部署本地永久磁碟區 + Restic + Minio。因為 Minio 是 S3 相容的 Object Store 解決方案，就可以使用 s3cmd 將本地 KIND Kubernetes 中的備份檔(Kubernetes metadata/restic persistent volume)下載至本地電腦。在另一個供應商建立新的 Kubernetes 集群復原 Minio 備份(從本地上傳)，再使用 Velero restore 進行 workload 的復原。 以上的操作也可能會因為跨不同的供應商有所不同 ","date":"2021-06-15","objectID":"/posts/velero-research-report/:3:0","tags":["velero","restic","kind","minio","gke","kubernetes","rocketchat"],"title":"Velero 初探簡報","uri":"/posts/velero-research-report/"},{"categories":null,"content":"心得 Backup process 整個初探與實踐都是基於 Velero 1.6 版本的文件來製作完成。跟 Etcd 的備份比較來說，Velero 提供了更細粒度的備份復原功能。基本的操作概念就是上面的備份流程，不過魔鬼總是藏在細節中，實際上還會有效能/\u0008資源配置(cpu/menory)需要詳加考慮的部份，原則上就是要小心服用 ","date":"2021-06-15","objectID":"/posts/velero-research-report/:4:0","tags":["velero","restic","kind","minio","gke","kubernetes","rocketchat"],"title":"Velero 初探簡報","uri":"/posts/velero-research-report/"},{"categories":null,"content":"文篇文章算是研究 Velero 的一些心得，及使用 Velero + Restic 進行跨 Provider 遷移集群的原理、注意事項及操作的過程，成功的將 Mac 本地的 KIND k8s 中的 Rocketchat workload 無縫的遷移到 GKE 中，中間的過程還算是簡單方便(如果沒有跨 Provider 有 Cloud Provider 的原生支援會更快速)，算是一個開源友好的集群遷移工具，不過魔鬼總是藏在細節中，官方文件最好是好好的看一看，要了解其中的限制","date":"2021-06-02","objectID":"/posts/velero-research-practice/","tags":["velero","restic","kind","minio","gke","kubernetes","rocketchat"],"title":"Velero 初探與實踐","uri":"/posts/velero-research-practice/"},{"categories":null,"content":"Velero 是一個開源的 Kubernetes 集群備份和遷移工具 (2019 年初 VMware 完成了對於容器技術廠商 Heptio 的收購後更名為 Velero, 其中的冷知識故事可以至 關於 Heptio 你需要知道的 - VMware 繁體中文部落格 閱讀) ","date":"2021-06-02","objectID":"/posts/velero-research-practice/:0:0","tags":["velero","restic","kind","minio","gke","kubernetes","rocketchat"],"title":"Velero 初探與實踐","uri":"/posts/velero-research-practice/"},{"categories":null,"content":"What is Velero? Velero is an open source tool to safely backup and restore, perform disaster recovery, and migrate Kubernetes cluster resources and persistent volumes Aiming to help with: Disaster Recovery: Recover from an issue Data Migration: Migrate apps between clusters Data Protection: Scheduled Actions ","date":"2021-06-02","objectID":"/posts/velero-research-practice/:1:0","tags":["velero","restic","kind","minio","gke","kubernetes","rocketchat"],"title":"Velero 初探與實踐","uri":"/posts/velero-research-practice/"},{"categories":null,"content":"backup process backup process Velero 的基本操作就是 CLI 會去操作 Kubernetes API 建立 Backup 物件 BackupController 偵測到新的 Backup 物件並檢查 檢查通過後就會操作 Kubernetes API Server 進行資料的備份 BackupController 就會透過 Plugin 會操作對應用 Object Storage Service 上傳檔案 如果 Provider 支援原生的快照操作, Plugin 就可以透過 API 備分永久磁碟區 ","date":"2021-06-02","objectID":"/posts/velero-research-practice/:1:1","tags":["velero","restic","kind","minio","gke","kubernetes","rocketchat"],"title":"Velero 初探與實踐","uri":"/posts/velero-research-practice/"},{"categories":null,"content":"Questions? 圍繞這個備份流程就會衍申很多細節出來，讓我們慢慢的疏理 集群備份到底包含了什麼東西? 集群復原到底包含了什麼東西? 集群遷移可以跨 Cloud provider 嗎? ","date":"2021-06-02","objectID":"/posts/velero-research-practice/:2:0","tags":["velero","restic","kind","minio","gke","kubernetes","rocketchat"],"title":"Velero 初探與實踐","uri":"/posts/velero-research-practice/"},{"categories":null,"content":"集群備份到底包含了什麼東西? backups.velero.io backupstoragelocations.velero.io deletebackuprequests.velero.io downloadrequests.velero.io podvolumebackups.velero.io podvolumerestores.velero.io resticrepositories.velero.io restores.velero.io schedules.velero.io serverstatusrequests.velero.io volumesnapshotlocations.velero.io Velero 所定義的 CRD (Custom Resource Definitions) 來看 backups.velero.io 備份是一種 Velero 資源，表示在某個時間點（API 物件和關聯的磁碟區狀態）捕獲 Kubernetes 集群狀態 對應備份的就是 restores.velero.io，恢復也是一種 Velero 資源，代表從 Velero 備份到目標 Kubernetes 集群的資源應用。 backupstoragelocations.velero.io \u0026 volumesnapshotlocations.velero.io 則是 Velero 儲存備份物件的位置及 Velero 磁碟區快照的位置 schedules.velero.io 表示應該運行的預調度或定期備份 serverstatusrequests.velero.io 是訪問有關 Velero 服務器的當前狀態信息的請求 downloadrequests.velero.io 是從備份物件儲存下載工件的請求，例如備份日誌文件。 備份的分類就 CRD 來看可以分成二塊 一個是 Kubernetes 集群範圍內的資源(pod, service, secret, etc.) 另一個就是磁碟區快照 (預設 Velero 會對任何的永久磁碟區進行磁碟快照，如果 Provider 有原生支援磁碟區快照的話就會透過 Plugin 進行 API 的操作，如果沒有原生支援磁碟區快照時可以啟用 Restic 一起使用，當然 Restic 也是有一些限制, hostPath 類型的磁碟區就沒有支原，不過 Local persistent volumes 是有的，在本地 K8s 集群測試時就可以選用，只是需要手動配置 PV) velero backup describe rocketchat-backup --details ... Resource List: apps/v1/ControllerRevision: - rocketchat/rocketchat-mongodb-arbiter-6d98cfbb59 - rocketchat/rocketchat-mongodb-primary-6fd77d9dd9 - rocketchat/rocketchat-mongodb-secondary-7cd46b58bf apps/v1/Deployment: - rocketchat/rocketchat-rocketchat ... v1/ServiceAccount: - rocketchat/default - rocketchat/rocketchat-rocketchat Velero-Native Snapshots: \u003cnone included\u003e Restic Backups: Completed: rocketchat/rocketchat-mongodb-primary-0: datadir 當備份完成之後我可以用查看備份的詳細資訊，除了 Kubernetes 資源的備份之外，最重要的就是 Restic Backups，列出來相關 Pod 的磁碟區備份的狀態 Velero 適合無狀態的 Workload，如果是有狀態的 Workload 可以搭配 Restic 來進行備份及復原 Tips 如果沒有跨 Provider 的需求且 Provider 有支援原生磁碟區快照，使用 Velero + Velero-Native Snapshots 就可以了 安裝 Velero 預設沒有啟用 Restic，需要特別指定, 備份碟碟區也需要手動指定. 另一種方法是使用 --default-volumes-to-restic 備份所有 Pod 的磁碟區 備份時可以使用 Resource filtering 正面表列或是負面表例來過濾目標物件 (如: namespace, deployments 等等) 備份也可提供了 Pre Hooks 及 Post Hooks 的功能，例如 pre 及 post Hooks 中凍結檔案系統來確保 …. \u0008\u0008雖說我們可以使用 Restic 來備份磁碟區，hostpath 的儲存類型是不支援的，而本地磁碟區(Local Persistent Volume) 是可以的，所以本地測試的 Kubernetes 需要手動配置本地磁碟區使用 Restic 備份才有效 ","date":"2021-06-02","objectID":"/posts/velero-research-practice/:2:1","tags":["velero","restic","kind","minio","gke","kubernetes","rocketchat"],"title":"Velero 初探與實踐","uri":"/posts/velero-research-practice/"},{"categories":null,"content":"集群復原到底包含了什麼東西? 當我們完成了備份可以使用 Velero 指令或是 Velero CRDs 查檢查一下備份的訊息 $ velero backup get NAME STATUS ERRORS WARNINGS CREATED EXPIRES STORAGE LOCATION SELECTOR rocketchat-backup Completed 0 0 2021-06-07 15:43:15 +0800 CST 29d default \u003cnone\u003e $ kubectl get backups.velero.io -n velero NAME AGE rocketchat-backup 17h 我們可以 Restoring Into a Different Namespace 將我們的備份復原至另一個 namespace 復原也是可以使用 Resource filtering 正面表列或是負面表例來過濾目標物件 (如: namespace, deployments 等等) 指定所需的資源進行復原 復原時更改儲存類別的對應 Changing PV/PVC Storage Classes，例如在本地 Kind Kubernetes 的儲存類別為 local-storage 對到 standard (Cloud Provider 有支援永久磁碟區動態佈建預設類別) 復原也跟備份一樣提供 Hooks。 InitContainer Restore Hooks 及 Exec Restore Hooks ","date":"2021-06-02","objectID":"/posts/velero-research-practice/:2:2","tags":["velero","restic","kind","minio","gke","kubernetes","rocketchat"],"title":"Velero 初探與實踐","uri":"/posts/velero-research-practice/"},{"categories":null,"content":"集群遷移可以跨 Cloud provider 嗎? Quote 基本上是可以的. 可以使用 Velero + Restic 來完成 接下來就示範在本地 Kind Kuberntes 部署 rocketchat，透過 Velero 及 Restic 將 Workload 遷移至 GKE 簡單的流程如下: 在本地 Kind Kubernetes 中配置儲存類別為 local-storage 的本地永久磁碟區 (Local Persistent Volume) 在本地 Kind Kubernetes 中建立 rocketchat 有狀態的 Workload 在本地 Kind Kubernetes \u0008中建立 Minio server 透過 Velero 及 Restic 備份相關 Kubernetes 資源及久永磁碟區(Local Persistent Volume) 至 Kind Kubernetes 中的 Minio \u0008S3 Bucket 使用 s3cmd 將 Kind Kubernetes 中的 s3://velero/backups/ s3://velero/restic/ 下載到本地電腦 \u0008backup 目錄 在 GKE 上建立一個 Kubernetes 集群 在 GKE 上安裝 Veleor 及 Restic 設定 使用 s3cmd 將 \u0008backup 目錄上傳至 GKE Kubernetes 集群中 minio S3 bucket 設置 change-storage-class-config 來指定儲存類型的轉換 使用 Velero 復原 rocketchat \u0008workload 等待 Workload 就緒 ","date":"2021-06-02","objectID":"/posts/velero-research-practice/:2:3","tags":["velero","restic","kind","minio","gke","kubernetes","rocketchat"],"title":"Velero 初探與實踐","uri":"/posts/velero-research-practice/"},{"categories":null,"content":"跨 Provider 集群遷移 Demo ","date":"2021-06-02","objectID":"/posts/velero-research-practice/:3:0","tags":["velero","restic","kind","minio","gke","kubernetes","rocketchat"],"title":"Velero 初探與實踐","uri":"/posts/velero-research-practice/"},{"categories":null,"content":"集群遷移的概念 在需要本地 KIND 集群及目標集群 GKE 上都裝上 Velero + Minio Server 使用 Velero + Restic 在本地 KIND 集群執行備份操作，並將備份儲存至集群內部的 Minio Server 使用 s3cmd 同步本地 KIND 集群 Minio Server 中的 s3://velero Bucket 至本機 backup 使用 s3cmd 將本機 backup 同步至目標集群 GKE 上 Minio Server s3://velero Bucket 使用 Velero + Restic 回復 Workload ","date":"2021-06-02","objectID":"/posts/velero-research-practice/:3:1","tags":["velero","restic","kind","minio","gke","kubernetes","rocketchat"],"title":"Velero 初探與實踐","uri":"/posts/velero-research-practice/"},{"categories":null,"content":"注意事項 為了簡化部署 Minio Server 及 Velero 的方式及資源，使用 helm + 減少 cpu/memory 的請求 size vmware-tanzu/helm-charts: Contains Helm charts for Kubernetes related open source tools Helm Charts to deploy Bitnami Object Storage based on MinIO(R) in Kubernetes 使用 s3tools/s3cmd 來同步備份使用的 Bucket ","date":"2021-06-02","objectID":"/posts/velero-research-practice/:3:2","tags":["velero","restic","kind","minio","gke","kubernetes","rocketchat"],"title":"Velero 初探與實踐","uri":"/posts/velero-research-practice/"},{"categories":null,"content":"操作步骤 在本地 KIND 集群進行備份 在本地建立 KIND 集群 cat \u003c\u003cEOF \u003e kind-config.yaml kind: Cluster apiVersion: kind.x-k8s.io/v1alpha4 nodes: - role: control-plane # add a mount from /path/to/my/files on the host to /files on the node extraMounts: - hostPath: /tmp/mnt_disks/ containerPath: /mnt/disks EOF kind create cluster --name rocketchat-migrate-demo --config kind-config.yaml 配置 metallb local Balancer kubectl apply -f https://raw.githubusercontent.com/metallb/metallb/v0.9.6/manifests/namespace.yaml kubectl create secret generic -n metallb-system memberlist --from-literal=secretkey=\"$(openssl rand -base64 128)\" kubectl apply -f https://raw.githubusercontent.com/metallb/metallb/v0.9.6/manifests/metallb.yaml cat \u003c\u003cEOF \u003e metallb-config.yaml apiVersion: v1 kind: ConfigMap metadata: namespace: metallb-system name: config data: config: | address-pools: - name: default protocol: layer2 addresses: - 172.18.0.155-172.18.0.200 EOF kubectl apply -f ./metallb-config.yaml 配置 rocketchat-migrate-demo-control-plane 的磁碟區掛載 連線至 rocketchat-migrate-demo-control-plane node docker exec -it rocketchat-migrate-demo-control-plane bash 在 rocketchat-migrate-demo-control-plane node 建立後序所需的磁碟區 for vol in pv1; do mkdir /mnt/disks/$vol; mount -t tmpfs $vol /mnt/disks/$vol; done 建立 local-storage 儲存類別 cat \u003c\u003cEOF \u003e local-pv-storage.yaml apiVersion: storage.k8s.io/v1 kind: StorageClass metadata: name: local-storage provisioner: kubernetes.io/no-provisioner volumeBindingMode: WaitForFirstConsumer EOF kubectl apply -f local-pv-storage.yaml 手動建立本地久永磁碟區 local-persistent-storage cat \u003c\u003cEOF \u003e local-pv.yaml kind: PersistentVolume apiVersion: v1 metadata: name: local-persistent-storage namespace: rocketchat labels: type: local spec: capacity: storage: 200Mi volumeMode: Filesystem accessModes: - ReadWriteOnce persistentVolumeReclaimPolicy: Delete storageClassName: local-storage local: path: /mnt/disks/pv1 nodeAffinity: required: nodeSelectorTerms: - matchExpressions: - key: kubernetes.io/hostname operator: In values: - rocketchat-migrate-demo-control-plane EOF kubectl apply -f local-pv.yaml 建立 Minio Server cat \u003c\u003cEOF \u003e minio-values.yaml global: minio: accessKey: minio secretKey: minio123 service: type: LoadBalancer defaultBuckets: velero persistence: size: 1G EOF helm install minio --create-namespace --namespace minio -f minio-values.yaml bitnami/minio Minio 建立 Demo rocketchat 應用，直接使用 helm 來部署，在 storageClass 中指定我們自定義的 local-storage cat \u003c\u003cEOF \u003e rocketchat.yaml persistence: enabled: true service: type: LoadBalancer mongodb: mongodbPassword: password mongodbRootPassword: password persistence: storageClass: local-storage size: 200Mi EOF helm install rocketchat --namespace rocketchat --create-namespace -f rocketchat.yaml stable/rocketchat Rocketchat 等待 Workload 就序之，經過初始化的設定，就可以開始使用，我們在 Channel #general 中新增一張圖還有一些文字 建立 Velero，我們一定使用 helm 來簡化部署的流程。在設定檔中指定了 Minio Server 相關的設定，啟用 Restic，還有為了 Demo 減少了 cpu/memory 的請求 Size helm repo add vmware-tanzu https://vmware-tanzu.github.io/helm-chartsk MINIO_SVC=$(kubectl -n minio get svc minio -o=jsonpath=\"{.status.loadBalancer.ingress[0].ip}\") PUBLIC_URL=http://$MINIO_SVC:9000 cat \u003c\u003cEOF \u003e velero-values.yaml configuration: provider: aws backupStorageLocation: bucket: velero config: region: default s3ForcePathStyle: true publicUrl: $PUBLIC_URL s3Url: http://minio.minio.svc.cluster.local:9000 volumeSnapshotLocation: config: region: default credentials: useSecret: true secretContents: cloud: | [default] aws_access_key_id = minio aws_secret_access_key = minio123 configMaps: restic-restore-action-config: labels: velero.io/plugin-config: \"\" velero.io/restic: RestoreItemAction data: image: velero/velero-restic-restore-helper:v1.6.0 deployRestic: true restic: resources: requests: cpu: 250m memory: 256Mi limits: cpu: 500m memory: 512Mi resources: requests: cpu: 250m memory: 128Mi limits: cpu: 500m memory: 512Mi initContainers: - name: velero-plugin-for-aws image: velero/velero-plugin-for-aws:v1.1.0 imagePullPolicy: IfNotPresent volumeMounts: - mountPath: /target name: pl","date":"2021-06-02","objectID":"/posts/velero-research-practice/:3:3","tags":["velero","restic","kind","minio","gke","kubernetes","rocketchat"],"title":"Velero 初探與實踐","uri":"/posts/velero-research-practice/"},{"categories":null,"content":"心得 文篇文章算是研究 Velero 的一些心得，及使用 Velero + Restic 進行跨 Provider 遷移集群的原理、注意事項及操作的過程，成功的將 Mac 本地的 KIND k8s 中的 Rocketchat workload 無縫的遷移到 GKE 中，中間的過程還算是簡單方便(如果沒有跨 Provider 有 Cloud Provider 的原生支援會更快速)，算是一個開源友好的集群遷移工具，不過魔鬼總是藏在細節中，官方文件最好是好好的看一看，要了解其中的限制 完整的 Demo code repo https://github.com/cage1016/velero-research-practice-demo ","date":"2021-06-02","objectID":"/posts/velero-research-practice/:4:0","tags":["velero","restic","kind","minio","gke","kubernetes","rocketchat"],"title":"Velero 初探與實踐","uri":"/posts/velero-research-practice/"},{"categories":null,"content":"Docker for Mac 由於沒有暴露網路給 Host 直接存取，當我們在 Mac 本地使用 Kind 開發 Kubernetes 就算想使用 metallb 來配置 LoadBalancer 也無法使用。docker-tuntap-osx 就是一個在 Docker for Mac 限制之下暫時可行的解決方案，本篇文章記錄一下步驟且用 WordPress 來示範","date":"2021-05-31","objectID":"/posts/docker-tuntap-osx-wordpress/","tags":["kind","docker","metallb","wordpress"],"title":"Docker Tuntap Osx WordPress","uri":"/posts/docker-tuntap-osx-wordpress/"},{"categories":null,"content":"在 MacOS 上開發測試 Kubernetes 相關應用服務時，Kubernets cluster 有幾種選擇 minikube kind Docker Desktop on Mac: 可以在設定中啟用 Kubernets 基本上都可以一定程度的在本地電腦上完成 Kubernets 相關的操作，不過由於 Docker Desktop on Mac 的限制並沒有將 Docker 的網路直接暴露給 Host 來存取，所以我們在本地端存取 Kubernets LoadBalancer type 的 Service 時會有一些不方便 這時候 MetalLB, bare metal load-balancer for Kubernetes 一個透過標準路由協議支援 bare metal 的 LoadBalancer \u0008就上場了，不過這時候還是因為剛剛說的 Docker Desktop on Mac 的硬限制，不支援。不過還有人提供了一些 workground 的方法 christian-posta/docker-tuntap-osx: A tuntap shim installer for “Docker for Mac”，詳細的原理請至 Github Repo 中有說明，此編文章也算是給自己作的筆記 ","date":"2021-05-31","objectID":"/posts/docker-tuntap-osx-wordpress/:0:0","tags":["kind","docker","metallb","wordpress"],"title":"Docker Tuntap Osx WordPress","uri":"/posts/docker-tuntap-osx-wordpress/"},{"categories":null,"content":"Demo 本次會使用到的工具 Docker Desktop on Mac christian-posta/docker-tuntap-osx: A tuntap shim installer for “Docker for Mac” kind MetalLB, bare metal load-balancer for Kubernetes 建立一個 Wordpress 並使用 MetalLB 配置的 IP 來存取 ","date":"2021-05-31","objectID":"/posts/docker-tuntap-osx-wordpress/:1:0","tags":["kind","docker","metallb","wordpress"],"title":"Docker Tuntap Osx WordPress","uri":"/posts/docker-tuntap-osx-wordpress/"},{"categories":null,"content":"Steps 安裝 Docker Desktop on Mac 安裝 tuntap brew install --cask tuntap 退出 Docker for Mac Git clone christian-posta/docker-tuntap-osx repo git clone https://github.com/christian-posta/docker-tuntap-osx 執行 shell 替換 Docker for Mac 的 hyperkit ./sbin/docker_tap_install.sh 檢查 tap 是否存在 ifconfig | grep \"tap\" Tap up ./sbin/docker_tap_up.sh 檢查 tap1 ，這時候應該會配置 IP Address, brona/iproute2mac: CLI wrapper for basic network utilites on Mac OS X inspired with iproute2 on Linux systems - ip command. ip a s | grep tap1 tap1: flags=8843\u003cUP,BROADCAST,RUNNING,SIMPLEX,MULTICAST\u003e mtu 1500 inet 10.0.75.1/30 brd 10.0.75.3 tap1 透過 kind 建立 Kuberneter cluster kind create cluster --name wordpress-demo Add static route: ./create-static-route.sh Install metallab ./install-metallb.sh Install WordPress kubectl apply -f https://gist.githubusercontent.com/cage1016/c2214d24db62d75218eb8bdbe236b93b/raw/3ed124f90f2f5154c393a2224910327c06258395/demo-secret.yaml kubectl apply -f https://gist.githubusercontent.com/cage1016/c2214d24db62d75218eb8bdbe236b93b/raw/3ed124f90f2f5154c393a2224910327c06258395/mysql-deployment.yaml kubectl apply -f https://gist.githubusercontent.com/cage1016/c2214d24db62d75218eb8bdbe236b93b/raw/3ed124f90f2f5154c393a2224910327c06258395/wordpress-deployment.yaml Get Service IP EXTERNAL_IP=$(kubectl get svc wordpress -o jsonpath='{.status.loadBalancer.ingress[0].ip}') echo $EXTERNAL_IP Launch WordPress ","date":"2021-05-31","objectID":"/posts/docker-tuntap-osx-wordpress/:1:1","tags":["kind","docker","metallb","wordpress"],"title":"Docker Tuntap Osx WordPress","uri":"/posts/docker-tuntap-osx-wordpress/"},{"categories":null,"content":"心得 在 Docker for Mac 的硬限制之下，透過 christian-posta/docker-tuntap-osx tuntap 的方式還是可以暫時的在 Mac 系統本地中使用 metallb，不過只要 Docker for Mac 重啟之後就必需重新 tuntap 一次，這個也是麻煩地方 在安全性考量之下，執行 ./sbin/*.sh 還是養成好習慣，檢查一下 Scripts 確認沒問題之後再執行 ","date":"2021-05-31","objectID":"/posts/docker-tuntap-osx-wordpress/:2:0","tags":["kind","docker","metallb","wordpress"],"title":"Docker Tuntap Osx WordPress","uri":"/posts/docker-tuntap-osx-wordpress/"},{"categories":null,"content":"vscode-dev-containers 透過 Container 有良好隔離性的特性來打造開發環境，官方已經提供了很多種開發環境可以直接使用，且這些 dev container 都可以自行修改 Dockerfile 及 devcontainer.json 來進行功能的擴充及參數配置。Google zx 可以讓我們使用 Javascript 來寫 Bash Script。用 devcontainer 來寫 xz scripts 最後用 Pack 建構成 Container image 交付給其他人使用","date":"2021-05-24","objectID":"/posts/devcontainer-zx-pack/","tags":["pack","zx","devcontainer"],"title":"Devcontainer Zx Pack","uri":"/posts/devcontainer-zx-pack/"},{"categories":null,"content":"身為一個開發者有時候會為了準個開發境而煩惱，例如 Golang/Node/Python 會有同時開發不同的版本的需求，雖然有如 gvm, tj/n, pyenv 等等的工具來幫我們來回切換不同的版本及環境，當電腦東西越裝越多難免還是會有打架的時候。microsoft/vscode-dev-containers 這時候就是一個非常好用的工具，最近慢慢感覺到它的方便性 ","date":"2021-05-24","objectID":"/posts/devcontainer-zx-pack/:0:0","tags":["pack","zx","devcontainer"],"title":"Devcontainer Zx Pack","uri":"/posts/devcontainer-zx-pack/"},{"categories":null,"content":"microsoft/vscode-dev-containers A repository of development container definitions for the VS Code Remote - Containers extension and GitHub Codespaces dev containers 是 vscode 的一個 Extension。簡的來說，就是透過 Container 有良好隔離性的特性來打造開發環境\u0008，官方已經提供了很多種開發環境可以直接使用，且這些 dev container 都可以自行修改 Dockerfile, devcontainer.json 來進行功能的擴充及參數配置 Dev Container Configuration Dev Container Status Bar ","date":"2021-05-24","objectID":"/posts/devcontainer-zx-pack/:1:0","tags":["pack","zx","devcontainer"],"title":"Devcontainer Zx Pack","uri":"/posts/devcontainer-zx-pack/"},{"categories":null,"content":"Ex: Hugo \"name\": \"Hugo (Community)\", \"build\": { \"dockerfile\": \"Dockerfile\", \"args\": { // Update VARIANT to pick hugo variant. // Example variants: hugo, hugo_extended // Rebuild the container if it already exists to update. \"VARIANT\": \"hugo_extended\", // Update VERSION to pick a specific hugo version. // Example versions: latest, 0.73.0, 0,71.1 // Rebuild the container if it already exists to update. \"VERSION\": \"latest\", // Update NODE_VERSION to pick the Node.js version: 12, 14 \"NODE_VERSION\": \"14\", } }, 使用 Hugo 編寫 Blog 文章的人可以直接使用，如果需要使用 hugo_extended 的版本，直接在 .devcontainer.json 中進行置，再點選 Rebuild Coontainer 就好了 ","date":"2021-05-24","objectID":"/posts/devcontainer-zx-pack/:1:1","tags":["pack","zx","devcontainer"],"title":"Devcontainer Zx Pack","uri":"/posts/devcontainer-zx-pack/"},{"categories":null,"content":"Ex: GitHub Codespaces (Default Linux Universal) Use or extend the new Ubuntu-based default, large, multi-language universal container for GitHub Codespaces 另一個我覺得非常好用的是 GitHub Codespaces (Default Linux Universal) Metadata Value Contributors The GitHub Codespaces team Categories Services, GitHub Definition type Dockerfile Published image mcr.microsoft.com/vscode/devcontainers/universal:linux mcr.microsoft.com/vscode/devcontainers/universal:focal Published image architecture(s) x86-64 Works in Codespaces Yes Container host OS support Linux, macOS, Windows Container OS Ubuntu Languages, platforms Python, Node.js, JavaScript, TypeScript, C++, Java, C#, F#, .NET Core, PHP, PowerShell, Go, Ruby, Rust 這一個 devcontainer base Image 跟 Github Codespaces 是一樣的。我們常用的 Kubectl, helm 等等工具都已經包好了，直接使用非常的方便，唯一的缺點就是 Container image 比較大，大約 10GB 😂 ","date":"2021-05-24","objectID":"/posts/devcontainer-zx-pack/:1:2","tags":["pack","zx","devcontainer"],"title":"Devcontainer Zx Pack","uri":"/posts/devcontainer-zx-pack/"},{"categories":null,"content":"Google/xz google/zx: A tool for writing better scripts #!/usr/bin/env zx await $`cat package.json | grep name` let branch = await $`git branch --show-current` await $`dep deploy --branch=${branch}` await Promise.all([ $`sleep 1; echo 1`, $`sleep 2; echo 2`, $`sleep 3; echo 3`, ]) let name = 'foo bar' await $`mkdir /tmp/${name}` 簡的來說就是 Bash Script 的加強版，可以使用 Javascript 來寫 Script, await 用一波 ","date":"2021-05-24","objectID":"/posts/devcontainer-zx-pack/:2:0","tags":["pack","zx","devcontainer"],"title":"Devcontainer Zx Pack","uri":"/posts/devcontainer-zx-pack/"},{"categories":null,"content":"devcontainer-zx-pack-devmo microsoft/vscode-dev-containers: A repository of development container definitions for the VS Code Remote - Containers extension and GitHub Codespaces google/zx: A tool for writing better scripts GoogleCloudPlatform/buildpacks: Builders and buildpacks designed to run on Google Cloud’s container platforms 上面二節簡單的介紹了 microsoft/vscode-dev-containers \u0026 google/zx。二個東西加起來就是在 Container 裡面開發 Bash Script 最近有一個需求就非常適合的使用 microsoft/vscode-dev-containers \u0026 google/zx 且利用 Pack 建構 Container image 最終交給 Kubernetes cornjob 執行 在 backend API service 運維時期，Opertion 交求提供一份 Script 給 cron job 執行來確定 API 服務是否在可服務狀態。這一個題目就非常適合透過這樣的組合來完成，使用 Javascript 比純 Bash 來的容易編寫 在建構 Container image 時，我們使用 pack + GoogleCloudPlatform/buildpacks \u0008builder 輕鬆完成建構 Container image 準備 run.mjs #!/usr/bin/env zx let resp = await fetch('http://wttr.in') if (resp.ok) { console.log(await resp.text()) } 建構 Container image pack build --builder=gcr.io/buildpacks/builder xz-run -p . 執行 Container image pack build --rm xz-run http://wttr.in ","date":"2021-05-24","objectID":"/posts/devcontainer-zx-pack/:3:0","tags":["pack","zx","devcontainer"],"title":"Devcontainer Zx Pack","uri":"/posts/devcontainer-zx-pack/"},{"categories":null,"content":"Repo https://github.com/cage1016/devcontainer-zx-pack-devmo ","date":"2021-05-24","objectID":"/posts/devcontainer-zx-pack/:3:1","tags":["pack","zx","devcontainer"],"title":"Devcontainer Zx Pack","uri":"/posts/devcontainer-zx-pack/"},{"categories":null,"content":"在 Kubernetes Pod 的生命周期中我們可以使用 `livenessProbe` 及 `readinessProbe` 探針來檢查服務健康，本篇文章簡單介紹了如何為 GRPC Service / Client 對應 `grpc_health_probe` 的配置設定及服務健康的檢查，最後使用 buildpack 建構所需 container image 含動態下載 Github `grpc_health_probe` Assets","date":"2021-05-13","objectID":"/posts/build-kubernetes-grpc-health-probe-with-pack/","tags":["kubernetes","grpc","pack"],"title":"Build Kuberntes GRPC Health Probe with Pack","uri":"/posts/build-kubernetes-grpc-health-probe-with-pack/"},{"categories":null,"content":" Kuberntes Pod 生命周期 在 Kubernetes Pod 完整的生命周期包含了三個部份: Iinit container Pod Hook 健康檢查。這三部都會影響到 Pod 的生命周期，而本篇文章說明如何使用 pack 打包 grpc-health-probe 來支援 GRPC 健康檢查 ","date":"2021-05-13","objectID":"/posts/build-kubernetes-grpc-health-probe-with-pack/:0:0","tags":["kubernetes","grpc","pack"],"title":"Build Kuberntes GRPC Health Probe with Pack","uri":"/posts/build-kubernetes-grpc-health-probe-with-pack/"},{"categories":null,"content":"Kubernetes livenessProbe \u0026 readinessProbe Configure Liveness, Readiness and Startup Probes | Kubernetes 在 Kubernetes cluster 中我們可以通過配置 livenessProbe 及 readinessProbe 二個探針來影響容器的生命周期 livenessProbe: 簡單的來說就是 Kubectl 通過 livenessProbe 來判斷容器是否存活 (Running)，如果 livenessProbe 探針偵測到容器不健康，Kubectl 就會刪除容器，並依據容器的重啟策略來處理，如果容器不包含 livenessProbe 探針，Kubectl 預設就會認定 livenessProbe 探針回傳值永遠為 Success readinessProbe: 簡單的來說就是 Kubectl 通過 livenessProbe 來判斷容器的可用性 (Ready)，只有 Pod 下面所有容器的狀態都是就緒時，Kubectl 才會認定該 Pod 已經處於可工作狀態。如果該 Pod 執行過期中 Ready 狀態變成 False，系統會將其從 Service 的後端 Endpoints 列表中移除，等待 Pod Ready 狀態再度成為 True 時加為 Service Endpoints 列表，這樣可以確認流量不會被導至不可用的 Pod 在配置 livenessProbe 及 readinessProbe 都有三種指定方式 ExecAction: 在容器中執行指令，回傳值為 0 表示健康 TCPSocketAction: 透過容器的 IP 及 Port 進行檢查，如果可以建立 TCP 連線表示健康 HTTPGetAction: 透過容器的 IP 及 Port 進行 HTTP GET 檢查，如果回傳狀態碼介於 200 - 400 表示健康 ","date":"2021-05-13","objectID":"/posts/build-kubernetes-grpc-health-probe-with-pack/:0:1","tags":["kubernetes","grpc","pack"],"title":"Build Kuberntes GRPC Health Probe with Pack","uri":"/posts/build-kubernetes-grpc-health-probe-with-pack/"},{"categories":null,"content":"Health checking gRPC servers on Kubernetes grpc_health_probe (ref: https://kubernetes.io/blog/2018/10/01/health-checking-grpc-servers-on-kubernetes/) 本篇文章因為要檢查 GRPC 服務是否健康，則屬於第一種 ExecAction 的範籌。Health checking gRPC servers on Kubernetes | Kubernetes 文章也說明如何使用 grpc-health-probe 工具來檢查 GRPC 是否健康 在 Pod 中我們可以配置 readinessProbe 及 livenessProbe spec: containers: - name: server image: \"[YOUR-DOCKER-IMAGE]\" ports: - containerPort: 10021 readinessProbe: exec: command: [\"/layers/cage1016_github-assets-cnb/github-assets/bin/grpc_health_probe\", \"-addr=:10021\"] initialDelaySeconds: 5 periodSeconds: 10 livenessProbe: exec: command: [\"/layers/cage1016_github-assets-cnb/github-assets/bin/grpc_health_probe\", \"-addr=:10021\"] initialDelaySeconds: 10 periodSeconds: 20 在 exec ommand 中 grpc_health_probe \u0008的執行檔是 /layers/cage1016_github-assets-cnb/github-assets/bin/grpc_health_probe 而非 grpc-health-probe 中看到的 /bin/grpc_health_probe 則是本篇的重點，我們慢慢說明 GPRC Server 健康檢查準備 // HealthServer is the server API for Health service. type HealthServer interface { // If the requested service is unknown, the call will fail with status // NOT_FOUND. Check(context.Context, *HealthCheckRequest) (*HealthCheckResponse, error) // Performs a watch for the serving status of the requested service. // The server will immediately send back a message indicating the current // serving status. It will then subsequently send a new message whenever // the service's serving status changes. // // If the requested service is unknown when the call is received, the // server will send a message setting the serving status to // SERVICE_UNKNOWN but will *not* terminate the call. If at some // future point, the serving status of the service becomes known, the // server will send a new message with the service's serving status. // // If the call terminates with status UNIMPLEMENTED, then clients // should assume this method is not supported and should not retry the // call. If the call terminates with any other status (including OK), // clients should retry the call with appropriate exponential backoff. Watch(*HealthCheckRequest, Health_WatchServer) error } 在要使用 grpc_health_probe 來檢查 GRCP 狀態是否健康，在 Server 端也需要進行一些配合，實作二個方法 Check 及 Watch // imports \"google.golang.org/grpc/health\" healthgrpc \"google.golang.org/grpc/health/grpc_health_v1\" // health server hs := health.NewServer() hs.SetServingStatus(cfg.ServiceName, healthgrpc.HealthCheckResponse_SERVING) // register healdh grpc server server = grpc.NewServer(grpc.UnaryInterceptor(kitgrpc.Interceptor)) healthgrpc.RegisterHealthServer(server, hs) 我們直接使用 google.golang.org/grpc/health \u0008提供的方法進行配置就可以快速完成 GRPC Server 端的準備工具，詳細的程式碼可以至 cage1016/ms-demo/cmd/add/main.go#L76-L77 及 cage1016/ms-demo/cmd/add/main.go#L190-L192 GPRC client 健康檢查準備 grpc-ecosystem/grpc-health-probe: A command-line tool to perform health-checks for gRPC applications in Kubernetes etc. grpc_health_probe -addr=localhost:5000 healthy: SERVING 在 local 的部份可以下載 grpc_health_probe 進行測試 建構 Container Image 本篇文章的重點就是如何使用 Pack 來建構含有 grpc_health_probe 功能的 container image 方法一 Dockerfile FROM gcr.io/gcp-runtimes/go1-builder:1.14 AS builder WORKDIR /src # restore dependencies COPY go.mod go.sum ./ RUN go mod download COPY . . RUN go build -gcflags='-N -l' -o /exe cmd/add/main.go # Adding the grpc_health_probe RUN GRPC_HEALTH_PROBE_VERSION=v0.3.2 \u0026\u0026 \\ wget -qO/bin/grpc_health_probe https://github.com/grpc-ecosystem/grpc-health-probe/releases/download/${GRPC_HEALTH_PROBE_VERSION}/grpc_health_probe-linux-amd64 \u0026\u0026 \\ chmod +x /bin/grpc_health_probe FROM gcr.io/distroless/base:latest COPY --from=builder /exe . COPY --from=builder /bin/grpc_health_probe ./grpc_health_probe ENTRYPOINT [\"/exe\"] 在建構 Container image 時下載 grpc_health_probe 執行檔至 /bin/grpc_health_probe，所以在 Kubernetes Pod livenessProbe 及 readinessProbe 中的 command 才會是 command: [\"/grpc_health_probe\", \"-addr=:5000\"] 在之前的文章 Github Assets Cnb ｜ KaiChu Build Your Buildpack ｜ KaiChu Buildpack Tips and Tricks ｜ KaiChu 都有分享使用 Pack 來建構 container image。那我們如何使用 P","date":"2021-05-13","objectID":"/posts/build-kubernetes-grpc-health-probe-with-pack/:0:2","tags":["kubernetes","grpc","pack"],"title":"Build Kuberntes GRPC Health Probe with Pack","uri":"/posts/build-kubernetes-grpc-health-probe-with-pack/"},{"categories":null,"content":"心得 在 Dockerfile 中使用 wget 動態去下載所需要的檔案算是一種常規的作法。反之在 buildapck 的架構之下要下載一個檔案卻有一點複雜，也是常常有需要下載 Github Assets 的剛性需求，特別寫了一個符合 Cloud Native Buildpack 的 cage1016/github-assets-cnb buildpack 來滿足這個需求，當這一個生態越來越豐富時，就會慢慢感覺像是在疊責木一樣 如同 cage1016/ms-demo 這個 gokit microserives demo 一樣，Add 及 Tictac 服務基本上都改用 pack 來建構 container image，為了在 Kubernetes Pod 新增 livenessProbe 及 readinessProbe 探針並使用 grpc_health_probe 來檢查 GRPC 服務的健康狀況，其實就是新增了 project.toml cat \u003c\u003cEOF \u003e\u003e project.toml # [[build.env]] # optional, github token for private assets # name = \"TOKEN\" # value = \"\u003cgithub-token\u003e\" # skaffold [[build.env]] # required name = \"REPO\" value = \"grpc-ecosystem/grpc-health-probe\" [[build.env]] # required name = \"FILE\" value = \"grpc_health_probe-linux-amd64\" [[build.env]] # optional, default set to FILE value name = \"TARGET\" value = \"grpc_health_probe\" # [[build.env]] # # optional, default set to 'latest' # name = \"VERSION\" # value = \"v1.22.0\" EOF 及 ... ports: - containerPort: 10021 readinessProbe: exec: command: [\"/layers/cage1016_github-assets-cnb/grpc-ecosystem_grpc-health-prob/bin/grpc_health_probe\", \"-addr=:10021\"] initialDelaySeconds: 5 livenessProbe: exec: command: [\"/layers/cage1016_github-assets-cnb/grpc-ecosystem_grpc-health-prob/bin/grpc_health_probe\", \"-addr=:10021\"] initialDelaySeconds: 10 ... 剩下的都不用動，P\u0008ack 就會操作 builder 按照所載入的 buildpack 完成對應的動作。慢慢體會這種抽換的方便性 ","date":"2021-05-13","objectID":"/posts/build-kubernetes-grpc-health-probe-with-pack/:0:3","tags":["kubernetes","grpc","pack"],"title":"Build Kuberntes GRPC Health Probe with Pack","uri":"/posts/build-kubernetes-grpc-health-probe-with-pack/"},{"categories":null,"content":"記錄了如何將整理 Github 公用帳號列表及成員的簡單服務從 GAE cron job 搬到 Github Actions 的使用方式","date":"2021-05-07","objectID":"/posts/github-script-repos-and-collaborators-list-sync/","tags":["github","actions"],"title":"Github Script Repos and Collaborators List Sync","uri":"/posts/github-script-repos-and-collaborators-list-sync/"},{"categories":null,"content":" Google Spreadsheet Github Markdown 在 2018 年時為了公用帳號有一個 Github repostiories \u0026 collaborators 列表的需求，還特別在 GAE 上用 Golang 寫了一個服務並啟用 cron job cron.yaml cron: - description: \"Sync Github Repo\" url: /sync schedule: every 1 hours from 00:00 to 23:59 timezone: Asia/Taipei 每一個小時用 Golang 呼叫 Github Graphql 取回來所有 Repo 列表，最後透過 Spreadsheet API 寫到特定的 Spreadsheet 中 需要開一個 Google Platform Platfrom 專案 部署 GAE 應用程式 Golang 呼叫 Github Graphql 取資料 Spreadsheet API 回寫資料 一這波操作下來是沒花到什麼錢啦，就是麻煩了一些，本來這個小東西跑的也好好的，最近最近人員的異動導至需要重新 review 大家的權限，Github 在 2019/11/3 正式推出了 Github Action，自己滿多 Repo 也早就在使用了，所以想說上述的需撾用 Github Action 重新實作會更來的容易些，事實上真的很方更，每一次 Action 的執行時間都不到 30 秒，就是快 在重構的時候也發現了許多非常棒的工具，也因此特別寫一篇文章來記錄一下 GitHub GraphQL API: Github Graphql Playground grpchql nektos/act: Run your GitHub Actions locally 🚀: 不得不提這一個工具，可以在本地端開發測試 Github Action，本地就可以開發就是方便 act demo (pic https://github.com/nektos/act) actions/github-script: Write workflows scripting the GitHub API in JavaScript: 在寫 Github Action workflows scripts 時可以直接用 Javascript 呼到 Github API，包好了直接用方便 jobs: readme: runs-on: ubuntu-latest steps: - run: npm install tablemark - uses: actions/github-script@v4 id: repository_collaborators with: github-token: ${{ secrets.REPO_TOKEN }} script: | const query = `query($endCursor: String = null) { viewer { repositories(first: 100, after: $endCursor, affiliations: [OWNER], orderBy: {field: CREATED_AT, direction: DESC}) { totalCount pageInfo { endCursor hasNextPage } nodes { name createdAt url } } } }`; const request = { owner: context.repo.owner, repo: context.repo.repo } const {data:collaboratorsData} = (await github.repos.getContent({ ...request, path: 'collaborators.txt' })); github.repos.getContent Github API 直接封裝起來用一波 qeek-dev/github-project-sync: sync github projects \u0026 collaborators: Octokit plugin adding one method for all of api.github.com REST API endpoints 這個網站提供了 API endpoints 的文件可以查詢 EX: octokit.rest.repos.getContent({ owner, repo, path, }); ","date":"2021-05-07","objectID":"/posts/github-script-repos-and-collaborators-list-sync/:0:0","tags":["github","actions"],"title":"Github Script Repos and Collaborators List Sync","uri":"/posts/github-script-repos-and-collaborators-list-sync/"},{"categories":null,"content":".github/workflows/cron.yml 基本的流程如下 Github Graphql 取回所有的 repos \u0026 collaborators, 需要 github-token: ${{ secrets.REPO_TOKEN }} 準備 md 所需的資料 使用 tablemark library 將 Array 轉換為 markdown if (Buffer.from(data.content, 'base64').compare(Buffer.from(result)) === 0) return，比對新舊 README.md 檔案是否一致，不一樣才需要更新 Buffer.from(data.content, 'base64').toString()，如果需要取出 github.repos.getContent 中的值需要進行轉 base64 轉換 ","date":"2021-05-07","objectID":"/posts/github-script-repos-and-collaborators-list-sync/:0:1","tags":["github","actions"],"title":"Github Script Repos and Collaborators List Sync","uri":"/posts/github-script-repos-and-collaborators-list-sync/"},{"categories":null,"content":"心得 如果專案放在 Github 上，Github action 真的可以作滿多事情的。GitHub Marketplace 也有非常多的資源可以用，不知道怎麼寫的話可以去援尋原始碼，真的推薦可以使用 ","date":"2021-05-07","objectID":"/posts/github-script-repos-and-collaborators-list-sync/:0:2","tags":["github","actions"],"title":"Github Script Repos and Collaborators List Sync","uri":"/posts/github-script-repos-and-collaborators-list-sync/"},{"categories":null,"content":"telepresence 是一個有效提升多微服務中連結本地開發的一個好用工具，它解決了 Skaffold 開發中本地 deubg 的不足，期待 GA 的到來","date":"2021-05-04","objectID":"/posts/telepresence-2-have-a-tried/","tags":["telepresence","debug","microservices","kubernetes"],"title":"Telepresence 2 Have a Tried","uri":"/posts/telepresence-2-have-a-tried/"},{"categories":null,"content":"在開發 Kuberentes 應用程式時使用 Skaffold 應該是基本操作了，Skaffold 可以幫忙加速開發的速度 (修改程式碼 → 構建 container image → push container image to registry (optional) → 部署至 Kubernets Cluster)，至於是否搭配 Helm 還是直接操作 yaml 就看個人喜好來決定 在 Debug 部份，Skaffold 也支援 Remote container debug 的功能 (之前的文章請參照 Skaffold debug goland)。雖然 Skaffold debug 很方便，不過當 Kubernetes 的應用一多時就沒有辦法在本機端完整的重現有所的服務，這時候開源的 Telepresence 就是一個很好的幫手 ","date":"2021-05-04","objectID":"/posts/telepresence-2-have-a-tried/:0:0","tags":["telepresence","debug","microservices","kubernetes"],"title":"Telepresence 2 Have a Tried","uri":"/posts/telepresence-2-have-a-tried/"},{"categories":null,"content":"Telepresence Local development against a remote Kubernetes or OpenShift cluster ** Note: Telepresence 1 is being replaced by our even better Telepresence 2. Please try Telepresence 2 first and report any issues as we expect this will be the default by Q2 2021. ** telepresence architecture (ref: https://www.getambassador.io/docs/telepresence/latest/reference/architecture/) (這邊以 Telepresence 2 為主) 基本上來說 Telepresence 透過 Traffic agent 將所有目標服務的流量/特定 header(“x-telepresence-intercept-id”) 請求重導至本機中，這樣我們就針對單一服務進行快速的進行開發，同時地機端如果也連接至 Kubernets Cluster 其他的資源也是相通的 telepresence version Client v2.2.1 (api v3) Daemon v2.2.0 (api v3) Usage: telepresence [command] Available Commands: Session Commands: connect Connect to a cluster login Authenticate to Ambassador Cloud logout Logout from Ambassador Cloud license Get License from Ambassador Cloud status Show connectivity status quit Tell telepresence daemon to quit Traffic Commands: list List current intercepts intercept Intercept a service leave Remove existing intercept preview Create or remove preview domains for existing intercepts Other Commands: version Show version uninstall Uninstall telepresence agents and manager dashboard Open the dashboard in a web page current-cluster-id Get cluster ID for your kubernetes cluster Telepresence 1.0 跟 2.0 差異很大，2.0 是以 Golang 重新改寫，官方也建議從 2.0 開始，不過 2.0 目前還沒有完全開發完成 NAMESPACE NAME READY STATUS RESTARTS AGE ambassador traffic-manager-78f4f95c7d-z62lm 1/1 Running 1 33h 第一次操作 Telepresence，會在 Kubernets 中建立 traffic-manager, Traffic-manager 是 Telepresence 2.0 的核心組件也是負責本地 Telepresence Demaons 及目標 Pod 中 Traffice Agent 的溝通 kubectl delete svc,deploy -n ambassador traffic-manager 必要的時候可以進行刪除，下一次 Telepresence 重新連線的時候會重建 ","date":"2021-05-04","objectID":"/posts/telepresence-2-have-a-tried/:0:1","tags":["telepresence","debug","microservices","kubernetes"],"title":"Telepresence 2 Have a Tried","uri":"/posts/telepresence-2-have-a-tried/"},{"categories":null,"content":"cage1016/ms-demo gokit microservice demo 接下來 Demo 就以 cage1016/ms-demo 中的 gokit microservice demo 來進行操作 Service Method Description add Sum Expose Sum(a,b) method tictac Tic Expose Tic method (incrase value by Add Sum GRPC ) tictac Tac Expose Tac method (recive value) gokit microservice demo architecture all TCP connections 準個一個可用的 K8s cluster，我們這邊使用 Mac docker-desktop 的 k8s cluster 部署 cage1016/ms-demo: gokit microservice demo Add, Tictac 微服務 kubectl apply -f https://raw.githubusercontent.com/cage1016/ms-demo/master/deployments/kubernetes-manifests-all.yaml kubectl get po NAME READY STATUS RESTARTS AGE add-68b7f4b486-cqf4m 1/1 Running 0 17m tictac-85f698c88f-cw6mg 2/2 Running 1 17m Expose service，這邊使用的方式為 LoadBalancer kubectl apply -f https://raw.githubusercontent.com/cage1016/ms-demo/master/deployments/lb-all.yaml kubectl get svc NAME TYPE CLUSTER-IP EXTERNAL-IP PORT(S) AGE add ClusterIP 10.97.120.99 \u003cnone\u003e 80/TCP,8000/TCP 18m add-external LoadBalancer 10.101.69.142 localhost 8180:31605/TCP,8181:32609/TCP 5m57s kubernetes ClusterIP 10.96.0.1 \u003cnone\u003e 443/TCP 5d5h tictac ClusterIP 10.96.191.66 \u003cnone\u003e 80/TCP,8000/TCP 18m tictac-external LoadBalancer 10.100.63.131 localhost 9190:30349/TCP,9191:30063/TCP 5m57s 設定攔截器，intercept Add service name grpc 至本機中 10121 (GRPC) service，等待指令完成後中顯示會攔截 add service 所有流量至 127.0.0.1:10121 telepresence intercept add --service add --port 10121:grpc Using Deployment add intercepted Intercept name : add State : ACTIVE Workload kind : Deployment Destination : 127.0.0.1:10121 Service Port Identifier: grpc Volume Mount Error : macFUSE 4.0.5 or higher is required on your local machine Intercepting : all TCP connections 這時候我們可以看到 add Pod 中已經被置入 traffic-agent kubectl iexec add Use the arrow keys to navigate: ↓ ↑ → ← ? Select Container: Container: ▸ add Container: traffic-agent 在 cage1016/ms-demo 中進行 Debug，VSCode 中 lanuch.json 加入 Debug 設定後執行 { \"configurations\": [ { \"name\": \"add\", \"type\": \"go\", \"request\": \"launch\", \"mode\": \"auto\", \"program\": \"${workspaceFolder}/cmd/add\", \"env\": { \"QS_LOG_LEVEL\": \"info\", \"QS_HTTP_PORT\": \"10120\", \"QS_GRPC_PORT\": \"10121\", } }, ] } debug 設定 Add 服務中斷點 debug 獲取 Tictac 服務的 URL TICTAC_HTTP_EXTERNAL_PORT=$(kubectl get service tictac-external -o jsonpath='{.spec.ports[?(@.name==\"http\")].port}') TICTAC_EXTERNAL_HOST=$(kubectl get service tictac-external -o jsonpath='{.status.loadBalancer.ingress[0].hostname}') # TICTAC_EXTERNAL_HOST=$(kubectl get service tictac-external -o jsonpath='{.status.loadBalancer.ingress[0].ip}') # unmark if necessary TICTAC_HTTP_EXTERNAL_URL=$TICTAC_EXTERNAL_HOST:$TICTAC_HTTP_EXTERNAL_PORT echo $TICTAC_HTTP_EXTERNAL_URL 使用 curl 進行請求 curl -X POST $TICTAC_HTTP_EXTERNAL_URL/tic VSCode 中執行中的 Add service 會成功攔截至流量並停在我們設置的中斷點中 debug header(“x-telepresence-intercept-id”) Telepresence 除了全流量的攔截之外也支援特定的請求，基本上的操作步驟是一樣的，差異的部份需要先進行 Telepresence login 進行 Telepresence login Telepresence login (Optional)，如果已經跑過一次 intercept，記得先退出當前的 intercept Telepresence leave add 一樣進行設定攔截器的配置並加上 --preview-url=false，我們並不需在 Ambassador 上產生 preview url 需要 Telepresence login 操作 intercept 才會有特定請求，不然怎麼操作都會是 all TCP connections telepresence intercept add --service add --port 10121:grpc --preview-url=false Using Deployment add intercepted Intercept name : add State : ACTIVE Workload kind : Deployment Destination : 127.0.0.1:10121 Service Port Identifier: grpc Volume Mount Error : macFUSE 4.0.5 or higher is required on your local machine Intercepting : HTTP requests that match all of: header(\"x-telepresence-intercept-id\") ~= regexp(\"5b771ea3-8f6a-4be1-82f3-675aa1e28840:add\") 這時候再使用 curl 進行請求並加上特定的 (x-telepresence-intercept-id) 才會進行攔截，沒有加上 Header 的請求反之不理 curl -H 'x-telepresence-intercept-id: 5b771ea3-8f6a-4be1-82f3-675aa1e28840:add' -X POST $TICTAC_HTTP_EXTERNAL_URL/tic VSCode 攔截特定請求 這邊一個成功的因素是 tictac tic 呼叫 add sum GRPC 時一同把 header 的 x-telepresence-intercept-id 加到 context 才可以 debug ","date":"2021-05-04","objectID":"/posts/telepresence-2-have-a-tried/:0:2","tags":["telepresence","debug","microservices","kubernetes"],"title":"Telepresence 2 Have a Tried","uri":"/posts/telepresence-2-have-a-tried/"},{"categories":null,"content":"結論 Teleresence 2 可以有效的降低多個微服務的 debug 體驗，只攔截特定請求更是方便，不需要擔心把微服務咬死，不過目前開發還在進行中，Github community 回報的 issue 還是不少，還是值得一玩。大家可以至 cage1016/ms-demo: gokit microservice demo 中 clone 有所的程式照著操作看看體驗看看 ","date":"2021-05-04","objectID":"/posts/telepresence-2-have-a-tried/:0:3","tags":["telepresence","debug","microservices","kubernetes"],"title":"Telepresence 2 Have a Tried","uri":"/posts/telepresence-2-have-a-tried/"},{"categories":null,"content":"在構建 container image 時，有時候會有需求動態下載 Github repo 中的 Assets 檔案，簡單的方式就是在 `dockerfile` 透過 `curl` 指令來獲取檔案，本篇文章則透過 paketo-buildpacks/packit 來實作一個可以下載 Github Assets 的 buildpack cage1016/github-assets-cnb","date":"2021-04-20","objectID":"/posts/github-assets-cnb/","tags":["buildpacks","gcp","pack","github","paketo"],"title":"Github Assets Cnb","uri":"/posts/github-assets-cnb/"},{"categories":null,"content":" Github Asset Cnb 在構建 container image 時，有時候會有需求動態下載 Github repo 中的 Assets 檔案，簡單的方式就是在 dockerfile 透過 curl 指令來獲取檔案，如果是 private repo 時另外配置 TOKEN 即可 dockerfile ARG GITHUB_TOKEN=\u003cgithub-token\u003e ARG REPO=qeek-dev/apitest-toolchain ARG FILE=apitest-toolchain-linux-amd64 ARG VERSION=v0.1.0 ARG TARGET=apitest-toolchain RUN ASSET_ID=$(if [ $VERSION != \"latest\" ]; then \\ echo $(curl -H \"Authorization: token $GITHUB_TOKEN\" -H \"Accept: application/vnd.github.v3.raw\" -s https://api.github.com/repos/$REPO/releases | jq \". | map(select(.VERSION == \\\"$VERSION\\\"))[0].assets | map(select(.name == \\\"$FILE\\\"))[0].id\"); \\ else\\ echo $(curl -H \"Authorization: token $GITHUB_TOKEN\" -H \"Accept: application/vnd.github.v3.raw\" -s https://api.github.com/repos/$REPO/releases | jq \".[0].assets | map(select(.name == \\\"$FILE\\\"))[0].id\"); \\ fi) \\ \u0026\u0026 curl -vLJo /tmp/$TARGET -H 'Accept: application/octet-stream' \"https://$GITHUB_TOKEN:@api.github.com/repos/$REPO/releases/assets/$ASSET_ID\" \\ \u0026\u0026 chmod +x /tmp/$TARGET \u0026\u0026 mv /tmp/$TARGET /bin 上述 dockerfile 可以分成二個部份 透過 Github API 獲取對應 Asset ID 透過 curl 下載對應 Asset ID 的實體檔案 也因為自己有這一個需求，所以 cage1016/github-assets-cnb 這一個 Buildapck 的專案就出現了 ","date":"2021-04-20","objectID":"/posts/github-assets-cnb/:0:0","tags":["buildpacks","gcp","pack","github","paketo"],"title":"Github Assets Cnb","uri":"/posts/github-assets-cnb/"},{"categories":null,"content":"cage1016/github-assets-cnb A Cloud Native Buildpack that Download Github Assets 基本上這一個 buildpack 就是透過 paketo-buildpacks/packit 這一個 Buildpacks Utils Library 來實作，一定程度減輕了對 buildpacks/spec 有點麻煩的規範 例如 github.com/paketo-buildpacks/packit/cargo: 有提供對 metadata.dependencies 操作的函式 github.com/paketo-buildpacks/packit/postal: 有提供 Drop 可以直接透過 http 來下載檔案 Usage Create a folder mkdir -p sample-app create project.toml, 這邊以下載 skaffold 為例，如果 Github Asset 是屬於 private repo，配置加上 TOKEN 即可 cat \u003c\u003cEOF \u003e\u003e sample-app/project.toml # [[build.env]] # optional, github token for private assets # name = \"TOKEN\" # value = \"\u003cgithub-token\u003e\" # skaffold [[build.env]] # required name = \"REPO\" value = \"GoogleContainerTools/skaffold\" [[build.env]] # required name = \"FILE\" value = \"skaffold-linux-amd64\" [[build.env]] # optional, default set to FILE value name = \"TARGET\" value = \"skaffold\" [[build.env]] # optional, default set to 'latest' name = \"VERSION\" value = \"v1.22.0\" EOF build container image with buildpack pack build test_assets_run --path ./sample-app \\ -b cage1016/github-assets-cnb@1.0.0 \\ --builder gcr.io/buildpacks/builder:v1 \\ \u0026\u0026 docker run --rm test_assets_run \"skaffold version\" demo 詳細實作的細節請至 cage1016/github-assets-cnb 查閱 github-assets-cnb@2.1.0 github-assets-cnb@1.1.0 我們在 project.toml 中配置相關的的 [[build.env]] 來指定對應的 Github Assets 參數。基本上可以達成一開始的期望在 Buildpack 構建 Container image 過期程中下載 Github Assses 的檔案，不過如果有需求下載 多個 Assets 時就沒有辦法滿足這個需求了 所以在 github-assets-cnb@2.1.0 中增加了 Support Download Public/Private Github Assets x-tar, gzip, x-zx, zip auto unarchive Support metadata.githubassets fields repo: Github Repo asset: Github Repo asset name tag: Release tag name, default set to “latest” token_env: (optional), Please assign ENV name for private repo destination: download asset destination path to, bin/\u003cyour-asset\u003e for application/x-executable asset strip_components: x-tar, gzip, x-zx suuport StripComponents feature. Create project.toml if you want to embed github assets cat \u003c\u003cEOF \u003e\u003e project.toml # assign token [[build.env]] name = \"APITEST_TOOLCHAIN_TOKEN\" value = \"\u003cgithub-token\u003e\" [[metadata.githubassets]] repo = \"kkdai/youtube\" asset = \"youtubedr_2.7.0_linux_arm64.tar.gz\" destination = \"bin\" [[metadata.githubassets]] repo = \"qeek-dev/apitest-toolchain\" token_env = \"APITEST_TOOLCHAIN_TOKEN\" asset = \"apitest-toolchain-linux-amd64\" destination = \"bin/apitest-toolchain\" tag = \"v0.1.0\" [[metadata.githubassets]] repo = \"stedolan/jq\" asset = \"jq-linux64\" destination = \"bin/jq\" EOF Build container image pack build myapp --buildpack cage1016/github-assets-cnb@2.1.0 Check /layers/cage1016_github-assets-cnb Container image ","date":"2021-04-20","objectID":"/posts/github-assets-cnb/:0:1","tags":["buildpacks","gcp","pack","github","paketo"],"title":"Github Assets Cnb","uri":"/posts/github-assets-cnb/"},{"categories":null,"content":"TODO","date":"2021-04-14","objectID":"/posts/ghcr-io-pack-build/","tags":["ghcr.io","registry","pack"],"title":"ghcr.io Pack Build","uri":"/posts/ghcr-io-pack-build/"},{"categories":null,"content":"Github 提供了開源的專案免費的 registry，所以寫個文章來記錄一下，如果使用 .github/workflows/build.yml 中使用 pack 來構建 container image Reference Packages: Container registry now supports GITHUB_TOKEN - GitHub Changelog ","date":"2021-04-14","objectID":"/posts/ghcr-io-pack-build/:0:0","tags":["ghcr.io","registry","pack"],"title":"ghcr.io Pack Build","uri":"/posts/ghcr-io-pack-build/"},{"categories":null,"content":"在 Buildpack Tips and Tricks 上一篤文章中我們提到了 Cloud Native Buildpacks 專案發起的目的還有一些使用上的心得，一般的使用情境就是選擇適合的 builder (Google, Heroku, Paketo)，必要時可以指定額外的 buildpack 。本篇文章稍後也會介紹 buildpack 基本組成元件、如何編寫自己的 buildpack 及發佈至 buildpack registry","date":"2021-04-08","objectID":"/posts/build-your-buildpack/","tags":["buildpacks","gcp","pack","heroku","paketo"],"title":"Build Your Buildpack","uri":"/posts/build-your-buildpack/"},{"categories":null,"content":"在 Buildpack Tips and Tricks ｜ KaiChu 上一篤文章中我們提到了 Cloud Native Buildpacks 專案發起的目的還有一些使用上的心得，一般的使用情境就是選擇適合的 builder (Google, Heroku, Paketo)，必要時可以指定額外的 buildpack 。本篇文章稍後也會介紹如何編寫自己的 buildpack 及如何發佈至 buildpack registry ","date":"2021-04-08","objectID":"/posts/build-your-buildpack/:0:0","tags":["buildpacks","gcp","pack","heroku","paketo"],"title":"Build Your Buildpack","uri":"/posts/build-your-buildpack/"},{"categories":null,"content":"這一篇文章會告訢你什麼 buildpack 基本組成元件介紹 手工打造自己定義 builpack (pure shell) 使用 packit 建立自己定義 buildpack (Buildpacks Utils Library) 怎麼透過 github action 直接發佈至 buildpack registry ","date":"2021-04-08","objectID":"/posts/build-your-buildpack/:0:1","tags":["buildpacks","gcp","pack","heroku","paketo"],"title":"Build Your Buildpack","uri":"/posts/build-your-buildpack/"},{"categories":null,"content":"這一篇文章不會告訢你什麼 怎麼編寫一個 builder, 如何自定義 builder 請先看官方的範例 Create a builder · Cloud Native Buildpacks Buildpack Examples: pack build test_img --path apps/test-app --builder cnbs/sample-builder:bionic Flags: -B, --builder string Builder image -b, --buildpack strings Buildpack to use. One of: a buildpack by id and version in the form of '\u003cbuildpack\u003e@\u003cversion\u003e', path to a buildpack directory (not supported on Windows), path/URL to a buildpack .tar or .tgz file, or a packaged buildpack image name in the form of '\u003chostname\u003e/\u003crepo\u003e[:\u003ctag\u003e]' Repeat for each buildpack in order, or supply once by comma-separated list ... 在 buildpack help 中可以看到 -b string or --buildpack strings 的參數可以額外的 buildpack，builder image 會依據 \u003cbuildpack\u003e@\u003cversion\u003e or \u003chostname\u003e/\u003crepo\u003e[:\u003ctag\u003e] 去 buildpack registry 抓取對應的 buildpack 回來一起編譯 (local 相對目錄也是可以的) 在開始編寫自己的 builpack 時，應該就要先了解整個 buildpack 的架構、元件還有運作的模式。先看看使用 buildpack 構建的 container image 包含了那些東西，我們以使用 gcr.io/buildpacks/builder:v1 builder 構建的 container image 來分析 ","date":"2021-04-08","objectID":"/posts/build-your-buildpack/:0:2","tags":["buildpacks","gcp","pack","heroku","paketo"],"title":"Build Your Buildpack","uri":"/posts/build-your-buildpack/"},{"categories":null,"content":"Pack inspect Pack 提供了 inspect 的指令可以幫助我們檢查 container image pack inspect \u003cimage-name\u003e [flags] $ pack inspect ms-sample-add Inspecting image: ms-sample-add REMOTE: (not present) LOCAL: Stack: google Base Image: Reference: 9875be79e8f3fc045dc520b8da706b14b07784aaec003e243c0a9d2050993f0a Top Layer: sha256:38407137fb1d65f4597f0dce78ac3b249dbfc247c30c4061981eb92b0fce4127 Run Images: gcr.io/buildpacks/gcp/run:v1 Buildpacks: ID VERSION HOMEPAGE google.go.runtime 0.9.1 - google.go.build 0.9.0 - google.utils.label 0.0.1 - Processes: TYPE SHELL COMMAND ARGS web (default) /layers/google.go.build/bin/main 由 Pack inspect 指令出輸結果，有幾個部份跟我們如要自定義 buildpack 時的概念有關係, Stack, Buildpacks, Processes 還有稍早到的 builder ","date":"2021-04-08","objectID":"/posts/build-your-buildpack/:0:3","tags":["buildpacks","gcp","pack","heroku","paketo"],"title":"Build Your Buildpack","uri":"/posts/build-your-buildpack/"},{"categories":null,"content":"Stack 由上一節 pack inspect 可以看出，Stack 是由 Base Image + Run Images 二個部份組合而成 (pack stack suggest) Base Image 的工作基本上就是生命周期中用來處理 build 工作的基底 container image，必要的時候是可以進行擴充的 Run Images 則為最後應用程式執行環境的基底 container image，必要的時候也是可以進行擴充 (上一篇文章中就遇到 gcr.io/buildpacks/gcp/run:v1 中不包含 /usr/share/zoneinfo 會導易 golang 程式在執行時區相關操作時報錯，而採用擴充 run image 來解決，Google 也更新了 run image 來解進這個問題) ","date":"2021-04-08","objectID":"/posts/build-your-buildpack/:0:4","tags":["buildpacks","gcp","pack","heroku","paketo"],"title":"Build Your Buildpack","uri":"/posts/build-your-buildpack/"},{"categories":null,"content":"Buildpacks (packaged in a builder) A buildpack is a unit of work that inspects your app source code and formulates a plan to build and run your application. Buildpack 就是每一個工作內容的最小單元，Buildpack 中定義在構建 container image 的生命周期中的事件 Detect, Analyze, Restore, Build, Export, Create, Launch, Rebase 需要作什麼動作 Output log Example: ... Network Mode: ===\u003e DETECTING ======== Results ======== pass: cage1016/jq-cnb@1.0.0 Resolving plan... (try #1) cage1016/jq-cnb 1.0.0 ===\u003e ANALYZING Previous image with name \"test_img\" not found ===\u003e RESTORING ===\u003e BUILDING URI -\u003e https://github.com/stedolan/jq/releases/download/jq-1.6/jq-linux64 Downloading dependency... Moving dependency... ===\u003e EXPORTING ... 當我們有需求要編寫自定義的 buildpack 時則最少需要包含三個檔案 buildpack.toml: 提供 builpack 相關的資訊，如 id, version, License 等等 bin/detect:)提供要套用當前 buildpack 的邏輯，如 pip 的 buildpack 檢查是否有 requestments.txt，沒有包含就跳出 bin/build: 承上面的範例，實作操作 pip 安裝對應的套件 bin/detect \u0026 bin/build 是為需要可執行的檔案，簡單就是 shell script, 不過也有一些工具 paketo-buildpacks/packit Buildpacks Utils Library 及 paketo-community/bootstrapper (bootstrap 工具包快速構建 cnb 專案框架)，使用 Golang 語言來產出 bin/detect, bin/build 的 binary 檔案供 Pack 指令直接使用 ","date":"2021-04-08","objectID":"/posts/build-your-buildpack/:0:5","tags":["buildpacks","gcp","pack","heroku","paketo"],"title":"Build Your Buildpack","uri":"/posts/build-your-buildpack/"},{"categories":null,"content":"Builder builder (ref: https://buildpacks.io/docs/concepts/components/create-builder.svg) A builder is an image that contains all the components necessary to execute a build. A builder image is created by taking a build image and adding a lifecycle, buildpacks, and files that configure aspects of the build including the buildpack detection order and the location(s) of the run image 簡單來說 builder 就是幫你準備的元件(稍早提到的 Stack，Buildpack 等等)，依照定義堆疊的順序(builder.toml)來幫你打包構建 container image https://github.com/GoogleCloudPlatform/buildpacks/blob/main/builders/gcp/base/builder.toml#L31-L45 [[buildpacks]] id = \"google.go.runtime\" uri = \"go/runtime.tgz\" [[buildpacks]] id = \"google.go.build\" uri = \"go/build.tgz\" [[buildpacks]] id = \"google.go.gopath\" uri = \"go/gopath.tgz\" [[buildpacks]] id = \"google.go.functions-framework\" uri = \"go/functions_framework.tgz\" ###### # Go # ###### [[order]] [[order.group]] id = \"google.go.runtime\" [[order.group]] id = \"google.go.functions-framework\" [[order.group]] id = \"google.go.build\" [[order.group]] id = \"google.config.entrypoint\" optional = true [[order.group]] id = \"google.go.clear_source\" optional = true [[order.group]] id = \"google.utils.label\" 以 gcr.io/buildpacks/builder:v1 來說，支援了 Go 1.10 +, Node.js 10 +, Python 3.7 +, Java 8, 11, .NET Core 3.1，所以我們會發現為了兼容這些程式語言，builder 中包含了非常多的 buildpack，並且描述了這些 buildpack 在對應語言中的順序 如稍早透過 pack inspect 指令看到 Buildpacks: cage1016/ms-demo-add ID VERSION HOMEPAGE google.go.runtime 0.9.1 - google.go.build 0.9.0 - google.utils.label 0.0.1 - cage1016/ms-sample-add 是一個 Golang 編寫的應用服務，在使用 gcr.io/buildpacks/builder:v1 構建 container image 中我們可以看到 buildpack 就是 GoogleCloudPlatform/buildpacks 中對於 Golang 語言中所指定的三個 google.go.runtime，google.go.build，google.utils.label, 至於沒有 google.go.functions-framework 是因為我們特別指定 Google Cloud Function 所需特別的參數，Pack 也就沒有將 google.go.functions-framework 一同構建至 container image 的 buildpack 中 ","date":"2021-04-08","objectID":"/posts/build-your-buildpack/:0:6","tags":["buildpacks","gcp","pack","heroku","paketo"],"title":"Build Your Buildpack","uri":"/posts/build-your-buildpack/"},{"categories":null,"content":"Build your first buildpack 在大至上了解 buildpack 的基本概念(Stack, buildpack, builder) 之後，就可以開始編寫我們自定義的 buildpack。這一次我們需要在 container image 中加入 jq 的 command 供後序使用 alpine Dockerfile RUN apk add –update jq \u0026\u0026 rm -rf /var/cache/apk/* 以 Dockerfile 的角度來說要在 container image 中加入 jq 只需要指定 jq 的名子就好。而在 buildpack 的框架下，就有幾種選擇 如果是在 container image 構建過程中，可以擴充 builder image，基於 builder 的 image 再往上疊，GoogleCloudPlatform/buildpacks: Extending the builder image 如果是在執行環境需要，可以擴充 run image，基於 builder stack 的 run image 再往上疊，GoogleCloudPlatform/buildpacks: Extending the run image 另一種方式就是編寫一個 inject jq 的 buildpack，再需要 jq 的時候透過 pack --buildpack \u003c\u003cbuildpack\u003e@\u003cversion\u003e\u003e 來加入，我們這一次就選擇自建 jq buildpack，部署之後也方便使用 稍早有提過，編寫一個 builpack 最少需要有 3 個檔案，buildpack.toml, bin/detect, bin/build ├── jq-cnb │ ├── bin │ │ ├── build │ │ └── detect │ └── buildpack.toml 準備好 3 個檔案就可以選擇 builder 來構建 buildpack 的 container image (這時候要注意的事情是，話說 builder 會按照 spec 來打包，實事上 builder 實作上還是有些語不同，選擇 builder 上要注意，且 builder 的 stack id 需要列在 buildpack.toml 上的白名單上，不在白名子的 id 會因安全性議題無法編譯) 使用 pack build 測試我們的 buildpack pack build test-jq-run --builder gcr.io/buildpacks/builder:v1 --buildpack ./jq-cnb --path \u003cempty-folder\u003e 構建完 container image 後可以使用 dcoker run 來檢查 jq 是否可以正常工作 $ docker run --rm test-jq-run \"echo '{\\\"foo\\\": 0}' | jq .\" { \"foo\": 0 } 使用 pack inspect 來看看我們構建出來的 container image test-jq-run，其中 buildpack 區塊正常的顯示我們在 buildapck.toml 中描述中的 id 一樣 $ pack inspect test-jq-run Inspecting image: test-jq-run REMOTE: (not present) LOCAL: Stack: google Base Image: Reference: 41b0f9df90f26562392b58280ade9df13e8020d4dd8e56e79910f48f4946a98e Top Layer: sha256:50ba10dd399f2f5fed9657b403f3bc3a2cea534620c3921143e1ac92037ab43b Run Images: gcr.io/buildpacks/gcp/run:v1 Buildpacks: ID VERSION HOMEPAGE cage1016/jq-cnb 1.0.0 - ","date":"2021-04-08","objectID":"/posts/build-your-buildpack/:1:0","tags":["buildpacks","gcp","pack","heroku","paketo"],"title":"Build Your Buildpack","uri":"/posts/build-your-buildpack/"},{"categories":null,"content":"Buildpacks Utils Library cage1016/jq-cnb: A Cloud Native Buildpack that include jq paketo-buildpacks/packit: Buildpacks Utils Library paketo-community/bootstrapper 上一節我們使用 shell 的方式來試範如果自定義一個簡單的 buildpack。簡單，但是複雜一點的官方 範例 就會覺得 shell 不是那麼好寫，難是在要符合 buildpack 的 規範 需要花時間去了解，所以這時候有一些工具來快速發起空專案就是一個好選擇 cage1016/jq-cnb 就是採用 paketo-buildpacks/packit Buildpacks Utils Library 為基礎來改寫上一節的 shell 程式碼，詳細的程式碼請直接連結至 github 頁面查看，邏輯基本上是一致，不同之處就是由 shell 的部份轉換成對 Buildpacks Utils Library 的操作。沒有誰好誰壞，端看大家喜歡用什麼方式 ","date":"2021-04-08","objectID":"/posts/build-your-buildpack/:1:1","tags":["buildpacks","gcp","pack","heroku","paketo"],"title":"Build Your Buildpack","uri":"/posts/build-your-buildpack/"},{"categories":null,"content":"deploy pack to buildpack registry .github/workflows/release.yaml name: Release on: release: types: - published jobs: register: name: Package, Publish, and Register runs-on: - ubuntu-latest steps: - id: checkout name: Checkout code uses: actions/checkout@v2 - if: ${{ github.event_name != 'pull_request' || ! github.event.pull_request.head.repo.fork }} name: Login to GitHub Package Registry uses: docker/login-action@v1 with: registry: ghcr.io username: ${{ github.repository_owner }} password: ${{ secrets.GHCR_TOKEN }} - id: setup-pack uses: buildpacks/github-actions/setup-pack@v4.1.0 - id: package run: | #!/usr/bin/env bash set -euo pipefail BP_ID=\"$(cat buildpack.toml | yj -t | jq -r .buildpack.id)\" VERSION=\"$(cat buildpack.toml | yj -t | jq -r .buildpack.version)\" PACKAGE=\"${REPO}/$(echo \"$BP_ID\" | sed 's/\\//_/g')\" pack package-buildpack --publish ${PACKAGE}:${VERSION} DIGEST=\"$(crane digest ${PACKAGE}:${VERSION})\" echo \"::set-output name=bp_id::$BP_ID\" echo \"::set-output name=version::$VERSION\" echo \"::set-output name=address::${PACKAGE}@${DIGEST}\" shell: bash env: REPO: ghcr.io/${{ github.repository_owner }}/buildpacks - id: register uses: docker://ghcr.io/buildpacks/actions/registry/request-add-entry:4.1.0 with: token: ${{ secrets.PUBLIC_REPO_TOKEN }} id: ${{ steps.package.outputs.bp_id }} version: ${{ steps.package.outputs.version }} address: ${{ steps.package.outputs.address }} 其實 buildpack 已經打造了一些工具來幫助開發者快速部署 Tools · Cloud Native Buildpacks，本次的範例就是使用 Github action + Release 自己發佈，實際的內容也是 Github action 中使用 pack package 方法的一些操作，當成功 release 之後就可以在 buildpack registry 中查詢的到 https://registry.buildpacks.io/buildpacks/cage1016/jq-cnb 最後我就可以直接使用 mkdir null-folder echo -n 1.5 \u003e null-folder/.jq-version # optional, default is set to 1.6 pack build test-new-jq-run --path ./null-folder -b cage1016/jq-cnb@1.1.0 --builder gcr.io/buildpacks/builder:v1 -v \u0026\u0026 docker run --rm test-new-jq-run \"echo '{\\\"foo\\\": 0}' | jq .\" $ pack inspect test-new-jq-run Inspecting image: test-new-jq-run REMOTE: (not present) LOCAL: Stack: google Base Image: Reference: 41b0f9df90f26562392b58280ade9df13e8020d4dd8e56e79910f48f4946a98e Top Layer: sha256:50ba10dd399f2f5fed9657b403f3bc3a2cea534620c3921143e1ac92037ab43b Run Images: gcr.io/buildpacks/gcp/run:v1 Buildpacks: ID VERSION HOMEPAGE cage1016/jq-cnb 1.1.0 https://github.com/cage1016/jq-cnb ","date":"2021-04-08","objectID":"/posts/build-your-buildpack/:1:2","tags":["buildpacks","gcp","pack","heroku","paketo"],"title":"Build Your Buildpack","uri":"/posts/build-your-buildpack/"},{"categories":null,"content":"Reference github-actions/README.md at main · buildpacks/github-actions: End-user GitHub Actions related to Cloud Native Buildpacks GoogleCloudPlatform/buildpacks: Builders and buildpacks designed to run on Google Cloud’s container platforms: Builders and buildpacks designed to run on Google Cloud’s container platforms Cloud Native Buildpacks · Cloud Native Buildpacks Paketo Buildpacks - Paketo Buildpacks cage1016/jq-cnb: A Cloud Native Buildpack that include jq Buildpack Registry ","date":"2021-04-08","objectID":"/posts/build-your-buildpack/:2:0","tags":["buildpacks","gcp","pack","heroku","paketo"],"title":"Build Your Buildpack","uri":"/posts/build-your-buildpack/"},{"categories":null,"content":"CNCF 下的 buildpack 是定義出轉換程式碼至 image 的標準，使用者可以適擇適合的 builder (Google, HeroKu, Paketo) 來產出 container image，除了免去編輯 Dockerfile 的部份、container image layer 有相同的體驗、container image 的安全性交由 builder 來處理等等好處。不過美好的事情背後也是有一些取捨。本篇文章就是最近優化 CI/CD pipeline 流程上使用 buildpack 的心得分享還有遇到的坑及解決方案","date":"2021-04-02","objectID":"/posts/buildpack-tips-and-tricks/","tags":["buildpacks","gcp","pack","heroku","paketo"],"title":"Buildpack Tips and Tricks","uri":"/posts/buildpack-tips-and-tricks/"},{"categories":null,"content":"2018 年去上海參加 Kubecon 就有聽到過 CNCF 下的 Cloud Native Buildpacks 的專案。回來也有試玩了一下，概念很不錯，那時候可能整個生態系統比較不建全，試玩了一下就放到旁邊去了 不過自從 Google Cloud Next 20’ - Hands-on Keynote: Building Trust for Speedy Innovation 中也有場次提到 Google 內部已經使用 Buildpack 的服務，之後就有比較用力的試了一下，也導入到自己的工程流程中 Google Cloud maintains a set of open source buildpacks for building containers to run \u003e on GKE，Anthos，\u0026 Cloud Run Cloud Build native support for buildpacks Cloud Run direct source deployments w/ buildpacks Cloud Shell has pack pre-installed. App Engine builds via buildpacks Cloud Functions builds via buildpacks Cloud Code deploy to Cloud Run with Buildpacks Skaffold native support for buildpacks 在跟同事分享 buildpack 的時候，同事覺得太複雜了。同樣的動作 Dockerfile 操作比 buildpack 來的容易簡單，那為什麼還需要導入 buildpack 這個東西把事情弄的複雜? ps. (先補充一個血淚: 只拿到前人留下來的 container image，沒有任何 Dockerfile, 後序再次開發只有一個慘字，如果一開始使用 buildpack 就不會那麼辛苦) ","date":"2021-04-02","objectID":"/posts/buildpack-tips-and-tricks/:0:0","tags":["buildpacks","gcp","pack","heroku","paketo"],"title":"Buildpack Tips and Tricks","uri":"/posts/buildpack-tips-and-tricks/"},{"categories":null,"content":"Cloud Native Buildpacks Cloud Native Buildpacks transform your application source code into images that can run on any cloud. 先從 buildpack 的目的來說，它其實是定義了一套如何從程式源始碼建立 container image 的 buildpacks/spec: Specification for Cloud Native Buildpacks This specification defines interactions between a platform, a lifecycle, a number of buildpacks, and an application For the purpose of transforming that application into an OCI image and For the purpose of developing or executing automated tests on that application. A buildpack is software that partially or completely transforms application source code into runnable artifacts. A lifecycle is software that orchestrates buildpacks and transforms the resulting artifacts into an OCI image. A platform is software that orchestrates a lifecycle to make buildpack functionality available to end-users such as application developers. 總的來說，buildpack 的目的是建立一個通用的規範， builder (Google, Heroku, Paketo) 除了實作這個規範之外也會增加一些功能來支援自己的產品(如 Google 的 gcr.io/buildpacks/builder:v1 builder 就有支援 Google Cloud function)。一般的情況就是選擇一個自己適合的 builder 直接使用 # Examples: pack build test_img --path apps/test-app --builder cnbs/sample-builder:bionic 當有特別的需求是可以自定義 buildpack 來完成，但開發者也必需依照同樣的規範的來實作自己的 buildpack；也因為 buildpack 需要按照規範來寫，不像 Dockerfile 這樣可以隨便寫(誤)，入門會有一點門檻，但是效益上會體現在如 container image 的安全性，大量產出 container image 的 CI/CD 流程上 聽起來好像很方便又覺得那邊卡卡的，我來說說一些心得 Pros 不用寫 Dcokerfile 一般的情況可以無惱的使用，可以把精力放在商業邏輯上 container image 的安性性由 builder 幫你處理 CI/CD 流程的整合: skaffold, cloud build, tekton 都有支援 Cons 因為要尊循規範, 自定義的入門門檻還是有一些 無惱 build container image 看似很美好，遇到 builder (Google, Heroku, Paketo) 不提供的部份就會很難受(踩到的坑後面再說) 如果想 build 出 container image size 小的部份得看 builder 有沒有支援，(如: paketobuildpacks/builder:tiny) ","date":"2021-04-02","objectID":"/posts/buildpack-tips-and-tricks/:0:1","tags":["buildpacks","gcp","pack","heroku","paketo"],"title":"Buildpack Tips and Tricks","uri":"/posts/buildpack-tips-and-tricks/"},{"categories":null,"content":"坑 現在來談談最近遇到的坑，先來看看現在 pack 建議的 builders，有 Google、Heroku 和 Paketo 三個，使用者可以跟據自己的需求選擇適合的 builder pack builder suggest Suggested builders: Google: gcr.io/buildpacks/builder:v1 Ubuntu 18 base image with buildpacks for .NET, Go, Java, Node.js, and Python Heroku: heroku/buildpacks:18 Base builder for Heroku-18 stack, based on ubuntu:18.04 base image Heroku: heroku/buildpacks:20 Base builder for Heroku-20 stack, based on ubuntu:20.04 base image Paketo Buildpacks: paketobuildpacks/builder:base Ubuntu bionic base image with buildpacks for Java, .NET Core, NodeJS, Go, Ruby, NGINX and Procfile Paketo Buildpacks: paketobuildpacks/builder:full Ubuntu bionic base image with buildpacks for Java, .NET Core, NodeJS, Go, PHP, Ruby, Apache HTTPD, NGINX and Procfile Paketo Buildpacks: paketobuildpacks/builder:tiny Tiny base image (bionic build image, distroless-like run image) with buildpacks for Java Native Image and Go 坑1 paketobuildpacks/builder:tiny 目前不支持 golang module 中使用 private repo fatal: could not read Username for 'https://github.com': terminal prompts disabled Confirm the import path was entered correctly. If this is a private repository, see https://golang.org/doc/faq#git_https for additional information. 依據 Private Repository Support · Issue #3 · paketo-buildpacks/go-mod-vendor 中討論的部份，如果是使用 Golang 語言且 Go Module 中有使用到 private repo 就會遇到權限不足的問題，issues 討論中也表示目前並不支持 private repo，不過有提出 pack 可以 inject SSH key (不過我自己是沒有試成功) 這個只適合想用 buildpack 產出 tiny 大小的 container image (Golang)，不過前提是沒有使用 private repo 坑2 gcr.io/buildpacks/builder:v1 gcr.io/buildpacks/gcp/run:v1 不包含 /usr/share/zoneinfo，如果 Golang 中有使用到 loc, _ := time.LoadLocation(\"Asia/Taipei\") 會報錯，不過 paketobuildpacks/builder:tiny 的 run image 有阿 !!!! 在我們用 gcr.io/buildpacks/builder:v1 產出 container image 後執行後發現報錯，root cause 是 container image 並不包含 /usr/share/zoneinfo 目錄導致報錯, pack inspect \u003ccontainer-image\u003e 後得知 run image 是 gcr.io/buildpacks/gcp/run:v1，而 gcr.io/buildpacks/gcp/run:v1 本身就沒有包含 /usr/share/zoneinfo 目錄，這時候就必需擴充 gcr.io/buildpacks/gcp/run:v1 中安裝 tzdata FROM gcr.io/buildpacks/gcp/run:v1 USER root RUN apt-get update \u0026\u0026 apt-get install -y --no-install-recommends \\ tzdata \u0026\u0026 \\ apt-get clean \u0026\u0026 \\ rm -rf /var/lib/apt/lists/* USER cnb 產出擴充的 run image docker build -t gcr.io/retailbase-dev/ext-run:v1 -f run.Dockerfile . 然後在 pack 中代入 擴充後有 run time pack build gcr.io/retailbase-dev/retailbase-organizationsvc:$SHORT_SHA --builder gcr.io/buildpacks/builder:v1 --env GOOGLE_BUILDABLE=cmd/organizationsvc/main.go --run-image gcr.io/retailbase-dev/ext-run:v1 2021/04/08 update 在發 issue Include tzdata in base images · GoogleCloudPlatform/buildpacks@50539bf 之後，Google 已經在 base image 中加上了 tzdata，這樣就不需要擴充 runtime 來解 Golang panic 的 bug，直接使用原來的 gcr.io/buildpacks/builder:v1 即可 坑三 gcr.io/cloud-builders/gcloud cloudbuild gcr.io/cloud-builders/gcloud 中有整合 pack 的參數，不過沒有辦法追加 runtime 的設定，就算我們擴充了 run time 也無法代入 gcloud builds submit [[SOURCE] --no-source] [--async] [--no-cache] [--disk-size=DISK_SIZE] [--gcs-log-dir=GCS_LOG_DIR] [--gcs-source-staging-dir=GCS_SOURCE_STAGING_DIR] [--ignore-file=IGNORE_FILE] [--machine-type=MACHINE_TYPE] [--region=REGION] [--substitutions=[KEY=VALUE,...]] [--timeout=TIMEOUT] [--worker-pool=WORKER_POOL] [--config=CONFIG; default=\"cloudbuild.yaml\" | --pack=[builder=BUILDER],[env=ENV],[image=IMAGE] | --tag=TAG, -t TAG] [GCLOUD_WIDE_FLAG ...] gcr.io/cloud-builders/gcloud 使用 pack 的相關參數只有 builder, env, 及 image - id: pack build export name: gcr.io/cloud-builders/gcloud args: - builds - submit - --pack=builder=gcr.io/buildpacks/builder:v1,env=GOOGLE_BUILDABLE=cmd/export/main.go,image=gcr.io/retailbase-dev/retailbase-export:$SHORT_SHA 所以就必需透過 GoogleCloudPlatform/cloud-builders-community: Community-contributed images for Google Cloud Build 中的方式，自行打包 pack 來使用 - name: gcr.io/retailbase-dev/pack:v0.18.0 args: - build - gcr.io/retailbase-dev/retailbase-export:$SHORT_SHA - --builder=gcr.io/buildpacks/builder:v1 - --env=GOOGLE_BUILDABLE=cmd/export/main.go - --run-image=gcr.io/retailbase-dev/ext-run:v1 如何自定義 buildp","date":"2021-04-02","objectID":"/posts/buildpack-tips-and-tricks/:0:2","tags":["buildpacks","gcp","pack","heroku","paketo"],"title":"Buildpack Tips and Tricks","uri":"/posts/buildpack-tips-and-tricks/"},{"categories":null,"content":"Reference Cloud Native Buildpacks: Buildpack 官方網站 GoogleCloudPlatform/buildpacks: Builders and buildpacks designed to run on Google Cloud’s container platforms: Google 版的 buildpack Paketo Buildpacks - Paketo Buildpacks Buildpacks | Heroku Dev Center: Heroku 版的 Buildpack gcloud builds submit | Cloud SDK Documentation | Google Cloud ","date":"2021-04-02","objectID":"/posts/buildpack-tips-and-tricks/:0:3","tags":["buildpacks","gcp","pack","heroku","paketo"],"title":"Buildpack Tips and Tricks","uri":"/posts/buildpack-tips-and-tricks/"},{"categories":null,"content":"Buildpack 讓發開人員免去了寫 Dockerfile 的痛苦，在使用 Cloud Run Button 中可以透過 project.toml 的配置來設定 buildpack 執行時期的參數，在 go code 進入點不在根目錄中的程式可以配置 GOOGLE_BUILDABLE 來指定程式進入點，必免導至 Container image 建立失敗","date":"2021-03-22","objectID":"/posts/cloud-run-button-tips/","tags":["GCP","CloudRun"],"title":"Cloud Run Button Tips","uri":"/posts/cloud-run-button-tips/"},{"categories":null,"content":"Cloud Run 最近為了節省 GCP 服務上的花費，將 GKE 的 cluster 的機器等級調低，相對應的是遷出部份服務到 Google managed 中，也因此重新將目光投射回 Cloud Run Cloud Run 是算是 Goolge Cloud Platfrom 中 serverless (以 Knative 標準打造) 服務的其中一項，開發人員期本上只要掌握打包 Container Image 的技能就可以使用 Cloud Run，如果你不知道 Cloud Run 可以作什麼，下面官方的影片可以看一下 ","date":"2021-03-22","objectID":"/posts/cloud-run-button-tips/:1:0","tags":["GCP","CloudRun"],"title":"Cloud Run Button Tips","uri":"/posts/cloud-run-button-tips/"},{"categories":null,"content":"Container images 剛剛提到開發人員只需要掌握 Container Image 打包的技能就可以入門 Cloud Run。而打包 Container Image 的方式可以從編寫 Dockerfile 或使用 CNCF 中 Cloud Native Buildpacks 的方式從原始碼打包 Container image。 Google Cloud Next 20’ - Hands-on Keynote: Building Trust for Speedy Innovation 中也有場次提到 Google 內部已經使用 Buildpack 的服務 Google Cloud maintains a set of open source buildpacks for building containers to run on GKE，Anthos，\u0026 Cloud Run Cloud Build native support for buildpacks Cloud Run direct source deployments w/ buildpacks Cloud Shell has pack pre-installed. App Engine builds via buildpacks Cloud Functions builds via buildpacks Cloud Code deploy to Cloud Run with Buildpacks Skaffold native support for buildpacks 最大的好處是不需要編寫 Dockerfile，Container 相關的安全漏洞也會幫你處理好，更詳細的部份可以參考 GoogleCloudPlatform/buildpacks: Builders and buildpacks designed to run on Google Cloud’s container platforms ","date":"2021-03-22","objectID":"/posts/cloud-run-button-tips/:2:0","tags":["GCP","CloudRun"],"title":"Cloud Run Button Tips","uri":"/posts/cloud-run-button-tips/"},{"categories":null,"content":"Cloud Run Button Let anyone deploy your GitHub repos to Google Cloud Run with a single click video/cage1016_gokit-add-cloud-run.mp4 再來介紹今天的主角 Cloud Run Button， GoogleCloudPlatform/cloud-run-button 可以讓你一鍵部署寫好的 Cloud Run Code. 基本的原理就是 Cloud Run Button 幫你完成 gcloud command 中 Cloud Run 相關的操作，從 source repo clone，build container image，到部署到 Cloud Run 中，非常的方便。 再建立 Container image 的過程中也是可以使用 Buildpack 的方式，也可以在根目錄中配置 project.toml 來設定 buildpack 相關的參數。如下 project.toml [[build.env]] name = \"GOOGLE_BUILDABLE\" value = \"cmd/add/main.go\" ","date":"2021-03-22","objectID":"/posts/cloud-run-button-tips/:3:0","tags":["GCP","CloudRun"],"title":"Cloud Run Button Tips","uri":"/posts/cloud-run-button-tips/"},{"categories":null,"content":"Cloud Code - Cloud Run Cloud Code - Visual Studio Marketplace 另外 Cloud Code 也有支援 Cloud Run 的整合，Cloud Run Button 是在 Cloud shell 透過 git clone 的方式來獲取原始碼，對於私人專案可能沒有那麼適合，就可以選擇 Cloud Code - Cloud Run，Cloud Code - Cloud Run 一樣有整合 buildpack，同樣適配 project.toml 設定參數 ","date":"2021-03-22","objectID":"/posts/cloud-run-button-tips/:3:1","tags":["GCP","CloudRun"],"title":"Cloud Run Button Tips","uri":"/posts/cloud-run-button-tips/"},{"categories":null,"content":"Demo https://github.com/cage1016/gokit-add-cloud-run ","date":"2021-03-22","objectID":"/posts/cloud-run-button-tips/:3:2","tags":["GCP","CloudRun"],"title":"Cloud Run Button Tips","uri":"/posts/cloud-run-button-tips/"},{"categories":null,"content":"延續上一篇文章 Rbac1 Design，透過 Postgres Transpose Rows to Columns (crosstab) 將行列互換，可以拿到一個基於每一個使用者基於 RBAC resource 對應操作權限","date":"2021-02-04","objectID":"/posts/postgres-transpose-rows-to-columns/","tags":["rbac1","rbac","postgres"],"title":"Postgres Transpose Rows to Columns","uri":"/posts/postgres-transpose-rows-to-columns/"},{"categories":null,"content":"延續上一篇文章 Rbac1 Design ｜ KaiChu, 我們透過 Postgres 中的 CTE (common table expression) recursive query 來查詢有繼承 Role 的有對應的權限 ","date":"2021-02-04","objectID":"/posts/postgres-transpose-rows-to-columns/:0:0","tags":["rbac1","rbac","postgres"],"title":"Postgres Transpose Rows to Columns","uri":"/posts/postgres-transpose-rows-to-columns/"},{"categories":null,"content":"user_id permission user_id key 87gb8fKJHGxh2Pz_Gk_R2 create:devops 87gb8fKJHGxh2Pz_Gk_R2 create:rbac 87gb8fKJHGxh2Pz_Gk_R2 create:users 87gb8fKJHGxh2Pz_Gk_R2 delete:devops 87gb8fKJHGxh2Pz_Gk_R2 delete:rbac 87gb8fKJHGxh2Pz_Gk_R2 delete:users 87gb8fKJHGxh2Pz_Gk_R2 read:devops 87gb8fKJHGxh2Pz_Gk_R2 read:rbac 87gb8fKJHGxh2Pz_Gk_R2 read:users 87gb8fKJHGxh2Pz_Gk_R2 update:devops 87gb8fKJHGxh2Pz_Gk_R2 update:rbac 87gb8fKJHGxh2Pz_Gk_R2 update:users h8Iqlb8Ixc4IltuOoY5QC create:devops h8Iqlb8Ixc4IltuOoY5QC delete:devops h8Iqlb8Ixc4IltuOoY5QC read:devops h8Iqlb8Ixc4IltuOoY5QC update:devops SbZeBSpuy2OdJ0WZ2Z_Qo read:devops SJ36zw7nRS4lx18dZlCoo create:users SJ36zw7nRS4lx18dZlCoo delete:users SJ36zw7nRS4lx18dZlCoo read:users SJ36zw7nRS4lx18dZlCoo update:users ","date":"2021-02-04","objectID":"/posts/postgres-transpose-rows-to-columns/:0:1","tags":["rbac1","rbac","postgres"],"title":"Postgres Transpose Rows to Columns","uri":"/posts/postgres-transpose-rows-to-columns/"},{"categories":null,"content":"user vs resource permission read:R, write:C, delete:D, update:U user_id devops rbac users 87gb8fKJHGxh2Pz_Gk_R2 CDRU CDRU CDRU h8Iqlb8Ixc4IltuOoY5QC CDRU NULL NULL SbZeBSpuy2OdJ0WZ2Z_Qo R NULL NULL SJ36zw7nRS4lx18dZlCoo NULL NULL CDRU 透過 postgres 的 Transpose Rows to Columns 可以得到上面一個人眼比較直覺得大表 核心的 sql 就是使用 crosstab 指令, 完整操作請看下方 full sql select * from crosstab( 'query order by 1', 'query distinct resource order by 1' ) as ( user_id text, \"devops\" text, \"rbac\" text, \"users\" text ) full sql create table roles ( id varchar(21) not null constraint roles_pkey primary key, parent_id varchar(21) constraint fk_roles_roles references roles, role_name text, description text, type bigint, enabled boolean, created_at timestamp with time zone, updated_at timestamp with time zone ); create table permissions ( id varchar(21) not null constraint permissions_pkey primary key, action_id text, resource_id text, key text, created_at timestamp with time zone, updated_at timestamp with time zone ); create table role_permission ( permission_id varchar(21) not null constraint fk_role_permission_permission references permissions, role_id varchar(21) not null constraint fk_role_permission_role references roles, constraint role_permission_pkey primary key (permission_id, role_id) ); create table actions ( id varchar(21) not null constraint actions_pkey primary key, name text, description text, created_at timestamp with time zone, updated_at timestamp with time zone ); create table resources ( id varchar(21) not null constraint resources_pkey primary key, name text, created_at timestamp with time zone, updated_at timestamp with time zone ); create table users ( id varchar(21) not null constraint users_pkey primary key, name text, enabled boolean, created_at timestamp with time zone, updated_at timestamp with time zone ); create table user_role ( role_id varchar(21) not null constraint fk_user_role_role references roles, user_id varchar(21) not null constraint fk_user_role_user references users, constraint user_role_pkey primary key (role_id, user_id) ); -- data INSERT INTO actions (id, name, description, created_at, updated_at) VALUES ('QPjlpxmEE7fSjeTvavn0C', 'create', 'create', '2021-01-24T10:24:17+08:00', '2021-01-24T10:24:17+08:00'); INSERT INTO actions (id, name, description, created_at, updated_at) VALUES ('2iNamDFktFA6qfz_Tk5nH', 'update', 'update', '2021-01-24T10:24:17+08:00', '2021-01-24T10:24:17+08:00'); INSERT INTO actions (id, name, description, created_at, updated_at) VALUES ('kZBX-FnIYa374wt4D5OlK', 'delete', 'delete', '2021-01-24T10:24:17+08:00', '2021-01-24T10:24:17+08:00'); INSERT INTO actions (id, name, description, created_at, updated_at) VALUES ('ozXzHwl1tDLmgIwCBjQMc', 'read', 'read', '2021-01-24T10:24:17+08:00', '2021-01-24T10:24:17+08:00'); INSERT INTO resources (id, name, created_at, updated_at) VALUES ('k4Wcq9zGqShiSH6-HmR9_', 'rbac', '2021-01-24T10:24:17+08:00', '2021-01-24T10:24:17+08:00'); INSERT INTO resources (id, name, created_at, updated_at) VALUES ('AoiiJEVfm3Fe8gtlZvE0_', 'users', '2021-01-24T10:24:17+08:00', '2021-01-24T10:24:17+08:00'); INSERT INTO resources (id, name, created_at, updated_at) VALUES ('_-0lB0FJklZQf0wMCOdb3', 'devops', '2021-01-24T10:24:17+08:00', '2021-01-24T10:24:17+08:00'); INSERT INTO permissions (id, action_id, resource_id, created_at, updated_at, key) VALUES ('7BvEdc4TA-gDOF-mfR3Wy', 'ozXzHwl1tDLmgIwCBjQMc', '_-0lB0FJklZQf0wMCOdb3', '2021-01-24T10:24:17+08:00', '2021-01-24T10:24:17+08:00', 'read:devops'); INSERT INTO permissions (id, action_id, resource_id, created_at, updated_at, key) VALUES ('4vIzJkqwRPj2vN_w4Oq88', 'QPjlpxmEE7fSjeTvavn0C', 'k4Wcq9zGqShiSH6-HmR9_', '2021-01-24T10:24:17+08:00', '2021-01-24T10:24:17+08:00', 'create:rbac'); INSERT INTO permissions (id, action_id, resource_id, created_at, updated_at, key) VALUES ('0rhMOepRtB5GPO_6xDLZ3', 'ozXzHwl1tDLmgIwCBjQMc', 'k4Wcq9zGqShiSH6-HmR9_', '2021-01-24T10:24:17+08:00', '2021-01-24T10:24:17+08:00', 'read:rbac'); INSERT INTO permissions (id,","date":"2021-02-04","objectID":"/posts/postgres-transpose-rows-to-columns/:0:2","tags":["rbac1","rbac","postgres"],"title":"Postgres Transpose Rows to Columns","uri":"/posts/postgres-transpose-rows-to-columns/"},{"categories":null,"content":"權限系統在任何應用程式都是基礎且重要的部份，主要是對不同的人訪問資源進行權限的控制，本篇文章並沒有特別的再說明 Role-Based Access Control, 解釋的文章已經太多了，隨便 Google 都是一堆。最期在公司的專案也是有採用 RBAC 來管控系統的權限，一般的 RBAC0 (最基本的 User - Role - Permission) 的模型大至上可以符合需求，不過在權限配直的時候會有一點重工，所以選擇了有角色繼承的 RBAC1 來進行實作","date":"2021-01-24","objectID":"/posts/rbac1-design/","tags":["rbac1","rbac","postgres"],"title":"Rbac1 Design","uri":"/posts/rbac1-design/"},{"categories":null,"content":"權限系統在任何應用程式都是基礎且重要的部份，主要是對不同的人訪問資源進行權限的控制，本篇文章並沒有特別的再說明 Role-Based Access Control, 解釋的文章已經太多了，隨便 Google 都是一堆。最期在公司的專案也是有採用 RBAC 來管控系統的權限，一般的 RBAC0 (最基本的 User - Role - Permission) 的模型大至上可以符合需求，不過在權限配直的時候會有一點重工，所以選擇了有角色繼承的 RBAC1 來進行實作 RBAC1 Postgres Database Schema ","date":"2021-01-24","objectID":"/posts/rbac1-design/:0:0","tags":["rbac1","rbac","postgres"],"title":"Rbac1 Design","uri":"/posts/rbac1-design/"},{"categories":null,"content":"public.actions column comment type length default constraints values id (pk) character varying 21 NOT NULL name text description text created_at timestamp with time zone updated_at timestamp with time zone ","date":"2021-01-24","objectID":"/posts/rbac1-design/:0:1","tags":["rbac1","rbac","postgres"],"title":"Rbac1 Design","uri":"/posts/rbac1-design/"},{"categories":null,"content":"public.permissions column comment type length default constraints values id (pk) character varying 21 NOT NULL action_id text resource_id text key text created_at timestamp with time zone updated_at timestamp with time zone ","date":"2021-01-24","objectID":"/posts/rbac1-design/:0:2","tags":["rbac1","rbac","postgres"],"title":"Rbac1 Design","uri":"/posts/rbac1-design/"},{"categories":null,"content":"public.resources column comment type length default constraints values id (pk) character varying 21 NOT NULL name text created_at timestamp with time zone updated_at timestamp with time zone ","date":"2021-01-24","objectID":"/posts/rbac1-design/:0:3","tags":["rbac1","rbac","postgres"],"title":"Rbac1 Design","uri":"/posts/rbac1-design/"},{"categories":null,"content":"public.role_permission column comment type length default constraints values permission_id (pk) character varying 21 NOT NULL, permission_id role_id (pk) character varying 21 NOT NULL, role_id ","date":"2021-01-24","objectID":"/posts/rbac1-design/:0:4","tags":["rbac1","rbac","postgres"],"title":"Rbac1 Design","uri":"/posts/rbac1-design/"},{"categories":null,"content":"public.roles column comment type length default constraints values id (pk) character varying 21 NOT NULL parent_id character varying 21 parent_id role_name text description text type bigint enabled boolean created_at timestamp with time zone updated_at timestamp with time zone ","date":"2021-01-24","objectID":"/posts/rbac1-design/:0:5","tags":["rbac1","rbac","postgres"],"title":"Rbac1 Design","uri":"/posts/rbac1-design/"},{"categories":null,"content":"public.user_role column comment type length default constraints values role_id (pk) character varying 21 NOT NULL, role_id user_id (pk) character varying 21 NOT NULL, user_id ","date":"2021-01-24","objectID":"/posts/rbac1-design/:0:6","tags":["rbac1","rbac","postgres"],"title":"Rbac1 Design","uri":"/posts/rbac1-design/"},{"categories":null,"content":"public.users column comment type length default constraints values id (pk) character varying 21 NOT NULL name text enabled boolean created_at timestamp with time zone updated_at timestamp with time zone create table roles ( id varchar(21) not null constraint roles_pkey primary key, parent_id varchar(21) constraint fk_roles_roles references roles, role_name text, description text, type bigint, enabled boolean, created_at timestamp with time zone, updated_at timestamp with time zone ); create table permissions ( id varchar(21) not null constraint permissions_pkey primary key, action_id text, resource_id text, key text, created_at timestamp with time zone, updated_at timestamp with time zone ); create table role_permission ( permission_id varchar(21) not null constraint fk_role_permission_permission references permissions, role_id varchar(21) not null constraint fk_role_permission_role references roles, constraint role_permission_pkey primary key (permission_id, role_id) ); create table actions ( id varchar(21) not null constraint actions_pkey primary key, name text, description text, created_at timestamp with time zone, updated_at timestamp with time zone ); create table resources ( id varchar(21) not null constraint resources_pkey primary key, name text, created_at timestamp with time zone, updated_at timestamp with time zone ); create table users ( id varchar(21) not null constraint users_pkey primary key, name text, enabled boolean, created_at timestamp with time zone, updated_at timestamp with time zone ); create table user_role ( role_id varchar(21) not null constraint fk_user_role_role references roles, user_id varchar(21) not null constraint fk_user_role_user references users, constraint user_role_pkey primary key (role_id, user_id) ); -- data INSERT INTO public.actions (id, name, description, created_at, updated_at) VALUES ('QPjlpxmEE7fSjeTvavn0C', 'create','create', '2021-01-24T10:24:17+08:00', '2021-01-24T10:24:17+08:00'); INSERT INTO public.actions (id, name, description, created_at, updated_at) VALUES ('2iNamDFktFA6qfz_Tk5nH', 'update','update', '2021-01-24T10:24:17+08:00', '2021-01-24T10:24:17+08:00'); INSERT INTO public.actions (id, name, description, created_at, updated_at) VALUES ('kZBX-FnIYa374wt4D5OlK', 'delete','delete', '2021-01-24T10:24:17+08:00', '2021-01-24T10:24:17+08:00'); INSERT INTO public.actions (id, name, description, created_at, updated_at) VALUES ('ozXzHwl1tDLmgIwCBjQMc', 'read','read', '2021-01-24T10:24:17+08:00', '2021-01-24T10:24:17+08:00'); INSERT INTO public.resources (id, name, created_at, updated_at) VALUES ('k4Wcq9zGqShiSH6-HmR9_', 'rbac', '2021-01-24T10:24:17+08:00', '2021-01-24T10:24:17+08:00'); INSERT INTO public.resources (id, name, created_at, updated_at) VALUES ('AoiiJEVfm3Fe8gtlZvE0_', 'users', '2021-01-24T10:24:17+08:00', '2021-01-24T10:24:17+08:00'); INSERT INTO public.resources (id, name, created_at, updated_at) VALUES ('_-0lB0FJklZQf0wMCOdb3', 'devops', '2021-01-24T10:24:17+08:00', '2021-01-24T10:24:17+08:00'); INSERT INTO public.permissions (id, action_id, resource_id, created_at, updated_at, key) VALUES ('7BvEdc4TA-gDOF-mfR3Wy', 'ozXzHwl1tDLmgIwCBjQMc', '_-0lB0FJklZQf0wMCOdb3', '2021-01-24T10:24:17+08:00', '2021-01-24T10:24:17+08:00', 'read:devops'); INSERT INTO public.permissions (id, action_id, resource_id, created_at, updated_at, key) VALUES ('4vIzJkqwRPj2vN_w4Oq88', 'QPjlpxmEE7fSjeTvavn0C', 'k4Wcq9zGqShiSH6-HmR9_', '2021-01-24T10:24:17+08:00', '2021-01-24T10:24:17+08:00', 'create:rbac'); INSERT INTO public.permissions (id, action_id, resource_id, created_at, updated_at, key) VALUES ('0rhMOepRtB5GPO_6xDLZ3', 'ozXzHwl1tDLmgIwCBjQMc', 'k4Wcq9zGqShiSH6-HmR9_', '2021-01-24T10:24:17+08:00', '2021-01-24T10:24:17+08:00', 'read:rbac'); INSERT INTO public.permissions (id, action_id, resource_id, created_at, updated_at, key) VALUES ('4P3xauyVkRxinMmKPL6Lh', '2iNamDFktFA6qfz_Tk5nH', 'k4Wcq9zGqShiSH6-HmR9_', '2021-01-24T10:24:17+08:00', '2021-01-24T10:24:17+08:00', 'update:rbac'); INSE","date":"2021-01-24","objectID":"/posts/rbac1-design/:0:7","tags":["rbac1","rbac","postgres"],"title":"Rbac1 Design","uri":"/posts/rbac1-design/"},{"categories":null,"content":"DB fiddle Playground https://www.db-fiddle.com/f/4jyoMCicNSZpjMt4jFYoz5/1179 ","date":"2021-01-24","objectID":"/posts/rbac1-design/:0:8","tags":["rbac1","rbac","postgres"],"title":"Rbac1 Design","uri":"/posts/rbac1-design/"},{"categories":null,"content":"Golang 也因為開源、程式語法的簡潔開始受到程式開發人員的喜好。也因些在搭建微服務架構應用程式的時候有很多選擇，在 Web 框架中就有 Gin, Echo, Beego 等等，每一個 Web 框架都有其不同的特性，而 Go-Kit 是一個微服務開發的工具鏈，本場次將基於 Kuberentes/Istio 透過 Go-kit 搭建微服務架構應用程式實戰中的工程項目進行說明","date":"2020-11-16","objectID":"/posts/gokit-engineering-operation/","tags":["gokit","kubernetes","microservices","istio","toolchain","gophercon"],"title":"GoPherCon 2020 TW: 如何透過 Go-kit 快速搭建微服務架構應用程式實戰","uri":"/posts/gokit-engineering-operation/"},{"categories":null,"content":" 如何透過 Go-kit 快速搭建微服務架構應用程式實戰 在第一屆的 GopherCon TW 中分享 如何透過 Go-kit 快速搭建微服務架構應用程式實戰 ","date":"2020-11-16","objectID":"/posts/gokit-engineering-operation/:0:0","tags":["gokit","kubernetes","microservices","istio","toolchain","gophercon"],"title":"GoPherCon 2020 TW: 如何透過 Go-kit 快速搭建微服務架構應用程式實戰","uri":"/posts/gokit-engineering-operation/"},{"categories":null,"content":"Aganda Go-kit Layout Test Toolchain 簡單的內容總結。第一部份還是簡單的說明 Go-kit 作為一個微服務工具包的設計理念及其中的模型分層 Service, Endpoint \u0026 Transport ，在小型的應用中進行架構強制分離會覺得有一點把問題複雜化。不過在微服務數量開始變多，開發人員變多的狀況下，架構強制分離好處效益就會出現。 進而在導入 Istio Service mesh 可以讓 Go-kit 核心概念保留，把微服務組件下放至 Istio 中進行處理，使單一微服務只需要專注商業邏輯開發 Layout 的部份就是基於 golang-standards/project-layout: Standard Go Project Layout 進行一些檔案配置的安排, 配合架構強制分離讓開發者知道什麼東西該放在那裡 Test 部份依照 Service, Transport 分別進行相對應的 unitest，採用 table case 及 mock 概念 Toolchain 則強調，架構強制分離配合程式碼產生器可以加快開發的速度 ","date":"2020-11-16","objectID":"/posts/gokit-engineering-operation/:0:1","tags":["gokit","kubernetes","microservices","istio","toolchain","gophercon"],"title":"GoPherCon 2020 TW: 如何透過 Go-kit 快速搭建微服務架構應用程式實戰","uri":"/posts/gokit-engineering-operation/"},{"categories":null,"content":"補充資料 Cloud Native Buildpacks · Cloud Native Buildpacks 是 CNCF 下面的一個專案，簡單來說就是透過 container 的方式來幫你從原始碼打包 container image 而不需要編寫 Dockerfile, Google 也在今年的 Cloud Next 20’ OnAir 上宣佈 Cloud Build, Cloud Run, Cloud Shell, Cloud Function, Cloud Code \u0026 Skafflold 都已經原生支援 GoogleCloudPlatform/buildpacks Suggested builders: Google: gcr.io/buildpacks/builder:v1 Ubuntu 18 base image with buildpacks for .NET, Go, Java, Node.js, and Python Heroku: heroku/buildpacks:18 heroku-18 base image with buildpacks for Ruby, Java, Node.js, Python, Golang, \u0026 PHP Paketo Buildpacks: paketobuildpacks/builder:base Ubuntu bionic base image with buildpacks for Java, NodeJS and Golang Paketo Buildpacks: paketobuildpacks/builder:full Ubuntu bionic base image with buildpacks for Java, .NET, NodeJS, Golang, PHP, HTTPD and NGINX Paketo Buildpacks: paketobuildpacks/builder:tiny Tiny base image (bionic build image, distroless run image) with buildpacks for Golang 上面列出的是目前建議的實作 buildpack 的 builders，每一家 builder 提供的參數可能有些不一樣，就請大家參照各別的說明文件 ","date":"2020-11-16","objectID":"/posts/gokit-engineering-operation/:0:2","tags":["gokit","kubernetes","microservices","istio","toolchain","gophercon"],"title":"GoPherCon 2020 TW: 如何透過 Go-kit 快速搭建微服務架構應用程式實戰","uri":"/posts/gokit-engineering-operation/"},{"categories":null,"content":"影片 ","date":"2020-11-16","objectID":"/posts/gokit-engineering-operation/:0:3","tags":["gokit","kubernetes","microservices","istio","toolchain","gophercon"],"title":"GoPherCon 2020 TW: 如何透過 Go-kit 快速搭建微服務架構應用程式實戰","uri":"/posts/gokit-engineering-operation/"},{"categories":null,"content":"投影片 https://www2.slideshare.net/cagechung/gokit-239269720 ","date":"2020-11-16","objectID":"/posts/gokit-engineering-operation/:0:4","tags":["gokit","kubernetes","microservices","istio","toolchain","gophercon"],"title":"GoPherCon 2020 TW: 如何透過 Go-kit 快速搭建微服務架構應用程式實戰","uri":"/posts/gokit-engineering-operation/"},{"categories":null,"content":"投影片中相關的 demo cage1016/gokit-workshop Simple tutorial from http/net to Gokit skeleton cage1016/ms-demo: gokit microservice demo gokit microservice demo cage1016/gk at feature/gokitconsulk8sistio gokit toolchain ","date":"2020-11-16","objectID":"/posts/gokit-engineering-operation/:0:5","tags":["gokit","kubernetes","microservices","istio","toolchain","gophercon"],"title":"GoPherCon 2020 TW: 如何透過 Go-kit 快速搭建微服務架構應用程式實戰","uri":"/posts/gokit-engineering-operation/"},{"categories":null,"content":" KAI CHU CHUNG Cloud GDE GDG Cloud Taipei co-organizers ","date":"2020-11-09","objectID":"/about/:0:0","tags":null,"title":"About","uri":"/about/"},{"categories":null,"content":"Kubernetes Nginx ingress/Istio manifest for Gokit microservice demo","date":"2020-11-03","objectID":"/posts/gokit-ms-demo/","tags":["gokit","kubernetes","microservices","istio"],"title":"Gokit microservice demo","uri":"/posts/gokit-ms-demo/"},{"categories":null,"content":"小弟在 GDG Devfest 2019 分享過 Build go kit microservices at kubernetes with ease，Gokit 是一個建立 microservice 的 toolkit，Gokit 提出 Transport Endpoint Service 三種概念來幫助開始者進行架構分離，對單一微服務進行架構強制分離或許會增加程式碼的閱讀性，不過對一定規模的微服務來說，一致性的程式架構分離反而會增加多人開發的效率 ","date":"2020-11-03","objectID":"/posts/gokit-ms-demo/:0:0","tags":["gokit","kubernetes","microservices","istio"],"title":"Gokit microservice demo","uri":"/posts/gokit-ms-demo/"},{"categories":null,"content":"cage1016/ms-demo Service Description add Expose Sum method tictac Expose Tic/Tac method cage1016/ms-demo: gokit microservice demo 提供了使用 gokit 建立的 kubernetes/istio 的 manifest, 可以讓使用者快速的練習基於 kubernetes/istio 來搭建 gokit 微服務 ","date":"2020-11-03","objectID":"/posts/gokit-ms-demo/:1:0","tags":["gokit","kubernetes","microservices","istio"],"title":"Gokit microservice demo","uri":"/posts/gokit-ms-demo/"},{"categories":null,"content":"Install Run skaffold run (first time will be slow) Set the ADD_HTTP_LB_URL/ADD_GRPC_LB_URL \u0026 TICTAC_HTTP_LB_URL/TICTAC_GRPC_LB_URL environment variable in your shell to the public IP/port of the Kubernetes loadBalancer export ADD_HTTP_LB_PORT=$(kubectl get service add-external -o jsonpath='{.spec.ports[?(@.name==\"http\")].port}') export ADD_GRPC_LB_PORT=$(kubectl get service add-external -o jsonpath='{.spec.ports[?(@.name==\"grpc\")].port}') export ADD_LB_HOST=$(kubectl get service add-external -o jsonpath='{.status.loadBalancer.ingress[0].hostname}') export ADD_HTTP_LB_URL=$ADD_LB_HOST:$ADD_HTTP_LB_PORT export ADD_GRPC_LB_URL=$ADD_LB_HOST:$ADD_GRPC_LB_PORT echo $ADD_HTTP_LB_URL echo $ADD_GRPC_LB_URL export TICTAC_HTTP_LB_PORT=$(kubectl get service tictac-external -o jsonpath='{.spec.ports[?(@.name==\"http\")].port}') export TICTAC_GRPC_LB_PORT=$(kubectl get service tictac-external -o jsonpath='{.spec.ports[?(@.name==\"grpc\")].port}') export TICTAC_LB_HOST=$(kubectl get service tictac-external -o jsonpath='{.status.loadBalancer.ingress[0].hostname}') export TICTAC_HTTP_LB_URL=$TICTAC_LB_HOST:$TICTAC_HTTP_LB_PORT export TICTAC_GRPC_LB_URL=$TICTAC_LB_HOST:$TICTAC_GRPC_LB_PORT echo $TICTAC_HTTP_LB_URL echo $TICTAC_GRPC_LB_URL Access by command sum method curl -X POST $ADD_HTTP_LB_URL/sum -d '{\"a\": 1, \"b\":1}' or grpcurl -d '{\"a\": 1, \"b\":1}' -plaintext -proto ./pb/add/add.proto $ADD_GRPC_LB_URL pb.Add.Sum tic method curl -X POST $TICTAC_HTTP_LB_URL/tic or grpcurl -plaintext -proto ./pb/tictac/tictac.proto $TICTAC_GRPC_LB_URL pb.Tictac.Tic tac method curl $TICTAC_HTTP_LB_URL/tac or grpcurl -plaintext -proto ./pb/tictac/tictac.proto $TICTAC_GRPC_LB_URL pb.Tictac.Tac Apply istio manifests kubectl apply -f deployments/istio-manifests Set the GATEWAY_HTTP_URL/GATEWAY_GRPC_URL environment variable in your shell to the public IP/port of the Istio Ingress gateway. export INGRESS_HTTP_PORT=$(kubectl -n istio-system get service istio-ingressgateway -o jsonpath='{.spec.ports[?(@.name==\"http2\")].port}') export INGRESS_GRPC_PORT=$(kubectl -n istio-system get service istio-ingressgateway -o jsonpath='{.spec.ports[?(@.name==\"https\")].port}') export INGRESS_HOST=$(kubectl -n istio-system get service istio-ingressgateway -o jsonpath='{.status.loadBalancer.ingress[0].hostname}') export GATEWAY_HTTP_URL=$INGRESS_HOST:$INGRESS_HTTP_PORT export GATEWAY_GRPC_URL=$INGRESS_HOST:$INGRESS_GRPC_PORT echo $GATEWAY_HTTP_URL echo $GATEWAY_GRPC_URL Access by command sum method curl -X POST $GATEWAY_HTTP_URL/api/v1/add/sum -d '{\"a\": 1, \"b\":1}' or grpcurl -d '{\"a\": 1, \"b\":1}' -plaintext -proto ./pb/add/add.proto $GATEWAY_GRPC_URL pb.Add.Sum tic method curl -X POST $GATEWAY_HTTP_URL/api/v1/tictac/tic or grpcurl -plaintext -proto ./pb/tictac/tictac.proto $GATEWAY_GRPC_URL pb.Tictac.Tic tac method curl $GATEWAY_HTTP_URL/api/v1/tictac/tac or grpcurl -plaintext -proto ./pb/tictac/tictac.proto $GATEWAY_GRPC_URL pb.Tictac.Tac ","date":"2020-11-03","objectID":"/posts/gokit-ms-demo/:1:1","tags":["gokit","kubernetes","microservices","istio"],"title":"Gokit microservice demo","uri":"/posts/gokit-ms-demo/"},{"categories":null,"content":"CleanUP skaffold delete or kubectl delete -f deployments/istio-manifests ","date":"2020-11-03","objectID":"/posts/gokit-ms-demo/:1:2","tags":["gokit","kubernetes","microservices","istio"],"title":"Gokit microservice demo","uri":"/posts/gokit-ms-demo/"},{"categories":null,"content":"在雲原生時代，基於 Kubernetes 的微服務應用程式架構模式已經快變成基本動作，本議程將介紹如何在 Kubernetes 進行 Debug 來加快開發的速度","date":"2020-10-20","objectID":"/posts/devfest20-how-to-debug-microservices-on-kubernetes-as-a-pros/","tags":["devfest","microservices","debug","kubernetes"],"title":"Devfest20 How to Debug Microservices on Kubernetes as a Pros","uri":"/posts/devfest20-how-to-debug-microservices-on-kubernetes-as-a-pros/"},{"categories":null,"content":"喜歡拿 YouTube 影片來製作自己客製作的 iPhone 鈴聲，cage1016/ios-ringtone-maker-yt container 幫你一口氣從下載音頻、裁切、轉檔(漸入漸出)、輸出至本地，剩下的就是透過 Garageband 輸出至手機即可","date":"2020-06-20","objectID":"/posts/ios-ringtone-maker-from-youtube/","tags":["docker","annie","ringtone","YouTube","iOS"],"title":"iOS ringtone maker from YouTube video","uri":"/posts/ios-ringtone-maker-from-youtube/"},{"categories":null,"content":"最近大竹弟打電話問說 iOS 鈴聲在 Garageband 上面製作的檔案怎麼這麼大，其實只有 5 秒的鈴聲 先來說一下 iPhone 上配置客製的鈴聲有二種方式 iTunes Garageband 上編輯直接輸出至鈴聲 由於 macOS 10.15 版本就沒有 itunes 可以用，所以基本上網路的教學大也是直接在 Garageband 上直接編輯後直接輸出至 iPhone 的鈴聲 以前我自己也是換過不少鈴聲，以前是透過 Free Ringtones for Android and iPhone. Free Ringtone Maker - Audiko 選擇喜歡的檔案下載安裝 雖然現成的工具方便，不過有時候找不到自己喜歡的歌曲，那就土砲一個吧 ","date":"2020-06-20","objectID":"/posts/ios-ringtone-maker-from-youtube/:0:0","tags":["docker","annie","ringtone","YouTube","iOS"],"title":"iOS ringtone maker from YouTube video","uri":"/posts/ios-ringtone-maker-from-youtube/"},{"categories":null,"content":"iOS ringtone maker from YouTube video cage1016/ios-ringtone-maker-yt: iOS ringtone maker from Youtube video 基本上的流程 找到喜歡的 YouTube vide 找到想要音頻的開始秒數 ex: 00:04:00 決定鈴聲的秒數 ex: 30 是否要音頻漸入漸出效果 直接下 command container 會直接輸出 m4r copy 至 iCloud 在 Garageband 引入 m4r 輸出至鈴聲 打完收工 ","date":"2020-06-20","objectID":"/posts/ios-ringtone-maker-from-youtube/:0:1","tags":["docker","annie","ringtone","YouTube","iOS"],"title":"iOS ringtone maker from YouTube video","uri":"/posts/ios-ringtone-maker-from-youtube/"},{"categories":null,"content":"demo 找到一個 YouTube 影片 Señorita - YouTube 從 22 秒開始 共 30 秒 音頻漸入漸出效果: fadein 3 秒， fadeout 3 秒 鈴聲直接輸出在執行 docker 路徑下 ./output $ ls ./output/ Pkh8UtuejGw.m4r 剩下的就是將檔案傳至手機，透過 Garageband 輸出至 iPhone DONE! BTW. 有時候再來弄 UI ","date":"2020-06-20","objectID":"/posts/ios-ringtone-maker-from-youtube/:0:2","tags":["docker","annie","ringtone","YouTube","iOS"],"title":"iOS ringtone maker from YouTube video","uri":"/posts/ios-ringtone-maker-from-youtube/"},{"categories":null,"content":"透過 Google App Engine 和 NATS 建立 Websocket PUBSUB 伺服器","date":"2020-03-16","objectID":"/posts/gae-custom-ws/","tags":["GAE","Google compute engine","Golang","websocket","GCP","NATS","CloudBuild"],"title":"Establishing a Websocket PUBSUB server with NATS and Google App Engine","uri":"/posts/gae-custom-ws/"},{"categories":null,"content":"在設計 API server 的時候會有遇到即時訊息傳遞的需求，同步可以用 GRPC 建立連線來溝通，為了降低系統的耦合性，可以選擇非同步的方式。而 PubSub 結合 websocket 是常用的方式。對於一位 Gopher 來說，NATS 是 CNCF 下面中關於訊息傳遞的開源專案且對 Golang 友善(比 Kafka 好多了 XD)，選擇 NATS 的 PubSub 功能搭配 websocket 好像也是一個合理的選擇 在 Google App Engine 上搭建整個系統需要幾個知識點，讓我們一個一個來解釋，最後會附上完整的程式碼 Google App Engine 有一個很棒的功能是非常容易的建立 service，每一個 service 可以類比成 microservice。現在已經支援了 Python, Java, Node.js, PHP, Runy, Go 等幾種程式語言，也可以在 standard, flex, custom runtime (打包成 Docker 就不受到程式語言限制了) 中進行混搭，怎麼搭配就看題目進行選擇 不囉嗦，先看整個架構圖 這邊我們有 3 個 service + 1 個 Google compute engine instance default (us-central1): 每一個 Google App Engine 一定要有一個 default service 且要第一個進行部署 add (us-central1): 核的的 service，提供 2 個 API，sum 和 concat ws (us-central1): 透過 NATS 的 client library + gorilla websocket 來實作 NATS (asia-east1-b): NATS 的 server ","date":"2020-03-16","objectID":"/posts/gae-custom-ws/:0:0","tags":["GAE","Google compute engine","Golang","websocket","GCP","NATS","CloudBuild"],"title":"Establishing a Websocket PUBSUB server with NATS and Google App Engine","uri":"/posts/gae-custom-ws/"},{"categories":null,"content":"知識點 ","date":"2020-03-16","objectID":"/posts/gae-custom-ws/:1:0","tags":["GAE","Google compute engine","Golang","websocket","GCP","NATS","CloudBuild"],"title":"Establishing a Websocket PUBSUB server with NATS and Google App Engine","uri":"/posts/gae-custom-ws/"},{"categories":null,"content":"## Google App Engine 上實作 websocket 只能使用 flex or custom runtime 這個是一個基本限制，如果在 Google App Engine 上有建立 websocket 的需求，只能選擇 flex or custom runtime. Google 官網有好幾個程式語言的範例1 ","date":"2020-03-16","objectID":"/posts/gae-custom-ws/:1:1","tags":["GAE","Google compute engine","Golang","websocket","GCP","NATS","CloudBuild"],"title":"Establishing a Websocket PUBSUB server with NATS and Google App Engine","uri":"/posts/gae-custom-ws/"},{"categories":null,"content":"## 部著 NATS server 稍早提過，NATS 是 CNCF 下面中關於訊息傳遞的開源專案且可以視為 cloud native (rock)，部署一個 NATS server 非常簡單。docker 就可以跑了，在 Google Cloud Platfrom 上我們可以透過 Cloud Deployment Manager 一鍵部署一個 NATS Certified by Bitnami 部著成功之後可以查看到相關的訊息，包含要連線的密碼 ","date":"2020-03-16","objectID":"/posts/gae-custom-ws/:1:2","tags":["GAE","Google compute engine","Golang","websocket","GCP","NATS","CloudBuild"],"title":"Establishing a Websocket PUBSUB server with NATS and Google App Engine","uri":"/posts/gae-custom-ws/"},{"categories":null,"content":"## Google App Engine Access NATS server via Serverless VPC 當我們一開始建立 Google App Engine 專案時我問我們要部署在什麼 region northamerica-northeast1 (Montréal) us-central (Iowa) us-west2 (Los Angeles) us-west3 (Salt Lake City) us-east1 (South Carolina) us-east4 (Northern Virginia) southamerica-east1 (São Paulo) europe-west (Belgium) europe-west2 (London) europe-west3 (Frankfurt) europe-west6 (Zürich) asia-northeast1 (Tokyo) asia-northeast2 (Osaka) asia-northeast3 (Seoul) asia-east2 (Hong Kong) asia-south1 (Mumbai) australia-southeast1 (Sydney) asia 中日本，韓國，香港都有，台灣就是沒有，表示哭哭 當我們使用 standard runtime 建立的應用程式有需要跟我們自己建立的 Google compute engine instance 進行溝通時，就必需透過 VPC 進行連線，阿不是在 GCP 專案下的機器是相通的嗎？ 一個簡單的判別方式，如果服務可以讓你設定 network 相關的設定就是；Google app engine standard runtime app.yaml 並沒有 network 相關可以配置的設定 (flex, custom runtime 中有)。而在 standard runtime 的 beta 中可以讓我們在 app.yaml 透過指定 vpc_access_connector 來 Configuring Serverless VPC Access 存取 Google compute engine2 上相關的資源 ","date":"2020-03-16","objectID":"/posts/gae-custom-ws/:1:3","tags":["GAE","Google compute engine","Golang","websocket","GCP","NATS","CloudBuild"],"title":"Establishing a Websocket PUBSUB server with NATS and Google App Engine","uri":"/posts/gae-custom-ws/"},{"categories":null,"content":"## 透過 cloudbuild 部署整個 app engine application 需要的啟用的 API及權限 $ gcloud app GROUP | COMMAND [GCLOUD_WIDE_FLAG ...] 部署 Google app engine 的方式為使用 gcloud command，當數量少的時候可以手動進行部署，不過當 service 數量多時候，手動部署是很累人的，所以透過 Cloud Build 就是一個簡單的方式，要注意的部份是，在 local 時是以 gcloud auth 的身份進行部署，不過在 cloud build 中是透過 cloud build 的 service account (xxx@cloudbuild.gserviceaccount.com), 所以需在啟用相關的 API 及配置相關應的權限給 cloud build 的 service account 才不會報錯 需要特別啟用的 API Cloud Build API App Engine Admin API: 在 Cloud build 中的設定直接 enable 就好 Serverless VPC Access API cloudbuild.yaml timeout: 1200s # 20 mins steps: - id: deploy website name: gcr.io/cloud-builders/gcloud args: - app - deploy - website/app.yaml - --version=$SHORT_SHA - --project=$PROJECT_ID - -q - id: deploy add service name: gcr.io/cloud-builders/gcloud args: - beta - app - deploy - cmd/add/app.yaml - --version=$SHORT_SHA - --project=$PROJECT_ID - -q - id: build ws name: gcr.io/cloud-builders/docker entrypoint: bash args: - -exc - | docker build --tag gcr.io/$PROJECT_ID/ws:$COMMIT_SHA --tag gcr.io/$PROJECT_ID/ws:$SHORT_SHA --file Dockerfile.ws . docker push gcr.io/$PROJECT_ID/ws:$COMMIT_SHA docker push gcr.io/$PROJECT_ID/ws:$SHORT_SHA - id: deploy ws service name: gcr.io/cloud-builders/gcloud args: - beta - app - deploy - cmd/ws/app.yaml - --version=$SHORT_SHA - --project=$PROJECT_ID - --image-url=gcr.io/$PROJECT_ID/ws:$SHORT_SHA - -q - id: deploy disptach name: gcr.io/cloud-builders/gcloud args: - app - deploy - dispatch.yaml cloud build 中的流程是 deploy website: default service, golang standard runtime deploy add: add service, golang standard runtime build ws docker image and push to gcr.io deploy ws service, golang custom runtime update disptach 需要配置以下權限給 cloud build service account App Engine Admin: cloud build deploy Google app engine Cloud Build Service Account: (default) Compute Network User: Access network Serverless VPC Access User: The “vpcaccess.connectors.use” permission is required. ","date":"2020-03-16","objectID":"/posts/gae-custom-ws/:1:4","tags":["GAE","Google compute engine","Golang","websocket","GCP","NATS","CloudBuild"],"title":"Establishing a Websocket PUBSUB server with NATS and Google App Engine","uri":"/posts/gae-custom-ws/"},{"categories":null,"content":"demo Google app engine 還有一個佛心的部份就是自帶 HTTPS，所以我們實作的 websocket entrypoint 也可從 ws:// 直接轉成 wss:// (rock) ","date":"2020-03-16","objectID":"/posts/gae-custom-ws/:2:0","tags":["GAE","Google compute engine","Golang","websocket","GCP","NATS","CloudBuild"],"title":"Establishing a Websocket PUBSUB server with NATS and Google App Engine","uri":"/posts/gae-custom-ws/"},{"categories":null,"content":"repo https://github.com/cage1016/gae-custom-ws ","date":"2020-03-16","objectID":"/posts/gae-custom-ws/:3:0","tags":["GAE","Google compute engine","Golang","websocket","GCP","NATS","CloudBuild"],"title":"Establishing a Websocket PUBSUB server with NATS and Google App Engine","uri":"/posts/gae-custom-ws/"},{"categories":null,"content":"Reference Creating Persistent Connections with WebSockets, 換程式語言也對應到相關的範例 ↩︎ 現在 vpc_access_connector 屬於 beta，所以在需要使用 gcloud beta app deploy ... ↩︎ ","date":"2020-03-16","objectID":"/posts/gae-custom-ws/:4:0","tags":["GAE","Google compute engine","Golang","websocket","GCP","NATS","CloudBuild"],"title":"Establishing a Websocket PUBSUB server with NATS and Google App Engine","uri":"/posts/gae-custom-ws/"},{"categories":null,"content":"Gokit is microservice tookit and use Service/Endpoint/Transport to strict separation of concerns design. This talk to use go-kit develop microservice application integrate with consul, zipkin, prometheus, etc service and deploy on Kubernetes ","date":"2019-12-01","objectID":"/posts/devfest19-build-go-kit-microservices-at-kubernetes-with-ease/:0:0","tags":["devfest","microservices","kubernetes","golang"],"title":"Devfest19 Build Go Kit Microservices at Kubernetes With Ease","uri":"/posts/devfest19-build-go-kit-microservices-at-kubernetes-with-ease/"},{"categories":null,"content":"skaffold v38.0 開始支持 Go container debugging support，非常大程度解決先前 remote debug golang 的痛苦","date":"2019-10-04","objectID":"/posts/skaffold-debug-goland/","tags":["kubernetes","skaffold","debug","golang","vscode","GoLand"],"title":"Skaffold debug goland","uri":"/posts/skaffold-debug-goland/"},{"categories":null,"content":"今年的 Google Cloud Summit 台北場 於 9/24 在內湖萬豪酒店舉行，在主題演講中再次聽到 Cloud Code 的部份也看到比較有感覺的 Live demo Cloud Code 隨附的工具能協助您以輕鬆快速的方式編寫、部署及偵錯雲端原生的應用程式。這項產品提供 Visual Studio Code 和 IntelliJ 等 IDE 的擴充功能，方便您在 Kubernetes 上針對程式碼快速進行疊代、偵錯及部署等作業。 Cloud Code 是基於 GoogleContainerTools/skaffold: Easy and Repeatable Kubernetes Development 為基礎上再整合 Visual Studio Code 和 IntelliJ IDE, 讓開發者可以直接在 IDE 上就可以快速開發 Kubernetes 上的應用程式 基本上來說 Cloud Code 給 Visual Studio Code 和 IntelliJ IDE 的 plugin 就是基於 skaffold 打造的(如下圖)，當你在 Visual Studio Code 執行(cmd+shift+p) Cloud Code: Continues Deploy 的 log 就會知道 ","date":"2019-10-04","objectID":"/posts/skaffold-debug-goland/:0:0","tags":["kubernetes","skaffold","debug","golang","vscode","GoLand"],"title":"Skaffold debug goland","uri":"/posts/skaffold-debug-goland/"},{"categories":null,"content":"Cloud Code \u0026 debug 在談談 Skaffold debug k8s golang 的程式前，先來看看目前 Cloud Code debug 的部份支援幾種程式語言 Visual Studio Code 中 Cloud code 可以新增的專案範本 依照官方文件，現在 Cloud Code 有整合 debug 的部份有 Node.js、 Python、Java。 Go 目前不支援, 不過在 skaffold v38.0 的時候終於加進了. (Add Go container debugging support #2306)，所以就有了這一篇文章。至於本來 Cloud Code 就有整合的語言就依照官方的操作流程應該就可以正常運作，所以這邊就不在說明了 ","date":"2019-10-04","objectID":"/posts/skaffold-debug-goland/:1:0","tags":["kubernetes","skaffold","debug","golang","vscode","GoLand"],"title":"Skaffold debug goland","uri":"/posts/skaffold-debug-goland/"},{"categories":null,"content":"Golang debug \u0026 skaffold 當我們開發 kubernetes 應用程式(golang)會有 remote debug 的需求，在 skaffold v38.0 版之前 remote debug golang 是需要比較複雜的方式(docker-compose or kubernetes)) 之前我們怎麼進行 remote debug golang 編譯 binary 時需要加入 github.com/derekparker/delve/cmd/dlv 執行 binary 時需要帶入 CMD [\"/go/bin/dlv\", \"--listen=:2345\", \"--headless=true\", \"--api-version=2\", \"exec\", \"/exe\"] docker-compose \u0026 kubernetes YAML 檔都需要加入額外的聲明(完整的 yaml 範例可以看 這) ... security_opt: - apparmor:unconfined cap_add: - SYS_PTRACE ... 需要 port forwarding dlv debug port 到本機 透過 localhost port forwarding 就可以 attach 到 remote 的 golang 步驟有一點麻煩 當 skaffold v38.0 開始支援 container debugging support，事情就變簡單了 remote debug 還是需要 dlv，不過 skaffold 透過 kubernetes 中的 initContainers 的方式來幫我們載入(Mount)相關的套件(dlv/dbg)，且會自動識別 runtime 來決定載入的套件，需 golang 的部份就在 gcr.io/gcp-dev-tools/duct-tape/go，(其他的 runtime 可由 https://github.com/GoogleContainerTools/container-debug-support/ 查詢)，並且會在 metadata 的 anootation 中加上 debug.cloud.google.com/config: {\"addsvc\":{\"dlv\":56268,\"runtime\":\"go\"}} remote debug 還是需要 dlv 相關的啟動參數，skaffold 會自動幫我載入 Containers: addsvc: Container ID: docker://493a405f1dc0ee462f4e5f269ae2fdb352e8468c186cbb26905c42e0bf5675cf Image: cage1016/skaffold-debug-go-demo-addsvc:88f846061af2d34e8347a6325dcf48bb638f6baa50fd4599240fa5280054048e Image ID: docker://sha256:88f846061af2d34e8347a6325dcf48bb638f6baa50fd4599240fa5280054048e Ports: 8020/TCP, 8021/TCP, 56268/TCP Host Ports: 0/TCP, 0/TCP, 0/TCP Command: /dbg/go/bin/dlv exec --headless --continue --accept-multiclient --listen=localhost:56268 --api-version=2 /exe docker-compose \u0026 kubernetes YAML 不需要再加註其他的聲明 Cloud Code 上跑 skaffold debug 會自動幫我們建立 port forwarding Cloud Code 上進行 deubg 的設定， { \"type\": \"cloudcode\", \"language\": \"Go\", \"request\": \"attach\", \"debugPort\": 56268, \"localRoot\": \"${workspaceFolder}/go\", \"remoteRoot\": \"/go/\", \"name\": \"skaffold-debug-go-demo\", \"podSelector\": { \"app\": \"addsvc\" } } ","date":"2019-10-04","objectID":"/posts/skaffold-debug-goland/:2:0","tags":["kubernetes","skaffold","debug","golang","vscode","GoLand"],"title":"Skaffold debug goland","uri":"/posts/skaffold-debug-goland/"},{"categories":null,"content":"參加 Global GDG Leaders Summit 2018 and Google I/O 2018 心得分享","date":"2018-08-20","objectID":"/posts/gdg-summit-2018-and-google-io-2018/","tags":["devfest","Google","I/O","2018","GDG","summit"],"title":"Global GDG Leaders Summit 2018 and Google I/O 2018 經驗分享","uri":"/posts/gdg-summit-2018-and-google-io-2018/"},{"categories":null,"content":"補作業 說了好久想去 Google I/O 終於在今年達成。第一次自費參加 Google I/O 之外，也以 \u001cGCPUG.TW organizer 的身份參加了一前一天的 Global GDG Leaders Summit 20181 ","date":"2018-08-20","objectID":"/posts/gdg-summit-2018-and-google-io-2018/:0:0","tags":["devfest","Google","I/O","2018","GDG","summit"],"title":"Global GDG Leaders Summit 2018 and Google I/O 2018 經驗分享","uri":"/posts/gdg-summit-2018-and-google-io-2018/"},{"categories":null,"content":"Global GDG Leaders Summit 534 GDG Leads. 91 Counties, 99 WTM Leads 今年的 Global GDG Leaders Summit 2018 在 Google Event Center 舉辦，為期一天的活動有滿滿的 Sessions Growth Collaboration Devfest Organizer Team Culture Event Management Misc. 2 除了聽聽 Session 之外，最重要的部份就屬認識來自全球的其他 GDG 朋友 (加拿大、中國、香港、日本、澳洲、紐西蘭 etcs)。第三天晚上也參加了 Northeast Asia and Oceania Community Summit3 ","date":"2018-08-20","objectID":"/posts/gdg-summit-2018-and-google-io-2018/:1:0","tags":["devfest","Google","I/O","2018","GDG","summit"],"title":"Global GDG Leaders Summit 2018 and Google I/O 2018 經驗分享","uri":"/posts/gdg-summit-2018-and-google-io-2018/"},{"categories":null,"content":"Google I/O 2018 以往的 Google I/O Keynote 都只能在台灣熬夜觀看(台灣/加州時間15個小時)，這一次終於在現在聽 Pichai 開場(雖然是白天，身體實際上還是在熬夜 QQ)。為期3天的議程，因為算是 Google 一年一度的科技大拜拜，所以議程幾乎含括了所有的產品線，不過我大至上還是挑選跟 Cloud 及有興趣的主題來聽，另外現場還是有許多 Sandbox 可以參觀 Google Assistant Cloud Firebase / Flutter Android / Android TV / Google Play / Wear OS by Google Android Things / Nest AR / VR Design Accessibility Web Payments Experiments AI / Machine Learning Sandbox 只有現在才看的到，所以這種活動有時間還是要走完比較值得。影片都會有錄影，所以回來還是有機會可以看的。Google I/O Social 還是需要的啦，認識新朋友是一件很棒的事 Reference Global GDG Leaders Summit - Home ↩︎ Global GDG Leaders Summit 2018 agdenda ↩︎ NEAO Community Gathering ↩︎ ","date":"2018-08-20","objectID":"/posts/gdg-summit-2018-and-google-io-2018/:2:0","tags":["devfest","Google","I/O","2018","GDG","summit"],"title":"Global GDG Leaders Summit 2018 and Google I/O 2018 經驗分享","uri":"/posts/gdg-summit-2018-and-google-io-2018/"},{"categories":null,"content":"在 iOS 上可以快速複製 titl 及 url/surl 的 recipe","date":"2018-06-14","objectID":"/posts/copy2clipboardwitheasy/","tags":["iOS","workflow","recipe"],"title":"workflow recipe -  Copy2ClipboardWithEasy","uri":"/posts/copy2clipboardwitheasy/"},{"categories":null,"content":" 小弟之前在在 Chrome Extension Store 上發佈了一個簡單的小工具 copy 2 clipboard with ease - Chrome Web Store 可以快速的複製頁面的 titl/url ","date":"2018-06-14","objectID":"/posts/copy2clipboardwitheasy/:0:0","tags":["iOS","workflow","recipe"],"title":"workflow recipe -  Copy2ClipboardWithEasy","uri":"/posts/copy2clipboardwitheasy/"},{"categories":null,"content":"iOS - WorkFlow Workflows combine a bunch of steps across apps into a single tap. Collect workflows like these to save time and effort every day 一個可以在 iOS 透過拖拖拉拉的方式進行有一點像寫程式的感覺來組合各種元件來達到一些特定的功能 ","date":"2018-06-14","objectID":"/posts/copy2clipboardwitheasy/:1:0","tags":["iOS","workflow","recipe"],"title":"workflow recipe -  Copy2ClipboardWithEasy","uri":"/posts/copy2clipboardwitheasy/"},{"categories":null,"content":"Copy2ClipboardWithEasy 類似 Chrome Extension - copy 2 clipboard with ease 的功能，可以在 iOS 中進行 url/title 的複製操作 ","date":"2018-06-14","objectID":"/posts/copy2clipboardwitheasy/:1:1","tags":["iOS","workflow","recipe"],"title":"workflow recipe -  Copy2ClipboardWithEasy","uri":"/posts/copy2clipboardwitheasy/"},{"categories":null,"content":"Install workflow : Copy2ClipboardWithEasy ","date":"2018-06-14","objectID":"/posts/copy2clipboardwitheasy/:2:0","tags":["iOS","workflow","recipe"],"title":"workflow recipe -  Copy2ClipboardWithEasy","uri":"/posts/copy2clipboardwitheasy/"},{"categories":null,"content":"Reference copy 2 clipboard with ease - Chrome Web Store Copy2ClipboardWithEasy Workflow — Powerful automation made simple. ","date":"2018-06-14","objectID":"/posts/copy2clipboardwitheasy/:3:0","tags":["iOS","workflow","recipe"],"title":"workflow recipe -  Copy2ClipboardWithEasy","uri":"/posts/copy2clipboardwitheasy/"},{"categories":null,"content":"Simple demonstrate multiple way to create screenshot via phantomjs, chromeless and puppeteer and build screenshot as a service via GAE flex runtime.","date":"2017-09-09","objectID":"/posts/screenshot-as-a-service/","tags":["phantomjs","chromeless","puppeteer","GAE"],"title":"Screenshot as a Service","uri":"/posts/screenshot-as-a-service/"},{"categories":null,"content":"GCPUG Taiwan Meetup #29 Screenshot as a service cage1016/screenshot-as-a-service-demo: GCPUG Taiwan Meetup #29: screenshot as a service demo code ","date":"2017-09-09","objectID":"/posts/screenshot-as-a-service/:0:0","tags":["phantomjs","chromeless","puppeteer","GAE"],"title":"Screenshot as a Service","uri":"/posts/screenshot-as-a-service/"},{"categories":null,"content":"Waldo-gcp 一個基本 Google Map 上計算最佳路徑的實小服務 當初會想弄一個 screenshot 的服務是因為 slideshare: Waldo-gcp 中會有擷圖的需求，且需要跟 GAE 進行整合，所以選擇了滿多人使用的 PhantomJS 來實作擷圖的服務並使用 GAE flex runtime 的型式發佈到 GAE 平台上作為專案的 microservice 使用 ","date":"2017-09-09","objectID":"/posts/screenshot-as-a-service/:0:1","tags":["phantomjs","chromeless","puppeteer","GAE"],"title":"Screenshot as a Service","uri":"/posts/screenshot-as-a-service/"},{"categories":null,"content":"Phantomjs PhantomJS is a headless WebKit scriptable with a JavaScript API. It has fast and native support for various web standards: DOM handling, CSS selector, JSON, Canvas, and SVG. http://phantomjs.org/ // yahoo.com.tw.js var page = require('webpage').create(); page.viewportSize = { width: 1440, height: 900 }; page.clipRect = { top: 0, left: 0, width: 1440, height: 900 }; page.open('http://yahoo.com.tw', function() { page.render('yahoo.com.tw.png'); phantom.exit(); }); // execute $ phantomjs yahoo.com.tw.js ","date":"2017-09-09","objectID":"/posts/screenshot-as-a-service/:0:2","tags":["phantomjs","chromeless","puppeteer","GAE"],"title":"Screenshot as a Service","uri":"/posts/screenshot-as-a-service/"},{"categories":null,"content":"chromless Chrome automation made simple. Runs locally or headless on AWS Lambda. https://github.com/graphcool/chromeless const { Chromeless } = require('chromeless') async function run() { const chromeless = new Chromeless() const screenshot = await chromeless .goto('https://www.google.com') .type('chromeless', 'input[name=\"q\"]') .press(13) .wait('#resultStats') .screenshot() console.log(screenshot) // prints local file path or S3 url await chromeless.end() } run().catch(console.error.bind(console)) ","date":"2017-09-09","objectID":"/posts/screenshot-as-a-service/:0:3","tags":["phantomjs","chromeless","puppeteer","GAE"],"title":"Screenshot as a Service","uri":"/posts/screenshot-as-a-service/"},{"categories":null,"content":"puppeteer const puppeteer = require('puppeteer'); (async () =\u003e { const browser = await puppeteer.launch(); const page = await browser.newPage(); await page.goto('https://www.google.com'); await page.screenshot({path: 'google.com.png'}); browser.close(); })(); 這兒舉三個簡單的例子來說明擷圖的技術，Phantomjs, Chromeless, puppeteer, 以前 Phantomjs 很熱門，不過最近 chromeless 等技術興起，也有友好的 API 可以給開發人員使用。GoogleChrome/puppeteer: Headless Chrome Node API 更是提供高階 API 來操作 Headless Chrome ","date":"2017-09-09","objectID":"/posts/screenshot-as-a-service/:0:4","tags":["phantomjs","chromeless","puppeteer","GAE"],"title":"Screenshot as a Service","uri":"/posts/screenshot-as-a-service/"},{"categories":null,"content":"Screenshot as service via GAE custom runtime app.yaml runtime: custom env: flex service: screenshot ... handlers: - url: /.* script: app.js 由於在兒我們使用的是包了 Express 及 PhantomJS 的 custome runtime 來實作 GAE 版的 screenshot service, yaml 的重點便是指定 runtime: custom, env: flex dockerfile FROM launcher.gcr.io/google/debian8 RUN DEBIAN_FRONTEND=noninteractive apt-get update -y \u0026\u0026 apt-get install --no-install-recommends -y -q curl apt-utils build-essential ca-certificates libfreetype6 libfontconfig1 RUN echo \"deb http://http.debian.net/debian jessie-backports main\" \u003e /etc/apt/sources.list.d/backports.list \u0026\u0026 \\ apt-get update -y \u0026\u0026 \\ apt-get install -y --no-install-recommends fonts-noto fonts-noto-cjk locales-all \u0026\u0026 \\ apt-get clean \u0026\u0026 \\ apt-get autoclean \u0026\u0026 \\ apt-get autoremove \u0026\u0026 \\ rm -rf /var/lib/apt/lists/* RUN mkdir /nodejs \u0026\u0026 curl http://nodejs.org/dist/v0.12.1/node-v0.12.1-linux-x64.tar.gz | tar xvzf - -C /nodejs --strip-components=1 ENV PATH $PATH:/nodejs/bin WORKDIR /app ADD package.json /app/ RUN npm install ADD . /app ENTRYPOINT [\"/nodejs/bin/npm\", \"start\"] DockerFile 的重點則是準備好基本的 library 及 Express/Phantomjs 的配置。準備好 DockerFile，app.yaml 還有程式碼，就可以透過 gcloud -q app deploy 的指命將服務推到 GCP 上 https://waldo-gcp-testbed.appspot.com/screenshot/usage.html ","date":"2017-09-09","objectID":"/posts/screenshot-as-a-service/:0:5","tags":["phantomjs","chromeless","puppeteer","GAE"],"title":"Screenshot as a Service","uri":"/posts/screenshot-as-a-service/"},{"categories":null,"content":"簡單記鎑一下最近在專案上需要利用 go regexp 來進行字串的拆解","date":"2017-08-30","objectID":"/posts/go-regex-notebook/","tags":["golang","regexp"],"title":"notebook - golang regexp","uri":"/posts/go-regex-notebook/"},{"categories":null,"content":" 簡單記鎑一下最近在專案上需要利用 regex 來進行字串的拆解 cfg:/etc/config/a.conf = 0 Build=20160331 Version = 2.2.13 Date = 2016-06-28 RC_Number = 181 Enable= Status = complete ePassword = V2@W5Q9N91N4fXGEEyL+yXOlw== Server Type = 5 Check External IP = 10 Enable = TRUE 需要將將上述的 conf 拆分成 key, value，意外發現了一個很常好用的網站 Online regex tester and debugger: PHP, PCRE, Python, Golang and JavaScript，可以很容易的在線上即時的進行測試，更棒的地方是他還是可以產出程式碼 package main import ( \"regexp\" \"fmt\" ) func main() { var re = regexp.MustCompile(`([^=]*)=(.*)`) var str = `cfg:/etc/config/a.conf = 0 Build=20160331 Version = 2.2.13 Date = 2016-06-28 RC_Number = 181 Enable= Status = complete ePassword = V2@W5Q9N91N4fXGEEyL+yXOlw== Server Type = 5 Check External IP = 10 Enable = TRUEÅ` for i, match := range re.FindAllString(str, -1) { fmt.Println(match, \"found at index\", i) } } ","date":"2017-08-30","objectID":"/posts/go-regex-notebook/:0:0","tags":["golang","regexp"],"title":"notebook - golang regexp","uri":"/posts/go-regex-notebook/"},{"categories":null,"content":"Reference StefanSchroeder/Golang-Regex-Tutorial: Golang - Regular Expression Tutorial 基础知识 - Golang 中的正则表达式 - GoLove - 博客园 Online regex tester and debugger: PHP, PCRE, Python, Golang and JavaScript ","date":"2017-08-30","objectID":"/posts/go-regex-notebook/:0:1","tags":["golang","regexp"],"title":"notebook - golang regexp","uri":"/posts/go-regex-notebook/"},{"categories":null,"content":"fetch travel distances and duration by Google Maps Distance Matrix API via Google Cloud Functions","date":"2017-08-18","objectID":"/posts/cloudfunctions-google-maps-services/","tags":["cloudfunctions","googlemaps","GCP"],"title":"CloudFunctions Google maps service","uri":"/posts/cloudfunctions-google-maps-services/"},{"categories":null,"content":"Waldo-gcp Waldo-gcp 在 2015 時 Google I/O Extended Taipei 時分享過一個計算最佳路徑的微服務。在提供幾組 Google Maps 上有效的地址，透過 Google Maps Distance Matrix API 來計算出每一個點一點之間的旅行距離及旅行時間。再透過基因演算出計算出周遊一圈旅行最短路徑 # 提供5組 Google Maps 上有效的地址 台北市內湖區瑞光路227號1樓, 高雄市鼓山區美術東二路106號, 台南市長榮路一段175號, 臺北市松山區南京東路五段123巷1弄15號, 高雄市五福四路131號2樓 # 透過 Google Maps Distance Matrix API 計算出 origin, destination, distance, duration 台北市內湖區瑞光路227號1樓, 高雄市鼓山區美術東二路106號, 352777, 13532 台北市內湖區瑞光路227號1樓, 台南市長榮路一段175號, 314041, 12166 台北市內湖區瑞光路227號1樓, 臺北市松山區南京東路五段123巷1弄15號, 5167, 783 台北市內湖區瑞光路227號1樓, 高雄市五福四路131號2樓, 356215, 14018 高雄市鼓山區美術東二路106號, 台南市長榮路一段175號, 46668, 3203 高雄市鼓山區美術東二路106號, 臺北市松山區南京東路五段123巷1弄15號, 355397, 14131 高雄市鼓山區美術東二路106號, 高雄市五福四路131號2樓, 4166, 748 台南市長榮路一段175號, 臺北市松山區南京東路五段123巷1弄15號, 314250, 12475 台南市長榮路一段175號, 高雄市五福四路131號2樓, 49930, 3339 臺北市松山區南京東路五段123巷1弄15號, 高雄市五福四路131號2樓, 359485, 14338 ","date":"2017-08-18","objectID":"/posts/cloudfunctions-google-maps-services/:0:1","tags":["cloudfunctions","googlemaps","GCP"],"title":"CloudFunctions Google maps service","uri":"/posts/cloudfunctions-google-maps-services/"},{"categories":null,"content":"CloudFunctions Google maps service Google Cloud Functions is a lightweight compute solution for developers to create single-purpose, stand-alone functions that respond to Cloud events without the need to manage a server or runtime environment - Google Cloud Functions Documentation Waldo-gcp 微服務中透過 flex runtime GAE Python 中的 library(googlemaps) 來呼叫 Google Maps Distance Matrix API. Google Function 在這很適合取代原來 Python 版本的 Google Maps Distance Matrix API. Cloud functions 可以建立 Background Funtions, HTTP Functions + HTTP Triggers, Cloud Pub/Sub Triggers, Cloud Storage Triggers, Direct Triggers. 所以我們可以建立一個可以執行 Google Maps Distance Matrix API 的 Cloud Functions, 透過起 HTTP Triggers, Direct Triggers 即可以建立計算旅行路徑的距離及時間 ","date":"2017-08-18","objectID":"/posts/cloudfunctions-google-maps-services/:0:2","tags":["cloudfunctions","googlemaps","GCP"],"title":"CloudFunctions Google maps service","uri":"/posts/cloudfunctions-google-maps-services/"},{"categories":null,"content":"Getting Started Github repo: cage1016/cloudfunctions-google-maps-services # clone repo $ git git@github.com:cage1016/cloudfunctions-google-maps-services.git \u0026\u0026 cd cloudfunctions-google-maps-services # install node packages $ npm install 修改 index.js 中 API Key, \u003cYOUR-GCP-API-KEY\u003e, 並確保你的 GCP 專案有啟用 Google Maps Distance Matrix API const googleMapsClient = require('@google/maps').createClient({ key: '\u003cYOUR-GCP-API-KEY\u003e' }) ... ","date":"2017-08-18","objectID":"/posts/cloudfunctions-google-maps-services/:1:0","tags":["cloudfunctions","googlemaps","GCP"],"title":"CloudFunctions Google maps service","uri":"/posts/cloudfunctions-google-maps-services/"},{"categories":null,"content":"distanceMatrix background 修改 makefile 中 BUCKET=\u003cYOUR-GCS-BUCKET\u003e Google Cloud Storage Bucket, Bucket 為 Cloud Functions 上傳的位置 修改完依序執行即可 # deploy distanceMatrix $ make deploy_backend # call distanceMatrix $ make call_backend # log distanceMatrix $ make log_backend # show description of distanceMatrix function $ make describe_backend ","date":"2017-08-18","objectID":"/posts/cloudfunctions-google-maps-services/:1:1","tags":["cloudfunctions","googlemaps","GCP"],"title":"CloudFunctions Google maps service","uri":"/posts/cloudfunctions-google-maps-services/"},{"categories":null,"content":"distanceMatrix background 修改 https://\u003cYOUR_REGION\u003e-\u003cYOUR_PROJECT_ID\u003e.cloudfunctions.net/distanceMatrixHttp endpoint, endpoints 可由 make deploy_http 中得到 修改完依序執行即可 # deploy distanceMatrixHttp $ make deploy_http # call distanceMatrixHttp $ make call_http # log distanceMatrixHttp $ make log_http # show description of distanceMatrixHttp function $ make describe_http ","date":"2017-08-18","objectID":"/posts/cloudfunctions-google-maps-services/:1:2","tags":["cloudfunctions","googlemaps","GCP"],"title":"CloudFunctions Google maps service","uri":"/posts/cloudfunctions-google-maps-services/"},{"categories":null,"content":"CloudFunctions ","date":"2017-08-18","objectID":"/posts/cloudfunctions-google-maps-services/:1:3","tags":["cloudfunctions","googlemaps","GCP"],"title":"CloudFunctions Google maps service","uri":"/posts/cloudfunctions-google-maps-services/"},{"categories":null,"content":"Reference googlemaps/google-maps-services-js: Node.js client library for Google Maps API Web Services Developer’s Guide | Google Maps Distance Matrix API | Google Developers Google Cloud Functions Documentation | Cloud Functions | Google Cloud Platform ","date":"2017-08-18","objectID":"/posts/cloudfunctions-google-maps-services/:2:0","tags":["cloudfunctions","googlemaps","GCP"],"title":"CloudFunctions Google maps service","uri":"/posts/cloudfunctions-google-maps-services/"},{"categories":null,"content":"wedding endpoint Service 負責整個專案最重要的資料收集部份，此篇建立簡單的範例來說明 endpoint API 的使用方式","date":"2017-07-12","objectID":"/posts/weddingcnp-via-gcp-3/","tags":["GAE","GCE","Datastore","EndpointAPI","sendgrid","API"],"title":"weddingcnp via GCP - 3. endpointAPI 設計實作","uri":"/posts/weddingcnp-via-gcp-3/"},{"categories":null,"content":"此篇就對 Cage \u0026 Ping wedding 中實作專案中最為重要的 backend API (endpoint API) 部份進行簡單的說明，每一個 Google App Engine Service 實作的細節會在後序的篇幅中介紹 weddingcnp 系例傳送門 weddingcnp via GCP 簡介 weddingcnp via GCP - 1. 專案架構切分 weddingcnp via GCP - 2. 前端頁面設計實作 weddingcnp via GCP - 3. endpointAPI 設計實作 weddingcnp 前端 vue.js 設計實作 weddingcnp edm 寄送 sendgrid endpointAPI 設計實作 Cage \u0026 Ping wedding 的網站大至上可以區分為靜態頁面(frontend Service, Golang) 及負責資料收集的 API (endpoints Service, Python). Google Endpoints API1 是架構在 GAE 上的一個 RPC (remote procedure call) 服務。由於 endpoints API 是基於 ProtoRPC remote.Service 實作出來的，所以在實作我們的方法時也是依照 protorpc 的方式來定義，小弟在寫 Cage \u0026 Ping wedding 這一個網站的時候 Endpoints API 還是 1.0，所以這篇文章還是以 Endpoints API 1.0 來說明 ","date":"2017-07-12","objectID":"/posts/weddingcnp-via-gcp-3/:0:0","tags":["GAE","GCE","Datastore","EndpointAPI","sendgrid","API"],"title":"weddingcnp via GCP - 3. endpointAPI 設計實作","uri":"/posts/weddingcnp-via-gcp-3/"},{"categories":null,"content":"endpoint API demo project 小弟我建立一個比較簡單的範例來說明 https://github.com/cage1016/endpoint-api-demo # git clone repo $ git clone git@github.com:cage1016/endpoint-api-demo.git # install GAE python requirement packages $ pip install -r requirements.txt -t lib Collecting arrow==0.8.0 (from -r requirements.txt (line 1)) Collecting python-dateutil (from arrow==0.8.0-\u003e-r requirements.txt (line 1)) Downloading python_dateutil-2.6.1-py2.py3-none-any.whl (194kB) 100% |████████████████████████████████| 194kB 1.2MB/s Collecting six\u003e=1.5 (from python-dateutil-\u003earrow==0.8.0-\u003e-r requirements.txt (line 1)) Using cached six-1.10.0-py2.py3-none-any.whl Installing collected packages: six, python-dateutil, arrow Successfully installed arrow python-dateutil-2.2 six-1.10.0 ... # run GAE python locally $ dev_appserver.py app.yaml INFO 2017-07-12 13:30:19,063 devappserver2.py:116] Skipping SDK update check. INFO 2017-07-12 13:30:19,706 api_server.py:312] Starting API server at: http://localhost:51100 INFO 2017-07-12 13:30:19,710 dispatcher.py:226] Starting module \"default\" running at: http://localhost:8080 INFO 2017-07-12 13:30:19,711 admin_server.py:116] Starting admin server at: http://localhost:8000 # visit http://localhost:8080 完全上述步驟後透過瀏覽器訪問 http://localhost:8080/_ah/api/explorer 就可以得到圖一中類似 Google API explorer 風格的本地測試頁面, 這是一個非常方便的工具，可以讓自己在本地透過瀏覽器直接操作自己定義的 endpointAPI 專案架構 . ├── apis // endpoint api packages │ ├── __init__.py │ └── books.py ├── lib ├── app.py // 主程式進入點 ├── app.yaml // GAE 配置檔 ├── appengine_config.py // lib 載入配置 ├── models.py // GAE Datastore 檔 ├── requirements.txt // GAE python 引用資源庫 ├── settings.py // 專案設定檔 └── utils.py // helpers function 一個 GAE endpoint API Service 大至上進行簡單的配置可以執行了 app.yaml module: default runtime: python27 api_version: 1 threadsafe: yes handlers: - url: /_ah/spi/.* script: app.API secure: always libraries: - name: endpoints version: latest app.yaml 配置上的重點為在 handlers 區塊加入 /_ah/spi/.* 這一個 route 並將 route 導至 endpoints API server app.py import endpoints from apis import books API = endpoints.api_server([ books.BooksAPI ]) endpoints api server 由 endpoints.api_server([]) 建立, 其中的參數是實作 protorpc.remote.Service 類別的 API, 目前我們只有實作一個 books.BooksAPI 所以只有填入一個 settings.py ... books_api = endpoints.api(name='dummy', version='v1', description='dummy API', allowed_client_ids=[CLIENT_ID, endpoints.API_EXPLORER_CLIENT_ID], scopes=[endpoints.EMAIL_SCOPE]) 在我們定義的 protorpc.remote.Service API 上加一個 Decorate2 來描述我們的 API(API 名稱、版號、說明、允許呼叫的 GCP CLIENT_ID, scopes 等等) @util.positional(2) def api(name, version, description=None, hostname=None, audiences=None, scopes=None, allowed_client_ids=None, canonical_name=None, auth=None, owner_domain=None, owner_name=None, package_path=None, frontend_limits=None, title=None, documentation=None, auth_level=None): api/books.py @books_api.api_class(resource_name=\"books\") class BooksAPI(remote.Service): \"\"\" Books API \"\"\" @endpoints.method(BOOKS_LIST_RESOURCE, BookForms, path=\"books\", http_method=\"GET\", name=\"list\") def listBooks(self, request): \"\"\"List books\"\"\" ... @endpoints.method(BOOKS_CREATE_RESOURCE, BookForm, path=\"books\", http_method=\"POST\", name=\"post\") def addBook(self, request): \"\"\"Add books\"\"\" ... @endpoints.method(BOOKS_DELETE_RESOURCE, BooleanMessage, path=\"books/{websafeKey}\", http_method=\"DELETE\", name=\"delete\") def deleteBook(self, request): \"\"\"Delete book\"\"\" ... @endpoints.method(BOOKS_UPDATE_RESOURCE, BookForm, path=\"books/{websafeKey}\", http_method=\"PUT\", name=\"put\") def updateBook(self, request): \"\"\"Update book\"\"\" ... 在定義 resource 下的方法時依然使用 Decorate 的方式來對方法進行設置 (method name, path, http method, cache control, scopes, audiences, client ids and auth_level 等) @util.positional(2) def method(request_message=message_types.VoidMessage, response_message=message_types.VoidMessage, name=None, path=None, http_method=‘POST’, cache_control=None, scopes=None, audiences=None, allowed_client_ids=None, auth_level=None): 設置完 endpointAPI 的基本架構，剩下的部份就是 GAE Python3 的基本操作，定義 Datastore module、對 Datastore 進行 CRUD 的操作。有興","date":"2017-07-12","objectID":"/posts/weddingcnp-via-gcp-3/:0:1","tags":["GAE","GCE","Datastore","EndpointAPI","sendgrid","API"],"title":"weddingcnp via GCP - 3. endpointAPI 設計實作","uri":"/posts/weddingcnp-via-gcp-3/"},{"categories":null,"content":"curl 透過瀏覽器操作過後，透過 curl 操作的結果也是一樣的 $ curl http://localhost:8080/_ah/api/dummy/v1/books { \"items\": [ { \"name\": \"Shel Silverstein\", \"title\": \"The Giving Tree\", \"websafeKey\": \"aghkZXZ-Tm9uZXIZCxIEQm9vayIPVGhlIEdpdmluZyBUcmVlDA\" }, { \"name\": \"Harper Lee\", \"title\": \"To Kill a Mockingbird\", \"websafeKey\": \"aghkZXZ-Tm9uZXIfCxIEQm9vayIVVG8gS2lsbCBhIE1vY2tpbmdiaXJkDA\" }, { \"name\": \"dfad\", \"title\": \"fdafd\", \"websafeKey\": \"aghkZXZ-Tm9uZXIPCxIEQm9vayIFZmRhZmQM\" } ] } Endpoints API 2.0 的版本已經出來了，相較於 1.0 改變滿大的，原先像 Google API explorer 的部份由 swagger 取代，詳細的說明請見官網 ↩︎ 在定義 API 說明時有二種方式。這邊採用的是 @books_api.api_class，在 books_api 下允許定義多組 RESTful resource ↩︎ go-endpoints 其實 go 版的寫法更為簡潔一點 ↩︎ gRPC API Service ↩︎ Cloud Endpoints Frameworks for App Engine ↩︎ ","date":"2017-07-12","objectID":"/posts/weddingcnp-via-gcp-3/:0:2","tags":["GAE","GCE","Datastore","EndpointAPI","sendgrid","API"],"title":"weddingcnp via GCP - 3. endpointAPI 設計實作","uri":"/posts/weddingcnp-via-gcp-3/"},{"categories":null,"content":"weddingcnp frontend Service 使用了 GAE standard runtime 搭配 echo 網頁框架實作","date":"2017-06-18","objectID":"/posts/weddingcnp-via-gcp-2/","tags":["GAE","GCE","Datastore","EndpointAPI","sendgrid","API"],"title":"weddingcnp via GCP - 2. 前端頁面設計實作","uri":"/posts/weddingcnp-via-gcp-2/"},{"categories":null,"content":"此篇就對 Cage \u0026 Ping wedding frontend Service 使用了 GAE standard runtime 搭配 echo 網頁框架實作介紹 weddingcnp 系例傳送門 weddingcnp via GCP 簡介 weddingcnp via GCP - 1. 專案架構切分 weddingcnp via GCP - 2. 前端頁面設計實作 weddingcnp via GCP - 3. endpointAPI 設計實作 weddingcnp 前端 vue.js 設計實作 weddingcnp edm 寄送 sendgrid weddingcnp 前端頁面設計實作 Cage \u0026 Ping wedding frontend Service(Module) 主要的功能如下 serve 靜態資源(audio、js、images、css)，serve 動態資源(婚紗照片由 Google Cloud Storage 提供) 服務整個主體的網站架構中模版 首頁介紹頁 婚妙相簿頁 婚宴地點介紹引導頁(訂婚、結婚) 報名頁面(我要參加)1 隱藏網頁(求婚影片搶先看)，連結由喜帖中的 QR code 提供 bingo 遊戲 frontend Service . ├── public // static resource │ ├── audio │ ├── css │ ├── images │ └── js ├── templates // html templates │ ├── bingo.tmpl // bingo game │ ├── chiayi.tmpl // 地點引導 │ ├── gallery.tmpl // 婚紗相簿 │ ├── greeting.tmpl // 隱藏網頁，連結由喜帖中的 QR code 提供 │ ├── index.tmpl │ ├── layout.tmpl │ ├── live.tmpl │ ├── luzhu.tmpl // 地點引導 │ └── rsvp.tmpl // 報名頁面 ├── app-engine.go ├── app-standalone.go // Google App Engine entry point ├── app.go ├── app.yaml // frontend services yaml ├── index.yaml // index for Datastore └── main.go // echo framework entry point ","date":"2017-06-18","objectID":"/posts/weddingcnp-via-gcp-2/:0:0","tags":["GAE","GCE","Datastore","EndpointAPI","sendgrid","API"],"title":"weddingcnp via GCP - 2. 前端頁面設計實作","uri":"/posts/weddingcnp-via-gcp-2/"},{"categories":null,"content":"Google App Engine Basic Google App Engine 現在有提供 Standard 及 Flexible 的版本 Standard: Python 2.7 Java 7 PHP 5.5 Go 1.62 Flexible: Python 2.7/3.5 Java 8 Node.js Go 1.8 Ruby PHP 5,6,7 .Net Custom Runtimes 二者最大的差異是 Standard runtime 為 Google Fully management，所以享有每天 28 instance FREE 的配額3，Flexible runtime 是以 GCE 的 instance 來跑，所以基本上的計價方式就是以 GCE 的計算方式，以分計費(最少收 10 分鐘的錢)，且因為是 GCE 的方式來跑，因此彈性上就會比 Standard runtime 的來的大，不過缺點就是一開機器就開始算錢惹。在 weddingcnp 專案一開始就希望能夠少花一點錢，評估上 Standard runtime 就已經滿足需求 Cage \u0026 Ping wedding frontend Service(Module) 選擇使用了 Standard runtime 中 Go 語言的實作方式。由於前端需求並不複雜且 Go 實作的方式要比 Python 來的簡潔，部署至 Google App Engine 上的專案大小、記憶體的表現都上 Go 的表現要來的比 Python 來的要好，因此選擇了 Go 來實作。 各位朋友就端看自己的需求來評估要使用那一種 runtime ","date":"2017-06-18","objectID":"/posts/weddingcnp-via-gcp-2/:1:0","tags":["GAE","GCE","Datastore","EndpointAPI","sendgrid","API"],"title":"weddingcnp via GCP - 2. 前端頁面設計實作","uri":"/posts/weddingcnp-via-gcp-2/"},{"categories":null,"content":"Google App Engine: hello example app.yaml runtime: go api_version: go1 handlers: - url: /.* script: _go_app hello.go package hello import ( \"fmt\" \"net/http\" ) func init() { http.HandleFunc(\"/\", handler) } func handler(w http.ResponseWriter, r *http.Request) { fmt.Fprint(w, \"Hello, world!\") } # start GAE server $ dev_appserver.py app.yaml INFO 2017-06-18 04:02:36,963 devappserver2.py:692] Skipping SDK update check. INFO 2017-06-18 04:02:37,519 api_server.py:272] Starting API server at: http://localhost:54584 INFO 2017-06-18 04:02:37,522 dispatcher.py:205] Starting module \"default\" running at: http://localhost:8080 INFO 2017-06-18 04:02:37,524 admin_server.py:116] Starting admin server at: http://localhost:8000 # fetch $ curl http://localhost:8080 Hello, world! ","date":"2017-06-18","objectID":"/posts/weddingcnp-via-gcp-2/:2:0","tags":["GAE","GCE","Datastore","EndpointAPI","sendgrid","API"],"title":"weddingcnp via GCP - 2. 前端頁面設計實作","uri":"/posts/weddingcnp-via-gcp-2/"},{"categories":null,"content":"Weddingcnp frontend Go 由語言中原生就有提供 net/http 的 package 可以使用，所以可以很輕易的建立一個 Google App Engine Go Standard 的應用程式，不過 Google App Engine 還是可以搭配使用其他的網頁框架: gin-gonic/gin、echo 等，weddingcnp 使用了 echo 這一套輕量的網頁框架 Google App Engine Standard 是由 Google fully management，因此在使用 echo 框架4需要特別的的調整一下 app-engin.go // +build appengine package main import ( \"github.com/labstack/echo\" \"github.com/labstack/echo/engine/standard\" \"net/http\" ) func createMux() *echo.Echo { e := echo.New() // note: we don't need to provide the middleware or static handlers, that's taken care of by the platform // app engine has it's own \"main\" wrapper - we just need to hook echo into the default handler s := standard.New(\"\") s.SetHandler(e) http.Handle(\"/\", s) return e } app-standalone.go // +build !appengine,!appenginevm package main import ( \"github.com/labstack/echo\" \"github.com/labstack/echo/engine/standard\" \"github.com/labstack/echo/middleware\" ) func createMux() *echo.Echo { e := echo.New() e.Use(middleware.Recover()) e.Use(middleware.Logger()) e.Use(middleware.Gzip()) e.Use(middleware.Static(\"public\")) return e } func main() { e.Run(standard.New(\":8080\")) } app.go package main // reference our echo instance and create it early var e = createMux() main.go package main ... /** * RSVP page */ func rsvpGET(c echo.Context) error { var p = \u0026Page{} p.Name = \"slider-title-page\" p.MenuIconWhite = true r.HTML(c.Response().(*standard.Response).ResponseWriter, http.StatusOK, \"rsvp\", p) return nil } ... func init() { e.GET(\"/\", indexGET) e.GET(\"/gallery\", galleryGET) e.GET(\"/chiayi\", chiayiGET) e.GET(\"/luzhu\", luzhuGET) e.GET(\"/rsvp\", rsvpGET) e.GET(\"/greeting\", greetingGET) e.GET(\"/live\", liveGET) e.GET(\"/bingo\", bingoGet) e.GET(\"/img\", imgServe) e.SetHTTPErrorHandler(ErrorHandler) } 透過 app-engine.go、app-standalone.go、app.go、main.go 的調整，就可以在 Google App Engine Standard runtime 上使用 echo 框架(不過僅限 Go 1.6)。在頁面 Render 的部份則是使用 github.com/unrolled/render 模版系統來建置。相簿的照片是放在 Google Cloud Storage 透過 Image API 來取存5，大至上都是很單純的頁面 此篇大至上說明 Cage \u0026 Ping wedding frontend Service(Module) 實作的方式。比較可惜的是目前 Go 主要的版本已經到 1.8.3, 1.9 Beta 也公佈了，而 Google App Engine Standard runtime 只有支援 Go 1.6 (1.8 應該快要支援), 當 Google App Engine Standard runtime 支援 Go 1.8 時才會有比較多的框架來搭配，目前就使用容易性來說還是 Flexible runtime 較好 報名頁面實作細節會再後序的篇幅說明 ↩︎ Google App Engine Standard 支援 1.8 的版本應該快了(1.9 Beta 都出來了 XD) ↩︎ Google App Engine Standard 享有一些免費的配額，細項請看 Quotas ↩︎ Google App Engine Recipe | Echo - High performance, minimalist Go web framework, 由於 GAE 目前只有支持 Go 1.6，且 Go 1.7 以後將 context 改為內建 package，一些依賴的 package 也跟著升級了，所以目前建議使用 Flexible 會比較簡單 ↩︎ GAE go Image API for GCS · Kaichu.io ↩︎ ","date":"2017-06-18","objectID":"/posts/weddingcnp-via-gcp-2/:3:0","tags":["GAE","GCE","Datastore","EndpointAPI","sendgrid","API"],"title":"weddingcnp via GCP - 2. 前端頁面設計實作","uri":"/posts/weddingcnp-via-gcp-2/"},{"categories":null,"content":"weddingcnp 使用 dispatch.yaml 來進行專案架構上的切分，利用 makefile 來加速部署的流程、速度","date":"2017-06-12","objectID":"/posts/weddingcnp-via-gcp-1/","tags":["GAE","GCE","Datastore","EndpointAPI","sendgrid","API"],"title":"weddingcnp via GCP - 1. 專案架構切分","uri":"/posts/weddingcnp-via-gcp-1/"},{"categories":null,"content":"此篇就對 Cage \u0026 Ping wedding 中實作的專案架構進行簡單的說明，每一個 Google App Engine Service 實作的細節會在後序的篇幅中介紹 weddingcnp 系例傳送門 weddingcnp via GCP 簡介 weddingcnp via GCP - 1. 專案架構切分 weddingcnp via GCP - 2. 前端頁面設計實作 weddingcnp via GCP - 3. endpointAPI 設計實作 weddingcnp 前端 vue.js 設計實作 weddingcnp edm 寄送 sendgrid weddingcnp 專案架構 Cage \u0026 Ping wedding 完全架構在 Google App Engine 上，再功能任務上需要達到幾個要求 服務靜態頁面, 一堆的 html/css/javascript 及些許的動態資料 作為 API 的伺服器，收集前端表單送過來的資料並儲存至 Datastore 中 webmasters domain owner project structure . ├── endpoints // endpoints instance │ ├── apis │ ├── handler │ ├── lib │ ├── app.py │ ├── app.pyc │ ├── app.yaml │ └── ... ├── frontend // frontend instance │ ├── public // 公開資源 │ │ ├── audio // 音樂檔 │ │ ├── css // 靜態網頁用 css │ │ ├── images // 靜態網頁用 image │ │ └── js // 靜態網頁用 javascript │ ├── templates // golang 模版 │ │ ├── bingo.tmpl │ │ ├── ..... │ │ └── rsvp.tmpl │ ├── app-engine.go │ ├── app-standalone.go │ ├── app.go │ ├── app.yaml │ ├── index.yaml │ └── main.go ├── ownership // webmaster instance │ ├── app.yaml │ └── googleae8f4bcce8bec00c.html ├── dispatch.yaml // dispatch.yaml └── makefile // cli helper makefile 整個專案的檔案架構如上，可以分為 endpoints、frontend、ownership 三個 Service(Module), 而 Google App Engine 可以非常有彈性的透過 Service1 的方式針對不同的任務給予不同資源2，而 Cage \u0026 Ping wedding 基本上使用預計的部份就足夠了，不需特別指派 dispatch.yaml dispatch: - url: \"*/_ah/spi/*\" module: default - url: \"*/tasks/*\" module: default - url: \"*/favicon.ico\" module: frontend - url: \"*/googleae8f4bcce8bec00c.html\" module: ownership - url: \"*/*\" module: frontend 上述的 dispatch.yaml 可以幫我們重導流量至我們設定的 Service(Module)，不過在部署的部份則是需要一個一個 Service(Module)來進行部署，部署完之後會在 Google App Engine Services 中看到所有的 Services 再則我們可以透過 version3 的方式來管理部署的 Service 當 Google App Engine Service 切分的越細，雖然可以任務的資源給予更細的調整，不過卻也造成部署上的複雜度，因此可以透過 mikefile 來加速部署的流程與速度 makefile ACCOUNT = cage.chung@gmail.com PROJECT = weddingcnp VERSION = b7484dd NODE_BIN = $(shell npm bin) set_config: gcloud config set account $(ACCOUNT) gcloud config set project $(PROJECT) install: # endpoints dependency pakcage pip install -r endpoints/requirements.txt -t endpoints/lib run: # node devServer.js \u0026 #goapp serve dispatch.yaml frontend/app.yaml endpoints/app.yaml ownership/app.yaml dev_appserver.py dispatch.yaml frontend/app.yaml endpoints/app.yaml ownership/app.yaml --appidentity_email_address=save-avatar@weddingcnp.iam.gserviceaccount.com --appidentity_private_key_path=/Users/cage/.gvm/pkgsets/go1.7/global/src/github.com/cage1016/weddingcnp/endpoints/weddingcnp-3a652c96507d.pem --skip_sdk_update_check=yes --host 0.0.0.0 --enable_sendmail=yes update_frontend: goapp deploy -application $(PROJECT) -version $(VERSION) frontend/app.yaml update_endpoints: goapp deploy -application $(PROJECT) -version $(VERSION) endpoints/app.yaml update_ownership: appcfg.py update --application=$(PROJECT) --version=1 ownership/app.yaml update_dispatch: appcfg.py --application=$(PROJECT) --version=$(VERSION) update_dispatch . update_index: appcfg.py --application=$(PROJECT) --version=$(VERSION) update_indexes endpoints update_queue: appcfg.py --application=$(PROJECT) --version=$(VERSION) update_queues endpoints update: update_frontend update_endpoints update_ownership update_dispatch update_index update_queue Service == Module, 以前的名子叫作 Module, 後來改名為 Service，透過 dispatch.yaml 來指定，可以針對 Service 給予不同的 runtime、機器資源或是用另一種程式語言混搭 ↩︎ waldogcp 一個也是基於 GCP 上建構出來的最佳路徑服務，亦使用 dispatch.yaml 來指派，對於服務中運算最重的部份(基因演算法)給予較大的機器 ↩︎ 將版號命名為 git 的 commit, 可以讓自己比較容易進行 Service 的版本管控 ↩︎ ","date":"2017-06-12","objectID":"/posts/weddingcnp-via-gcp-1/:0:0","tags":["GAE","GCE","Datastore","EndpointAPI","sendgrid","API"],"title":"weddingcnp via GCP - 1. 專案架構切分","uri":"/posts/weddingcnp-via-gcp-1/"},{"categories":null,"content":"weddingcp 是一個為自已結婚時使用 Google Cloud Platform 為基礎客製的網站，用來收集報名資訊及婚紗線上展示相關事宜用","date":"2017-06-08","objectID":"/posts/weddingcnp-via-gcp/","tags":["GAE","GCE","Datastore","EndpointAPI","sendgrid","API"],"title":"weddingcnp via GCP","uri":"/posts/weddingcnp-via-gcp/"},{"categories":null,"content":"Cage \u0026 Ping wedding 是一個我們為結婚喜宴處理朋友出席報名相關事宜特別開發的網站，所有的服務全部建構在 Google Cloud Platform 上 功能大至如下: 喜宴相關資訊 訂婚場/結婚場時間、地點、交通資訊 出席人數統計(強制使用 Google/Facebook 登入)。訂婚場/結婚場，人數、葷素、兒童椅等，需不需要住宿 婚紗搶先看，先公開一部份。喜宴當天再公佈所有照片 喜宴進行中的 Bingo 遊戲 EDM (發佈 email 給參加的朋友) GA (關心一下有多少人來看) 因為我們規劃了一些特別的梗(其實是要幫每一個出席的人作一張專屬的桌卡)，所需要每一個人的大頭照(avatar)，立馬就動到使用 Google/Facebook 進行登入，授權後程式能夠自動的抓到每一個人的照片，雖然不是每一個人的照片解析度都夠進行後制的加工，不過已經可以節省下非常多的時間 有結過婚的朋友都非常的清楚，統計出席人數是一件很麻煩的事情，出席的大人數、小孩數、小孩有沒有佔位、需不需要兒童座椅、有沒有住宿的需求。種種的資料統計很麻煩，所以就計設出一個表單，想出席的朋友直接登入 Google/Facebook 帳號後，填完相關問題的表單送出後就好了，收單前可以俢改資料(這塊踩到大的雷，透過 Google Analytic 可以很多是直接使用手機登入網站，不過遇到表單無法送出的問題，後來針對相容性作調整後才讓大家順利的報完名) ","date":"2017-06-08","objectID":"/posts/weddingcnp-via-gcp/:0:0","tags":["GAE","GCE","Datastore","EndpointAPI","sendgrid","API"],"title":"weddingcnp via GCP","uri":"/posts/weddingcnp-via-gcp/"},{"categories":null,"content":"weddingcnp architecture 上面是 weddingcnp 的架構圖，整個網站完全是架構在 Google App Engine 上，透過 dispatch.yaml 的設定將流量切為服務前端靜態網頁(golang + vue.js + auth0)及後端 endpoint API 的部份。前後端為不同的 instance, 可以容易在 Google App Engine 的管理介面中計對前後端別分進行版控 Enpoints API 作為接收前端送過來的資料，並接報名相關資料儲存到 Google DataStore, 並自動將使用者的 Avatar 儲存到 Google Cloud Storage 並將所有的名單透過 Google client API 轉存一份至 Google Drive 方便後序處理。只要有人報名會自動透過 sendgrid 寄通知到自己的信箱，不需一直去盯著 Google Spreadsheet 上面的名單有沒有增加 整個構架的實作細節我會分為五個部份來說明, 先把標題寫出來，內容會陸續的補上 1. weddingcnp 專案架構切分 使用 Google App Engine golang standard runtime 來作為網站的服務器，選擇使用吃資源較少的 golang，機器平均開機後的記憶體大約 200-300 MB, 效能比 Python 的好太多了 使用 dispatch.yaml 來進行服務的切分，將 endpoint API 的部份導至另外的 instance 作處理 2. weddingcnp 前端頁面設計實作 前端使用 echo 框架搭配 template 來產出頁面 3. weddingcnp endpointAPI 設計實作 利用 dispatch.yaml 來指定 endpoint API 實作的 Service，這邊基本 endpoint API 熟悉度使用 Python 版本，service 的另一個好處是可以再同一個專案下使用混合的語言來發開，這兒的例子是前端使用 golang, endpoint API 的部份使用 Python，搭配 Flexible 的環境也可以的，彈性非常的高 4. weddingcnp 前端 vue.js 設計實作 本來是打算使用 react.js 來實作前端，不過太花時間了，所以選擇了 vue.js 來快速實作出介接 endpoint API 前端的表單 5. weddingcnp edm 寄送 sendgrid 在收集到名單時，可以發通知給朋友。這兒的例子是我們的婚紗照片上線時，就發了 EDM 通知告訴朋友快點上來看。使用的是 sendgrid 來發信，透過 sendgrid 的模版、client API 讓發 html 的 EDM 輕鬆多了 weddingcnp 系例傳送門 weddingcnp via GCP 簡介 weddingcnp via GCP - 1. 專案架構切分 weddingcnp via GCP - 2. 前端頁面設計實作 weddingcnp via GCP - 3. endpointAPI 設計實作 weddingcnp 前端 vue.js 設計實作 weddingcnp edm 寄送 sendgrid ","date":"2017-06-08","objectID":"/posts/weddingcnp-via-gcp/:1:0","tags":["GAE","GCE","Datastore","EndpointAPI","sendgrid","API"],"title":"weddingcnp via GCP","uri":"/posts/weddingcnp-via-gcp/"},{"categories":null,"content":"在 Golang 中利用 regEx 找到 Facebook Live rtmp server url and stream key","date":"2017-02-21","objectID":"/posts/golang-regex/","tags":["rtmp","facebook","golang","regEx","Live API"],"title":"Golang regEx parse Facebook Live rtmp","uri":"/posts/golang-regex/"},{"categories":null,"content":"最近因為公司專案的關係，開始接觸 Facebook Live API，需要動態的透過 API 去建立一組 Live 直播 並將 rtmp 的整個字串拆解成 ServerUrl 及 StreamKey 二個部份再由 ffmpeg 拿到這個資訊去 streaming。因為 Youtube Data API v3 可以別分拿 StreamName 及 IngestionAddress, 所以只需要對 Facebook 的部份特別處理 先來看一下 Facebook Live API 建立直播拿回來的完整的 rmtp url rtmp://rtmp-api.facebook.com:80/rtmp/1854721994809041?ds=1\u0026s_l=1\u0026a=ATjdLqx4xd23Q2mF 完整的 rtmp url 由 StreamUrl + StreamKey 組成 StreamUrl: rtmp://rtmp-api.facebook.com:80/rtmp/ StreamKey: 1854721994809041?ds=1\u0026s_l=1\u0026a=ATjdLqx4xd23Q2mF 因此可以透過 Golang regEx 的方式來拆解 package main import ( \"fmt\" \"regexp\" ) func getParams(regEx, url string) (paramsMap map[string]string) { var compRegEx = regexp.MustCompile(regEx) match := compRegEx.FindStringSubmatch(url) paramsMap = make(map[string]string) for i, name := range compRegEx.SubexpNames() { if i \u003e 0 \u0026\u0026 i \u003c= len(match) { paramsMap[name] = match[i] } } return } func main() { params := getParams(`(?P\u003cServerKey\u003e^rtmp://.+/)(?P\u003cStreamKey\u003e.+)`, `rtmp://rtmp-api.facebook.com:80/rtmp/1854721994809041?ds=1\u0026s_l=1\u0026a=ATjdLqx4xd23Q2mF`) fmt.Println(params[\"ServerKey\"]) // rtmp://rtmp-api.facebook.com:80/rtmp/ fmt.Println(params[\"StreamKey\"]) // 1854721994809041?ds=1\u0026s_l=1\u0026a=ATjdLqx4xd23Q2mF } The Go Playground - Demo reference Regex Tester Golang - A Go regular expression online tester Facebook Live API - Video ","date":"2017-02-21","objectID":"/posts/golang-regex/:0:0","tags":["rtmp","facebook","golang","regEx","Live API"],"title":"Golang regEx parse Facebook Live rtmp","uri":"/posts/golang-regex/"},{"categories":null,"content":"Simple example to demo how to serve GCS image via GAE Image API","date":"2016-10-31","objectID":"/posts/gae-go-image-api/","tags":["GAE","Golang","echo","pongor"],"title":"GAE go Image API for GCS","uri":"/posts/gae-go-image-api/"},{"categories":null,"content":" LIVE DEMO 在開發 GAE 應用程式時，難免會遇到應用程式需要處理圖片的問題。GAE 的應用程用可以直接存取靜態的資源檔案，這塊直接在 app.yaml 檔案中設定就可以了，不過也因為 GAE 應用程式的特性，需要將所有的資源上傳一份到 GAE 正式環境中，所以會發現上傳專案的容量大小會爆增(如果你將所有需要的圖檔階直接放在程式內)。 專案檔案太大會影響 GAE 在自動擴展的效能，所以盡可能的將不必要的東西移多專案外(圖檔等) app.yaml ... - url: /favicon.jpg mime_type: image/x-icon static_files: public/images/favicon.jpg upload: public/images/favicon.jpg - url: /js/* mime_type: text/javascript static_dir: public/js secure: always - url: /css/* mime_type: text/css static_dir: public/css secure: always http_headers: Access-Control-Allow-Origin: \"*\" - url: /images/* static_dir: public/images secure: always 每一個 GCP 的專案可以有 5G 免費的 Google Cloud Storage 空間，所以將 GAE 上大檔案的靜態資源放到 GCS 是一個很好的決定，在 GAE 程式中可以使用 google-api-go-client 來存取 GCS 上相關的資源。如果是圖片檔的話，更可以直接用 Image API 的方式來直接讀取圖片資源 Images Go API 讓我們使用 Blobstore 的方式來讀取/裁切圖檔，當我們透過 Blobstore 拿到靜態圖檔時可以直接透過 url 的方式對目標圖片進行調整圖檔的大小或進行裁切 # 將目標圖片重新縮放至 32 像素(等比例 - 長邊) http://lhx.ggpht.com/randomStringImageId=s32 # 將照片裁切至 32 像素 http://lhx.ggpht.com/randomStringImageId=s32-c ","date":"2016-10-31","objectID":"/posts/gae-go-image-api/:0:0","tags":["GAE","Golang","echo","pongor"],"title":"GAE go Image API for GCS","uri":"/posts/gae-go-image-api/"},{"categories":null,"content":"imgServe 因些我們就可以設計一個動態的路由來對應至 GCS 上特定路徑的圖片 /img?f=dress/banner.png --\u003e GCS:Bucket/dress/banner.png /img?f=dress/color/banner.png --\u003e GCS:Bucket/dress/color/banner.png /img?f=dress/color/banner.png\u0026s=200 --\u003e GCS:Bucket/dress/color/banner.png 等比縮放至 200 像素 /img?f=dress/color/banner.png\u0026s=200-c --\u003e GCS:Bucket/dress/color/banner.png 等比縮放至 200 像素且進行 1:1 的裁切 如此一來前端面頁如果需要引用照片，可以直接使用 \u003cimg src=\"/img?f=dress/banner.png\" alt=\"\"\u003e，如果目標圖片不存在則直接輸入一開始就準備好的 image 404 圖片進行代替 main.go package main import ( \"fmt\" \"golang.org/x/net/context\" \"net/http\" \"github.com/labstack/echo\" \"github.com/labstack/echo/engine/standard\" \"google.golang.org/appengine\" \"google.golang.org/appengine/blobstore\" \"google.golang.org/appengine/image\" ) const ( Bucket = \"\u003cyour-gae-default-bucket\u003e\" NotFoundImageURL = \"img-api-example/img404.jpg\" ) /** * index page */ func indexGET(c echo.Context) error { c.Render(200, \"index.tpl\", map[string]interface{}{ \"title\": \"go gae image API example\", \"images\": []string{ \"img?f=img-api-example/1.png\", \"img?f=img-api-example/1.png\u0026s=200\", \"img?f=img-api-example/1.png\u0026s=200-c\", \"img?f=img-api-example/2.jpg\", }, }) return nil } /** * get not foound image default image, img404.jpg */ func getNotFoundImage(ctx context.Context) (urlString string, err error) { blobPath := fmt.Sprintf(\"/gs/%s/%s\", Bucket, NotFoundImageURL) blobKey, err := blobstore.BlobKeyForFile(ctx, blobPath) if err != nil { return } opts := image.ServingURLOptions{Secure: false, Crop: true} url, err := image.ServingURL(ctx, blobKey, \u0026opts) if err != nil { return } urlString = url.String() return } /** * image serve handler */ func imgServe(c echo.Context) error { ctx := appengine.NewContext(c.Request().(*standard.Request).Request) filePath := c.QueryParam(\"f\") size := c.QueryParam(\"s\") blobPath := fmt.Sprintf(\"/gs/%s/%s\", Bucket, filePath) blobKey, err := blobstore.BlobKeyForFile(ctx, blobPath) if err != nil { c.String(http.StatusExpectationFailed, err.Error()) } opts := image.ServingURLOptions{Secure: false, Crop: true} if url, err := image.ServingURL(ctx, blobKey, \u0026opts); err != nil { if n, err := getNotFoundImage(ctx); err != nil { return err } else { c.Redirect(http.StatusTemporaryRedirect, n) } } else { if size != \"\" { c.Redirect(http.StatusTemporaryRedirect, fmt.Sprintf(\"%s=s%s\", url.String(), size)) } else { c.Redirect(http.StatusTemporaryRedirect, url.String()) } } return nil } func init() { e.GET(\"/\", indexGET) e.GET(\"/img\", imgServe) } ","date":"2016-10-31","objectID":"/posts/gae-go-image-api/:1:0","tags":["GAE","Golang","echo","pongor"],"title":"GAE go Image API for GCS","uri":"/posts/gae-go-image-api/"},{"categories":null,"content":"GAE Go Image serve GCS image ","date":"2016-10-31","objectID":"/posts/gae-go-image-api/:1:1","tags":["GAE","Golang","echo","pongor"],"title":"GAE go Image API for GCS","uri":"/posts/gae-go-image-api/"},{"categories":null,"content":"demo code cage1016/gae-go-image-example: GAE go image API example ","date":"2016-10-31","objectID":"/posts/gae-go-image-api/:1:2","tags":["GAE","Golang","echo","pongor"],"title":"GAE go Image API for GCS","uri":"/posts/gae-go-image-api/"},{"categories":null,"content":"解決 gvm install go1.4 安裝錯誤訊息","date":"2016-09-21","objectID":"/posts/gvm-install-go1-4/","tags":["Golang","gvm"],"title":"解決 gvm install go1.4 安裝錯誤 [筆記]","uri":"/posts/gvm-install-go1-4/"},{"categories":null,"content":"本來是使用 brew 來管理 golang 的版本，brew 及 brew cask 某些程度是很方便，不過也越來越覺得彈性差了點。繼 node 使用 tj 大神的 tj/n: Node version management 之外，golang 也打算使用 moovweb/gvm: Go Version Manager 來管理版本，不過在照著官方步驟時報錯了，順手記錄了一下解決的方式 brew info go $ brew info go go: stable 1.6 (bottled), HEAD Go programming environment https://golang.org /usr/local/Cellar/go/1.4.2 (4,567 files, 148.2M) Built from source /usr/local/Cellar/go/1.5 (5,328 files, 259.2M) Poured from bottle /usr/local/Cellar/go/1.5.2 (5,336 files, 259.6M) Poured from bottle /usr/local/Cellar/go/1.5.3 (5,337 files, 269.6M) Poured from bottle /usr/local/Cellar/go/1.6 (5,653 files, 472.9M) * Poured from bottle From: https://github.com/Homebrew/homebrew/blob/master/Library/Formula/go.rb ==\u003e Options --without-cgo Build without cgo --without-godoc godoc will not be installed for you --without-vet vet will not be installed for you --HEAD Install HEAD version ==\u003e Caveats As of go 1.2, a valid GOPATH is required to use the `go get` command: https://golang.org/doc/code.html#GOPATH You may wish to add the GOROOT-based install location to your PATH: export PATH=$PATH:/usr/local/opt/go/libexec/bin fixed gvm install go1.4 報錯 $ gvm install go1.4 Installing go1.4... * Compiling... ERROR: Failed to compile. Check the logs at /Users/cage/.gvm/logs/go-go1.4-compile.log ERROR: Failed to use installed version 拿錯誤訊息餵狗之後找到 update readme.md for go1.5 installation by imyelo · Pull Request #176 · moovweb/gvm install go1.4 順利完成 $ gvm install go1.4 -B Installing go1.4 from binary source 指定 golang 版本 $ gvm use go1.4 Now using version go1.4 順利安裝其他版本 $ gvm install go1.7 Installing go1.7... * Compiling... go1.7 successfully installed! ","date":"2016-09-21","objectID":"/posts/gvm-install-go1-4/:0:0","tags":["Golang","gvm"],"title":"解決 gvm install go1.4 安裝錯誤 [筆記]","uri":"/posts/gvm-install-go1-4/"},{"categories":null,"content":"sync-settings 是一個可以無痛幫你備份 Atom 所有的設定(包含 package) 的擴充工具","date":"2016-09-20","objectID":"/posts/atom-sync-settings/","tags":["Atom"],"title":"Atom sync-settings","uri":"/posts/atom-sync-settings/"},{"categories":null,"content":"Atom 是一個 GitHub 開發的免費、開放原始碼編輯器，目前有非常多的擴充工具可以安裝(4,913 packages)，也有非常多的主題佈景可以安裝(1,645 themes)，彈性非常的高，你可以打造成自己熟悉的開發環境。 當你好不容易打造好自己熟悉的開發環境時，如果要換電腦時，重新還原熟悉的開發環境是需要花一點功夫。以下是手動的方式 備份機上的清單到一個檔案 $ apm list --installed --bare | grep '^[^@]\\+' -o \u003e my_atom_packages.txt 在另外一台機器上使用 apm 進行批次安裝的動作 $ apm install --packages-file my_atom_packages.txt 上述的動作雖然可以幫你快速的解決安裝擴充工具的問題，不過設定檔得自已再進行設定，還是有一點麻煩 ","date":"2016-09-20","objectID":"/posts/atom-sync-settings/:0:0","tags":["Atom"],"title":"Atom sync-settings","uri":"/posts/atom-sync-settings/"},{"categories":null,"content":"atom-community/sync-settings Synchronize all your settings and packages across atom instances 一個超極方便的擴充工具來解決你 Atom 上擴充工具的同步及其設定，sync-settings 是透過 Github Gist 來幫你備份擴充工具的清單即設定，所以在 sync-settings 的設定中你必需填入 Personal Access Token (一組適合特殊需求專給特定程式介接存取 github 資源用:這就是 sync-settings) Gist Id (你的 Gist id) ","date":"2016-09-20","objectID":"/posts/atom-sync-settings/:1:0","tags":["Atom"],"title":"Atom sync-settings","uri":"/posts/atom-sync-settings/"},{"categories":null,"content":"建立 Personal Access Token 打開 Github: Personal Access Tokens \u003e 點選 gist \u003e Generate token \u003e 複製並填入 Atom:sync-settings 中 ","date":"2016-09-20","objectID":"/posts/atom-sync-settings/:1:1","tags":["Atom"],"title":"Atom sync-settings","uri":"/posts/atom-sync-settings/"},{"categories":null,"content":"建立 Gist 打開 Create a new Gist 填上說明 \u003e Create secret gist \u003e 複製 Gist Id 並填入 Atom:sync-settings 中 ","date":"2016-09-20","objectID":"/posts/atom-sync-settings/:1:2","tags":["Atom"],"title":"Atom sync-settings","uri":"/posts/atom-sync-settings/"},{"categories":null,"content":"Sync Backup 在填入 Personal Access Token 及 Gist Id 後，就可以進行同步的動作 Shit + command + P (Mac), Ctrl + Shit + P (Windows) ","date":"2016-09-20","objectID":"/posts/atom-sync-settings/:1:3","tags":["Atom"],"title":"Atom sync-settings","uri":"/posts/atom-sync-settings/"},{"categories":null,"content":"Sync restore 在其他電腦上裝好 Atom \u003e 安裝 sync-settings \u003e 進行 Sync: restore 的動作 Shit + command + P (Mac), Ctrl + Shit + P (Windows) 最後分享一下我的 Atom 擴充工具清單 Sublime-Style-Column-Selection atom-alignment atom-beautify atom-ternjs auto-update-packages autocomplete-go autocomplete-plus builder-go change-case cobalt2-syntax color-picker docblockr emmet environment file-icons fold-functions go-config go-debug go-get go-plus go-rename godoc gofmt gometalinter-linter gorename highlight-selected imdone-atom jshint language-c language-docker language-gitignore language-protobuf language-shellscript linter linter-eslint linter-js-standard linter-jscs linter-jshint mocha-test-runner navigator-godef open-recent package-sync pigments project-manager react regex-railroad-diagram rst-preview-pandoc set-syntax seti-syntax seti-ui sync-settings terminal-plus tester-go todo-show tool-bar tool-bar-main trailing-spaces tree-view ","date":"2016-09-20","objectID":"/posts/atom-sync-settings/:1:4","tags":["Atom"],"title":"Atom sync-settings","uri":"/posts/atom-sync-settings/"},{"categories":null,"content":"TensorFlow 是由 Google 所公布的開源機器學習平台，根據 Github 的數據統計，TensorFlow 成為2016年最受關注的十大開源專案之一。此次分享將介紹，如何在 NAS 上整合TensorFlow 及相關 Open source project，以展示幾種相關的資料分析應用","date":"2016-08-22","objectID":"/posts/retrain-inception-model-for-nas/","tags":["NAS","tensorflow","retrain-model","coscup"],"title":"COSCUP 2016 - NAS也會揀土豆","uri":"/posts/retrain-inception-model-for-nas/"},{"categories":null,"content":" tensorflow logo 今年在 COSCUP 2016 上分享了「NAS 也可以揀土豆」主題。 TensorFlow 是由 Google 所公布的開源機器學習平台，根據 Github 的數據統計，TensorFlow 成為2016年最受關注的十大開源專案之一。此次分享將介紹，如何在 NAS 上整合TensorFlow 及相關 Open source project，以展示幾種相關的資料分析應用。 ","date":"2016-08-22","objectID":"/posts/retrain-inception-model-for-nas/:0:0","tags":["NAS","tensorflow","retrain-model","coscup"],"title":"COSCUP 2016 - NAS也會揀土豆","uri":"/posts/retrain-inception-model-for-nas/"},{"categories":null,"content":"outline Machine learning Deep learning Neural Network Convolutional neural network Building a classifier for NAS Study information ","date":"2016-08-22","objectID":"/posts/retrain-inception-model-for-nas/:1:0","tags":["NAS","tensorflow","retrain-model","coscup"],"title":"COSCUP 2016 - NAS也會揀土豆","uri":"/posts/retrain-inception-model-for-nas/"},{"categories":null,"content":"slide ","date":"2016-08-22","objectID":"/posts/retrain-inception-model-for-nas/:2:0","tags":["NAS","tensorflow","retrain-model","coscup"],"title":"COSCUP 2016 - NAS也會揀土豆","uri":"/posts/retrain-inception-model-for-nas/"},{"categories":null,"content":"github demo repo cage1016/coscup2016-nas-session: Nas 也可以揀土豆 ","date":"2016-08-22","objectID":"/posts/retrain-inception-model-for-nas/:3:0","tags":["NAS","tensorflow","retrain-model","coscup"],"title":"COSCUP 2016 - NAS也會揀土豆","uri":"/posts/retrain-inception-model-for-nas/"},{"categories":null,"content":"tips 在準備簡報的過程中也學習到了 Machine learning, Deep learning, Convolutional Neural Network(CNN) 的相關概念, 其實花了很多時候再分辨這其中的差異有什麼不同, 自己也是剛剛開始學習這門學科, 主題分享上算是入門給大家比較大一點的概念(也是自己的學習心得) ","date":"2016-08-22","objectID":"/posts/retrain-inception-model-for-nas/:4:0","tags":["NAS","tensorflow","retrain-model","coscup"],"title":"COSCUP 2016 - NAS也會揀土豆","uri":"/posts/retrain-inception-model-for-nas/"},{"categories":null,"content":"Study information Deep Learning | Udacity Research Blog: Train your own image classifier with Inception in TensorFlow jtoy/awesome-tensorflow: TensorFlow - A curated list of dedicated resources http://tensorflow.org Deep Learning - Convolutional Neural Networks Neural networks and deep learning Multiple Component Learning DIGITS/GettingStarted.md at master · NVIDIA/DIGITS How to Retrain Inception’s Final Layer for New Categories TensorFlow For Poets DIY Deep Learning for Vision: a Hands-On Tutorial with Caffe - Google Slides Caffe | Deep Learning Framework Understanding Convolutional Neural Networks for NLP – WildML ","date":"2016-08-22","objectID":"/posts/retrain-inception-model-for-nas/:5:0","tags":["NAS","tensorflow","retrain-model","coscup"],"title":"COSCUP 2016 - NAS也會揀土豆","uri":"/posts/retrain-inception-model-for-nas/"},{"categories":null,"content":"docker run small container with SPA serving by golang","date":"2016-08-04","objectID":"/posts/golang-serve-static-site/","tags":["golang","webpack"],"title":"golang serving a single page application","uri":"/posts/golang-serve-static-site/"},{"categories":null,"content":"golang serve SPA 最近有前端開發的需求，選用了 react-redux-starter-kit 來進行二次開發，省去一些想要使用 React, redux, redux-router 的基本配置，這樣速度會快一點 因為 react-redux-starter-kit 也使用 webpack 進行程式碼的打包, 所以最後的產出預設在 dist 資料夾中，所以部署時只需要一個簡單的 host server 即可 # dist example $ l total 752 -rw-r--r-- 1 cage staff 3317 Aug 4 00:22 1.counter.fa53ea42bc9ff9de19bd.js -rw-r--r-- 1 cage staff 144953 Aug 4 00:22 app.5d0f2ab61ef7dd5daac5.js -rw-r--r-- 1 cage staff 2619 Aug 4 00:22 app.97a1751c9624097874a4b54cb93fa067.css -rw-r--r-- 1 cage staff 173 Aug 4 00:33 app.go -rw-r--r-- 1 cage staff 24838 Aug 4 00:22 favicon.ico -rw-r--r-- 1 cage staff 103 Aug 4 00:22 humans.txt -rw-r--r-- 1 cage staff 604 Aug 4 00:22 index.html -rw-r--r-- 1 cage staff 24 Aug 4 00:22 robots.txt -rw-r--r-- 1 cage staff 183224 Aug 4 00:22 vendor.9012d9d99074521f418e.js 考慮效能的問題, 最後打算使用 golang 來當作 host server, golang 內建的 net/http 可以輕鬆的使用 http.FileServer(http.Dir(\"./\")) 來 host 整個靜態目錄 package main import ( \"log\" \"net/http\" ) func main() { log.Println(\"Listening port 3000...\") log.Fatal(http.ListenAndServe(\":3000\", http.FileServer(http.Dir(\"./\")))) } 但是上述的作法基本上是可以動的, 不過如果前端自己有使用到 redux-router 時, golang 並不會將請求導至前端的 router 而是直接得到 golang 404 而不會進到前端 redux-router 訂定的 router (如果有使用 redux-router 對 Notfound 進行處理) http://localhost:3000/dfa 所以我們使用了 golang echo 的 web framework, 監聽所有的請求並直接導至 index.html 的前端靜態檔案 package main import ( \"flag\" \"fmt\" \"net/http\" \"os\" \"strings\" \"github.com/labstack/echo\" \"github.com/labstack/echo/engine/standard\" mw \"github.com/labstack/echo/middleware\" ) const ( wwwRoot = \"./\" ) var ( httpPort = flag.Int(\"http\", 3000, \"http port number\") ) func Init() *echo.Echo { e := echo.New() e.Debug() e.Use(mw.Logger()) e.Use(mw.Recover()) e.Any(\"/*\", echo.HandlerFunc(func(c echo.Context) (err error) { r := c.Request().(*standard.Request).Request w := c.Response().(*standard.Response).ResponseWriter requestPath := r.URL.Path fileSystemPath := wwwRoot + r.URL.Path endURIPath := strings.Split(requestPath, \"/\")[len(strings.Split(requestPath, \"/\"))-1] splitPath := strings.Split(endURIPath, \".\") splitLength := len(splitPath) if splitLength \u003e 1 \u0026\u0026 splitPath[splitLength-1] != \"go\" { f, error := os.Stat(fileSystemPath) if error == nil \u0026\u0026 !f.IsDir() { http.ServeFile(w, r, fileSystemPath) return } } http.ServeFile(w, r, wwwRoot+\"index.html\") return })) return e } func main() { flag.Parse() server := Init() server.Run(standard.New(fmt.Sprintf(`:%d`, *httpPort))) } http://localhost:3000/dfa ","date":"2016-08-04","objectID":"/posts/golang-serve-static-site/:1:0","tags":["golang","webpack"],"title":"golang serving a single page application","uri":"/posts/golang-serve-static-site/"},{"categories":null,"content":"run SPA as with docker image 處理完 golang 對 single page application 的支援, 進一步簡化部署的流程, 可以將整個 single page application 連同 app.go 利用 golang build 的方式編譯成執行檔, 再將 golang 執行檔透過 Dockerfile 編譯成 docker image, 這樣一來就可以很容易的部署在任何可以執行 container 的環境 上述一系列的流程我們可以使用 npm run scripts 的方式把它完全串起來來達到一鍵建立 docker image FROM alpine:3.3 MAINTAINER cage.chung \u003ccage.chung@gmail.com\u003e WORKDIR /go ADD . /go/ EXPOSE 3000 CMD [\"./counter\"] Dockerfile 檔案中我們需要指定 docker image 啟動時直接執行我們透過 GOOS=linux GOARCH=amd64 go build -o counter 編譯出來的執行檔 counter* 執行自訂義 npm scripts $ npm run docker 成功執行後會自動建立 docker image # list docker image $ docker images REPOSITORY TAG IMAGE ID CREATED SIZE username/counter v0.1.0 1771ddbe0a98 4 seconds ago 14.67 MB 執行 docker image # run docker image $ docker run -d --name counter -p 3000:3000 username/counter:v0.1.0 f8394fec624a4e3b989f7ce48857f64178e39aa8a5195f39e2d0d5a6572ee55c # docker ps $ dps CONTAINER ID IMAGE COMMAND CREATED STATUS PORTS NAMES f8394fec624a username/counter:v0.1.0 \"./counter\" 2 seconds ago Up 1 seconds 0.0.0.0:3000-\u003e3000/tcp counter ","date":"2016-08-04","objectID":"/posts/golang-serve-static-site/:2:0","tags":["golang","webpack"],"title":"golang serving a single page application","uri":"/posts/golang-serve-static-site/"},{"categories":null,"content":"repo Demo example cage1016/golang-serve-spa # clone repo $ git clone git@github.com:cage1016/golang-serve-spa.git # npm install package $ npm install # 一鍵建立 docker image $ npm docker # docker run $ docker run -d --name counter -p 3000:3000 username/counter:v0.1.0 ","date":"2016-08-04","objectID":"/posts/golang-serve-static-site/:3:0","tags":["golang","webpack"],"title":"golang serving a single page application","uri":"/posts/golang-serve-static-site/"},{"categories":null,"content":"如何在 django-oscar 使用自己的 locale 檔案","date":"2016-04-14","objectID":"/posts/django-oscar-i18n/","tags":["Python","Oscar","virtualenv","locale","i18n"],"title":"筆記 - django oscar i18n","uri":"/posts/django-oscar-i18n/"},{"categories":null,"content":"django-oscar 是一個滿完整的開源的 EC 專案。Oscar 內建 i18n 是使用 transifex，依照 django-oscar 的說明，當 django-oscar 進行 master 的發佈時才會去更新相關的翻譯檔案，如果 i18n 的更新速度沒有辦法符合自己的需求有二種方式，1)加入 transifex 專案幫忙翻譯，只是 django-oscar 的更新速度比較慢 2)使用本地的檔案 目前 django-oscar 支援的 i18n ├── am_ET ├── ar ├── ar_SA ├── bg_BG ├── bn ├── bn_BD ├── ca ├── cmn ├── cs ├── cs_CZ ├── da ├── de ├── el_GR ├── en ├── en_US ├── es ├── es_AR ├── es_CL ├── et ├── eu ├── fa ├── fa_IR ├── fi ├── fr ├── he ├── hi ├── hi_IN ├── id ├── it ├── ja ├── ka_GE ├── ko ├── lt ├── nb_NO ├── nl ├── pl ├── pt_BR ├── pt_PT ├── ro_RO ├── ru ├── ru_RU ├── sk ├── sk_SK ├── sv ├── sv_SE ├── th_TH ├── tr ├── tr_TR ├── uk ├── uk_UA ├── vi ├── zh ├── zh-Hant ├── zh_CN ├── zh_HK ├── zh_TW └── zh_TW.Big5 django-oscar 使用 i18n 的設定，如果需要使用本地的 Locale 檔案，需要另外指定 LOCALE_PATHS settings.py ########## GENERAL CONFIGURATION # See: https://docs.djangoproject.com/en/dev/ref/settings/#time-zone TIME_ZONE = 'Asia/Taipei' # See: https://docs.djangoproject.com/en/dev/ref/settings/#language-code LANGUAGE_CODE = 'en-us' # Includes all languages that have \u003e50% coverage in Transifex # Taken from Django's default setting for LANGUAGES gettext_noop = lambda s: s LANGUAGES = ( ('en-us', gettext_noop('English (United States)')), ('zh-cn', gettext_noop('Simplified Chinese')), ('zh-tw', gettext_noop('Chinese (Taiwan)')), ) # Locale Path LOCALE_PATHS = ( normpath(join(DJANGO_ROOT, 'locale')), ) # See: https://docs.djangoproject.com/en/dev/ref/settings/#site-id SITE_ID = 1 # See: https://docs.djangoproject.com/en/dev/ref/settings/#use-i18n USE_I18N = True # See: https://docs.djangoproject.com/en/dev/ref/settings/#use-l10n USE_L10N = True # See: https://docs.djangoproject.com/en/dev/ref/settings/#use-tz USE_TZ = True ########## END GENERAL CONFIGURATION 在建立自己的 django-oscar EC 商城時是使用 pip install django-oscar 來安裝，所以要重製所有 django-oscar 的翻譯 message 時就必需建立 $PATH_TO_OSCAR 的 symlink, 指定 symlink 之後執行 python ./manage.py makemessages 才會到 django-oscar env 的目錄把相關的 message 字串建立成 *.go 檔 ","date":"2016-04-14","objectID":"/posts/django-oscar-i18n/:0:0","tags":["Python","Oscar","virtualenv","locale","i18n"],"title":"筆記 - django oscar i18n","uri":"/posts/django-oscar-i18n/"},{"categories":null,"content":"Simple go through 使用 generator-django-oscar-app 快速建立專案。依照連結的操作方式完成後(應該已經建立專案目錄，virtualenv) 切換至工作目錄 (env) cd {project_path}/sandbox 建立 i18n 及 locale 目錄 (env) mkdir i18n locale link virtualenv django-oscar source (env) ln -s ~/.virtualenvs/{your-ven-name}/lib/python2.7/site-packages/oscar i18n/oscar 使用 makemessage 建立 zh_TW locale 檔 # django-oscar locale: sandbox/i18n/oscar/locale # project locale: sandbox/locale (env) python manage.py makemessages --symlinks --locale=zh_TW 編譯 messages (env) python manage.py compilemessages ","date":"2016-04-14","objectID":"/posts/django-oscar-i18n/:1:0","tags":["Python","Oscar","virtualenv","locale","i18n"],"title":"筆記 - django oscar i18n","uri":"/posts/django-oscar-i18n/"},{"categories":null,"content":"如何利用 virtualenv, virtualenvwrapper, requirements.txt, linkenv, link_pip 快速建置 Google App Engine - Python 開發環境","date":"2016-03-28","objectID":"/posts/gae-link-pip-helper/","tags":["Shell","Python","GAE","pip","virtualenv"],"title":"gae link pip helper","uri":"/posts/gae-link-pip-helper/"},{"categories":null,"content":"Python 的社群非常活躍有非常多好用的套件可以使用，也有 pip 的套件管理程式來讓開發者管理套件升級、版控等問題 ","date":"2016-03-28","objectID":"/posts/gae-link-pip-helper/:0:0","tags":["Shell","Python","GAE","pip","virtualenv"],"title":"gae link pip helper","uri":"/posts/gae-link-pip-helper/"},{"categories":null,"content":"virtualenv 一般在發者 Python 相關的專案會引入 virtualenv 的概念來區隔多專案發開套件的相依問題。如果沒有導入 virtualenv 時 pip install 會直接把套件安裝在全域環境，專案也許也引用某些套件特定的版次，此種方式會造成開發上的擾困。基本上都會建議使用 virtualenv ","date":"2016-03-28","objectID":"/posts/gae-link-pip-helper/:1:0","tags":["Shell","Python","GAE","pip","virtualenv"],"title":"gae link pip helper","uri":"/posts/gae-link-pip-helper/"},{"categories":null,"content":"virtualenvwrapper virtualenvwrapper 是 virtualenv 的加強版。它會把套件安裝的目錄統一收到 ${HOME}/.virtualenvs 下集中管理，也提供更方便建立、移除、切換 virtualenv 的指令 ","date":"2016-03-28","objectID":"/posts/gae-link-pip-helper/:2:0","tags":["Shell","Python","GAE","pip","virtualenv"],"title":"gae link pip helper","uri":"/posts/gae-link-pip-helper/"},{"categories":null,"content":"GAE 在開發 Google App Engine - Python 的時候，在做用第三方套件的時候會有一些限制 (Libraries in Python 2.7 - Python — Google Cloud Platform)，Google App Engine 的執行環境中有支援了一些第三方套件，引用的方式是直接在專案的 app.yaml 中指定即可 libraries: - name: PIL version: \"1.1.7\" - name: webob version: \"1.1.1\" - name: jinja2 version: latest 而 Google App Engine 的執行環境中沒有支援的第三方套件則需要將引用到的第三方套件程式源始碼以檔案方式一同上傳到 Google App Engine 平台才可以正常執行。一般進行 pip 套件安裝時會裝在當前的 virtualenv 或 全域的環境變數中，但是搭配 GAE 指則需要使用 pip install -r requirements.txt -t lib 套件裝在當然目錄 lib 並在 appengine_config.py 中將 lib 目錄加到 sys path 中 import os, sys sys.path.insert(0, os.path.join(os.path.dirname(__file__), 'lib')) ","date":"2016-03-28","objectID":"/posts/gae-link-pip-helper/:3:0","tags":["Shell","Python","GAE","pip","virtualenv"],"title":"gae link pip helper","uri":"/posts/gae-link-pip-helper/"},{"categories":null,"content":"How to use Google App Engine with virtualenv | Vita Smid ~ Zephyrus | Mathematics, philosophy, code, travel and everything in between. 文章作者開發了一個 linkenv 的套件可以利用指令快速用 symbol link 建立 virtualenv 到本地的資料夾。 ","date":"2016-03-28","objectID":"/posts/gae-link-pip-helper/:4:0","tags":["Shell","Python","GAE","pip","virtualenv"],"title":"gae link pip helper","uri":"/posts/gae-link-pip-helper/"},{"categories":null,"content":"link pip helper Shell $ virtualenv env $ source bin/env/activate (env)$ pip install djangoappengine six ... (env)$ pip install -r requirements.txt ... 因為 How to use Google App Engine with virtualenv | Vita Smid ~ Zephyrus | Mathematics, philosophy, code, travel and everything in between. 文章提及的方式只有使用到 virtualenv 並沒有使用 virtualenvwrapper，所以每次新專案步驟重置就會花比較多的時間。 link pip.sh #!/usr/bin/env bash # [How to use Google App Engine with virtualenv | Vita Smid ~ Zephyrus | # Mathematics, philosophy, code, travel and everything in between.](http://ze.phyr.us/appengine-virtualenv/) # virtualenv pip package link helper # rm -rf gaenv # linkenv $VIRTUAL_ENV/lib/python2.7/site-packages gaenv # Default linker foler DEFAULT_LINK_FOLDER=gaenv if [[ $# -eq 0 ]] then LIB=$DEFAULT_LINK_FOLDER else LIB=$1 fi # relink rm -rf $DEFAULT_LINK_FOLDER rm -rf $LIB linkenv $VIRTUAL_ENV/lib/python2.7/site-packages $LIB 為了減少 Google App Engine 專案建立的時間，將上述的 shell 加入 .bash_profile 搭配 virtualenv virtualenvwrapper requirements.txt 就可以簡易的建置開發環. ","date":"2016-03-28","objectID":"/posts/gae-link-pip-helper/:5:0","tags":["Shell","Python","GAE","pip","virtualenv"],"title":"gae link pip helper","uri":"/posts/gae-link-pip-helper/"},{"categories":null,"content":"Quick tutorial Github repo: cage1016/link-pip-helper # git clone repo $ git clone git@github.com:cage1016/link-pip-helper.git Cloning into 'link-pip-helper'... remote: Counting objects: 7, done. remote: Compressing objects: 100% (5/5), done. remote: Total 7 (delta 0), reused 7 (delta 0), pack-reused 0 Receiving objects: 100% (7/7), done. Checking connectivity... done. # switch to link-pip-helper $ cd link-pip-helper/ # 利用 virtualenvwrapper 建立 virtualenv $ mkvirtualenv link-pip-helper-tutorial New python executable in /Users/{HOME}/.virtualenvs/link-pip-helper-tutorial/bin/python2.7 Also creating executable in /Users/{HOME}/.virtualenvs/link-pip-helper-tutorial/bin/python Please make sure you remove any previous custom paths from your /Users/{HOME}/.pydistutils.cfg file. Installing setuptools, pip, wheel...done. virtualenvwrapper.user_scripts creating /Users/{HOME}/.virtualenvs/link-pip-helper-tutorial/bin/predeactivate virtualenvwrapper.user_scripts creating /Users/{HOME}/.virtualenvs/link-pip-helper-tutorial/bin/postdeactivate virtualenvwrapper.user_scripts creating /Users/{HOME}/.virtualenvs/link-pip-helper-tutorial/bin/preactivate virtualenvwrapper.user_scripts creating /Users/{HOME}/.virtualenvs/link-pip-helper-tutorial/bin/postactivate virtualenvwrapper.user_scripts creating /Users/{HOME}/.virtualenvs/link-pip-helper-tutorial/bin/get_env_details # pip 安裝相依套件 $ pip install -r requirements.txt Collecting google-api-python-client==1.4.0 (from -r requirements.txt (line 1)) .... # 執行 shell (你可以將 link pip.sh 內容 export 成任何 function 名) $ link_pip lib # 本地執行 Google App Engine $ dev_appserver.py . ","date":"2016-03-28","objectID":"/posts/gae-link-pip-helper/:6:0","tags":["Shell","Python","GAE","pip","virtualenv"],"title":"gae link pip helper","uri":"/posts/gae-link-pip-helper/"},{"categories":null,"content":"在使用 GAE command line tools 上傳專案至 appengine.google.com 上時，會遇到 HTTP Error 403: Forbidden Unexpected HTTP status 403. Aborting 的訊息，如何解決問題。","date":"2016-03-10","objectID":"/posts/gae-appcfg-update-403/","tags":["Python","GAE","appcfg"],"title":"gae appcfg update 403","uri":"/posts/gae-appcfg-update-403/"},{"categories":null,"content":"當 GAE application 本地開發到一個階段時，就會開始想要上傳至 appengine.google.com 進行線上的測試，這時候便會使 command line 工 具來上傳專案 $ appcfg.py update default/app.yaml ownership/app.yaml 10:46 AM Host: appengine.google.com 10:46 AM Application: \u003cyour-application-id\u003e; version: 1 10:46 AM Starting update of app: \u003cyour-application-id\u003e, version: 1 10:46 AM Getting current resource limits. 2016-03-10 10:46:17,616 ERROR appcfg.py:2396 An error occurred processing file '': HTTP Error 403: Forbidden Unexpected HTTP status 403. Aborting. Error 403: --- begin server output --- You do not have permission to modify this app (app_id=u's~\u003cyour-application-id\u003e'). --- end server output --- 重新進行 gcloud oauth login \u0026 gcloud project set \u003cyour-application-id\u003e 檢查 gcloud config $ gcloud config list Your active configuration is: [default] [app] suppress_change_warning = true [compute] region = asia-east1 zone = asia-east1-b [core] account = \u003cyour-account\u003e disable_usage_reporting = False project = \u003cyour-default-project-id\u003e 還是遇到同樣的問題，HTTP Error 403: Forbidden Unexpected HTTP status 403. Aborting。 要解決這個問題的方法有二種 --no_cookies Do not save authentication cookies to local disk. 直接刪除 .appcfg_cookies \u0026 .appcfg_oauth2_tokens 並重新進行 gcloud oauth login $ la | grep .appcfg_ -rw------- 1 cage staff 960 Jul 8 2015 .appcfg_cookies -rw-r--r-- 1 cage staff 43 Nov 15 13:01 .appcfg_nag -rw------- 1 cage staff 774 Mar 10 10:33 .appcfg_oauth2_tokens ","date":"2016-03-10","objectID":"/posts/gae-appcfg-update-403/:0:0","tags":["Python","GAE","appcfg"],"title":"gae appcfg update 403","uri":"/posts/gae-appcfg-update-403/"},{"categories":null,"content":"簡單說明如何快速建立一個 Django 專案及搭配 Virtualenv, PyCharm","date":"2015-11-01","objectID":"/posts/django-getting-started/","tags":["Python","Django","twoscoops","PyCharm"],"title":"django getting started","uri":"/posts/django-getting-started/"},{"categories":null,"content":"Django Quick Getting Started pip virtualenv virtualenvwrapper Django twoscoops/django-twoscoops-project PyCharm 簡單說明如何快速建立一個 Django 專案及搭配 Virtualenv, PyCharm ","date":"2015-11-01","objectID":"/posts/django-getting-started/:0:0","tags":["Python","Django","twoscoops","PyCharm"],"title":"django getting started","uri":"/posts/django-getting-started/"},{"categories":null,"content":"Virtualenv Python 社群擁有非常多的好用的套件，所以 pip 的套件管理程式就變的非常的好用。但是這時候就有出現另一個問題。不同專案所需要函數庫可能不盡相同，所以 Virtualenv 可以隔離函數庫需求不同的專案，讓它們不會互相影響。 在沒有權限的情況下安裝新套件 不同專案可以使用不同版本的相同套件 套件版本升級時不會影響其他專案 # install virtualenv (會安裝在全域環境下) $ pip install virtualenv # 建立一個 virtualenv, 建立完成後會在 quick_getting_started新增一個 env_QGS 的目錄 $ cd ~/ \u0026\u0026 mkdir quick_getting_started $ virtualenv env_QGS # 執行 Virtualenv, 執行完會再 termianl `$` 號前面出現 virtualenv 的名稱 $ source env_QGS/bin/activateds (env_QGS) $ # 退出 virtualenv (env_QGS) $ deactivate Tips: Virtualenv 方便讓我隔離了不同專案下的函式庫，但是我們建立出來的 env_QGS (virtualenv 目錄) 會散落在各地，在管理上面還是有一點點麻煩。這時候就有另一個 virtualenvwrapper 幫我們解決這一個問題 virtualenvwrapper 是一個 virtualenv 的強加版，方便我們管理有的 virtualenv 將所有的虛擬環境整合在一個目錄下。 管理（新增、移除、複製）所有的虛擬環境。 可以使用一個命令切換虛擬環境。 Tab 補全虛擬環境的名字。 每個操作都提供允許使用者自訂的 hooks。 可撰寫容易分享的 extension plugin 系統。 所以剛剛的操作步驟就可以得到簡化 # 列出所有的 virtualenv. 所有的 virtualenv 集中管理(~/.virtualenvs/) $ workon djago-oscar-api-test django-oscar-paypal django-oscar_demo django-sample-app github_flask_oauth2 mysite oauth2app oscar .... # 建立 virtualenv env_QGS, 建立完成後會自動幫你啟動(超棒der) $ mkvirtualenv env_QGS New python executable in env_QGS/bin/python Installing setuptools, pip, wheel...done. virtualenvwrapper.user_scripts creating /Users/cage/.virtualenvs/env_QGS/bin/predeactivate virtualenvwrapper.user_scripts creating /Users/cage/.virtualenvs/env_QGS/bin/postdeactivate virtualenvwrapper.user_scripts creating /Users/cage/.virtualenvs/env_QGS/bin/preactivate virtualenvwrapper.user_scripts creating /Users/cage/.virtualenvs/env_QGS/bin/postactivate virtualenvwrapper.user_scripts creating /Users/cage/.virtualenvs/env_QGS/bin/get_env_details (env_QGS) $ ","date":"2015-11-01","objectID":"/posts/django-getting-started/:1:0","tags":["Python","Django","twoscoops","PyCharm"],"title":"django getting started","uri":"/posts/django-getting-started/"},{"categories":null,"content":"Django Django是一個開放原始碼的Web應用框架，由Python寫成。採用了MVC的軟體設計模式，即模型M，視圖V和控制器C。它最初是被開發來用於管理勞倫斯出版集團旗下的一些以新聞內容為主的網站的。並於2005年7月在BSD授權條款下釋出。這套框架是以比利時的吉普賽爵士吉他手Django Reinhardt來命名的。Django - 維基百科，自由的百科全書 # 使用 mkvirtualenv env_QGS, 列出預設安裝 Python 函式庫 (env_QGS) $ pip list pip (7.1.2) setuptools (18.2) wheel (0.24.0) # 安裝 Django, 目前最新的版本為 1.8.5 (env_QGS) $ pip django Collecting django Using cached Django-1.8.5-py2.py3-none-any.whl Installing collected packages: django Successfully installed django-1.8.5 # 安裝完 Django 後, 會自帶 `django-admin.py` 方便我們進行 Django 專案的建立及其他對應功能 (env_QGS) $ django-admin.py help Type 'django-admin.py help \u003csubcommand\u003e' for help on a specific subcommand. Available subcommands: [django] check compilemessages createcachetable dbshell diffsettings dumpdata flush inspectdb loaddata makemessages makemigrations migrate runfcgi runserver shell showmigrations sql sqlall sqlclear sqlcustom sqldropindexes sqlflush sqlindexes sqlmigrate sqlsequencereset squashmigrations startapp startproject syncdb test testserver validate # 建立第一個 Django 專案 (env_QGS) $ django-admin.py startproject my_site # 列出使用 startproject my_site 後的檔案架構 (env_QGS) $ tree . └── my_site # django project root ├── manage.py └── my_site # django app root ├── __init__.py ├── settings.py ├── urls.py └── wsgi.py # 基本上使用 django-admon 建立完後就可以接直執行 (env_QGS) $ python mysite/manage.py runserver Tips: 使用 django-admin.py 可以快速的建立專案，但是在專案進行還是會遇到發開/測試/部署等執行階段，再這些階段會遇到函式庫不同(requirments.txt), 設定檔配置也會不同(settings)。空專案建立再手動調整的方式就會比較累，所以在專案建立時就引用 twocoops template 來加快專案檔案架構的配置 ","date":"2015-11-01","objectID":"/posts/django-getting-started/:2:0","tags":["Python","Django","twoscoops","PyCharm"],"title":"django getting started","uri":"/posts/django-getting-started/"},{"categories":null,"content":"twoscoops Two Scoops Press: Making Python and Django as fun as ice cream twocoops 是一本書，這本書教你如何最佳實踐 Django 1.8，如上一節提的問題(multiple requirements.txt、settings)等配置方式 # 我們接著上節的進度 (~/tmp/quick_gettting_started) (env_QGS) $ ls my_site # 剛剛建立的 my_site 專案 # 使用 twosoops template (env_QGS) $ django-admin.py startproject --template=https://github.com/twoscoops/django-twoscoops-project/archive/master.zip --extension=py,rst,html mysite2 # 比較一下 twoscoops 幫我作了什麼 $ tree . ├── my_site # my_site django project root │ ├── db.sqlite3 │ ├── manage.py │ └── my_site # my_site django app │ ├── __init__.py │ ├── settings.py │ ├── urls.py │ ├── wsgi.py └── mysite2 # mysite 2 repo level (如果有使用 git) ├── CONTRIBUTORS.txt ├── LICENSE.txt ├── README.rst ├── docs # django docs (sphinx) │ ├── Makefile │ ├── __init__.py │ ├── conf.py │ ├── deploy.rst │ ├── index.rst │ ├── install.rst │ └── make.bat ├── mysite2 # mysite2 django project root (同 my_site django project root level) │ ├── manage.py │ ├── mysite2 # mysite2 django app root (同 my_site django app root level) │ │ ├── __init__.py │ │ ├── settings # multiple settings root │ │ │ ├── __init__.py │ │ │ ├── base.py │ │ │ ├── local.py │ │ │ ├── production.py │ │ │ └── test.py │ │ ├── urls.py │ │ └── wsgi.py │ ├── static │ │ ├── css │ │ ├── fonts │ │ └── js │ └── templates │ ├── 404.html │ ├── 500.html │ └── base.html ├── requirements # multiple requirements root │ ├── base.txt │ ├── local.txt │ ├── production.txt │ └── test.txt └── requirements.txt Tips: 在執行 mysite2 之前需對建立出來的檔案進行一些修改(因為這個 template 是針對 Django 1.6，我們想要使用 Django 1.8.5 所以必修進行修正) requirements mysite2/requirements/base.txt : Django==1.6.5 –\u003e Django==1.8.5 mysite2/requirements/local.txt : django-debug-toolbar==1.2.1 –\u003e django-debug-toolbar==1.4 mysite2/mysite2/mysite2/settings base.py mark line 29 # TEMPLATE_DEBUG = DEBUG mark line 246 # 'south', (south support \u003c Django 1.7) local.py mark line 15 # TEMPLATE_DEBUG = DEBUG # install package (env_QGS) $ cd mysite2 (env_QGS) $ pip install -r requirements/local.txt # database migrate (env_QGS) $ python mysite2/manage.py migrate Operations to perform: Synchronize unmigrated apps: staticfiles, debug_toolbar, messages Apply all migrations: admin, contenttypes, sites, auth, sessions Synchronizing apps without migrations: Creating tables... Running deferred SQL... Installing custom SQL... Running migrations: Rendering model states... DONE ... # 執行 (env_QGS) $ python mysite2/manage.py runserver --settings=mysite2.settings.local ","date":"2015-11-01","objectID":"/posts/django-getting-started/:3:0","tags":["Python","Django","twoscoops","PyCharm"],"title":"django getting started","uri":"/posts/django-getting-started/"},{"categories":null,"content":"Pycharm Pycharm 是一個很好用的 Python 編輯器，我最喜歡的部份是可以拿來 debug。不過在開發環境上需要設定一下才能配合 virtualenv + twoscoops Project structure 設定 mysite2(django project level) 為source Project interpreter 加入已經建立好的 virtualenv 設定 Django (Django project, settings, manage.py path) **設定 Run/Debug Configration ** Run with fly Enjoying debug mode ","date":"2015-11-01","objectID":"/posts/django-getting-started/:4:0","tags":["Python","Django","twoscoops","PyCharm"],"title":"django getting started","uri":"/posts/django-getting-started/"},{"categories":null,"content":"Reference Python 的虛擬環境及多版本開發利器─Virtualenv 與 Pythonbrew - OpenFoundry ","date":"2015-11-01","objectID":"/posts/django-getting-started/:5:0","tags":["Python","Django","twoscoops","PyCharm"],"title":"django getting started","uri":"/posts/django-getting-started/"},{"categories":null,"content":"docker 社群開發的速度非常的快速，而 docker 1.8 又有比較大的改變。boot2docker 的功能被 docker-machine 取代，此篇文章算是自己作一個記錄","date":"2015-10-04","objectID":"/posts/docker-notebook-1/","tags":["docker","docker-machine","boot2docker","nginx"],"title":"[筆記] docker 1.8.2 rc","uri":"/posts/docker-notebook-1/"},{"categories":null,"content":"在 Mac os x 開發 docker，因為 Mac 無法原生支援 Docker，所以在 docker 1.7 以前的版上就必需透過 boot2docker，boot2docker 會在本機的 VirtualBox 上安裝一個虛擬機。Docker client 機乎是接近原生的狀態跑在 Mac 上，只不過 Docker 的 server 是跑在 boot2docker 的虛擬機中. picture: https://viget.com/extend/how-to-use-docker-on-os-x-the-missing-guide XD WARNING: The 'boot2docker' command line interface is officially deprecated. Please switch to Docker Machine (https://docs.docker.com/machine/) ASAP. Docker Toolbox (https://docker.com/toolbox) is the recommended install method. picture: https://docs.docker.com/installation/mac/#installation docker 社群開發的速度非常的快速，而 docker 1.8 之後就有了比較大的變化。安裝的工具也發生了變化， 多了 Docker Toolbox，官方的安裝步驟 for Mac 點我 安裝完了 Docker Toolbox 之後，可以直接在 Launchpad 上尋找 Docker Quickstart Terminal，執行之後終端機會進行 VirtualBox 初始化， 並建立 default 的虛擬機(在 1.7 版時則是利用 boot2docker 來建立虛擬機，並會在 VirtualBox 中建立一個名為 boot2docker-vm 的虛擬機)。 $ bash --login '/Applications/Docker/Docker Quickstart Terminal.app/Contents/Resources/Scripts/start.sh' Machine default already exists in VirtualBox. Starting machine default... Started machines may have new IP addresses. You may need to re-run the `docker-machine env` command. Setting environment variables for machine default... ## . ## ## ## == ## ## ## ## ## === /\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\\___/ === ~~~ {~~ ~~~~ ~~~ ~~~~ ~~~ ~ / ===- ~~~ \\______ o __/ \\ \\ __/ \\____\\_______/ docker is configured to use the default machine with IP 192.168.99.100 For help getting started, check out the docs at https://docs.docker.com 接著利用 docker-machine 來查詢目前那些 Docker host $ docker-machine ls NAME ACTIVE DRIVER STATE URL SWARM default * virtualbox Running tcp://192.168.99.100:2376 dev virtualbox Stopped ","date":"2015-10-04","objectID":"/posts/docker-notebook-1/:0:0","tags":["docker","docker-machine","boot2docker","nginx"],"title":"[筆記] docker 1.8.2 rc","uri":"/posts/docker-notebook-1/"},{"categories":null,"content":"Simple Demo 接下來利用簡單的步驟來試範在 Docker 上跑一個 Nginx 並透過設定對外開放 port 讓外部可以直接存取到 Nginx 的頁面 # 確認 docker-machine env 狀態 (我們以預設的 Docker host - default) $ docker-machine env default # 必要時重置一下 shell 環境 # eval \"$(docker-machine env default)\" # 建立資料夾 $ mkdir web \u0026\u0026 cd web # 執行一個 container # -d daemon: 設定 container 跑在背景執行 # -p expose port: 設定 container 的 port 與 docker host 的 port mapping, Nginx 預設 port 為 80 # --name 指定一個名子給 container $ docker run -d -p 80:80 --name web nginx $ docker ps CONTAINER ID IMAGE COMMAND CREATED STATUS PORTS NAMES e6644e903590 nginx \"nginx -g 'daemon off\" 3 seconds ago Up 4 seconds 0.0.0.0:80-\u003e80/tcp, 443/tcp web # 訪問 Nginx $ curl http://$(docker-machine ip default):80 \u003c!DOCTYPE html\u003e \u003chtml\u003e \u003chead\u003e \u003ctitle\u003eWelcome to nginx!\u003c/title\u003e \u003cstyle\u003e body { width: 35em; margin: 0 auto; font-family: Tahoma, Verdana, Arial, sans-serif; } \u003c/style\u003e \u003c/head\u003e \u003cbody\u003e \u003ch1\u003eWelcome to nginx!\u003c/h1\u003e \u003cp\u003eIf you see this page, the nginx web server is successfully installed and working. Further configuration is required.\u003c/p\u003e \u003cp\u003eFor online documentation and support please refer to \u003ca href=\"http://nginx.org/\"\u003enginx.org\u003c/a\u003e.\u003cbr/\u003e Commercial support is available at \u003ca href=\"http://nginx.com/\"\u003enginx.com\u003c/a\u003e.\u003c/p\u003e \u003cp\u003e\u003cem\u003eThank you for using nginx.\u003c/em\u003e\u003c/p\u003e \u003c/body\u003e \u003c/html\u003e ","date":"2015-10-04","objectID":"/posts/docker-notebook-1/:1:0","tags":["docker","docker-machine","boot2docker","nginx"],"title":"[筆記] docker 1.8.2 rc","uri":"/posts/docker-notebook-1/"},{"categories":null,"content":"Tips $ docker info Get http:///var/run/docker.sock/v1.20/info: dial unix /var/run/docker.sock: no such file or directory. * Are you trying to connect to a TLS-enabled daemon without TLS? * Is your docker daemon up and running? 如果遇到這個問題，只有重置一下 docker-machine 即可，Docker 還很貼心的告訴你如何重置 shell eval \"$(docker-machine env default)\" $ docker-machine env default export DOCKER_TLS_VERIFY=\"1\" export DOCKER_HOST=\"tcp://192.168.99.100:2376\" export DOCKER_CERT_PATH=\"/Users/cage/.docker/machine/machines/default\" export DOCKER_MACHINE_NAME=\"default\" # Run this command to configure your shell: # eval \"$(docker-machine env default)\" 相關參考資料 Mac OS下的boot2docker | 最完整的Docker聖經 - Docker原理圖解及全環境安裝 在 Mac OS X 系统里使用 Docker - 品雪其寒 - 博客频道 - CSDN.NET Installation on Mac OS X ","date":"2015-10-04","objectID":"/posts/docker-notebook-1/:2:0","tags":["docker","docker-machine","boot2docker","nginx"],"title":"[筆記] docker 1.8.2 rc","uri":"/posts/docker-notebook-1/"},{"categories":null,"content":"開發 App Engine，開發者雖然只要專注於 Data 及 Application 即可，但是也因為為享有諸多的服務而有所限制(目前只有支援 4 種程式語言 Golang, Python, Java, PHP、在 sandbox 中無法寫入檔案等限制)，而 Managed VMs 中引進了 docker 的元素讓 App Engine 有了更多的彈性。如: 可以進行檔案讀寫、自定 Runtime。","date":"2015-09-30","objectID":"/posts/managed-vms-lab/","tags":["Golang","GAE","Python","Managed-VMs"],"title":"Managed VMs lab","uri":"/posts/managed-vms-lab/"},{"categories":null,"content":"Presentation: slide: GAE Managed VM Introduction - Google Slides source code: cage1016/managed-vms-lab ","date":"2015-09-30","objectID":"/posts/managed-vms-lab/:0:0","tags":["Golang","GAE","Python","Managed-VMs"],"title":"Managed VMs lab","uri":"/posts/managed-vms-lab/"},{"categories":null,"content":"GAE Overview Google App Engine 是 Google Cloud Platform 中一個 PasS (Platform as a service) 的服務. 在 Pass 的 GAE 中，開發者只需要專注於 Application 及 Data， 其於的 Runtime、Middleware、OS、Virtualization、Servers、Storage、Networking 則完全被 Google 控制管理。 GAE Architecture picture: https://cloud.google.com/solutions/architecture/webapp App Engine 目前提供的執行環境有 Python、Golang、Java及PHP 4 種程式語言。支援多版本應用程式實例(multiple version)， 且可以直接在 Console 介面中進行版本的切換，也支援流量分流來方便進行 A/B 測試。 App Engine 也整合了 Memcache 及 Tasks Queue 的服務。Memcache 是一種記憶體快取並可以共享在 App Engine 的實例中， 它可以有效的提高資料存取的速度(如帳號資料從 Datastore 讀取後放至 Memcache 一份)。 Tasks Queues 則提供了一種處理長時間請求的方式(600s)。而 App Engine 也內建了 load balancer。 ","date":"2015-09-30","objectID":"/posts/managed-vms-lab/:1:0","tags":["Golang","GAE","Python","Managed-VMs"],"title":"Managed VMs lab","uri":"/posts/managed-vms-lab/"},{"categories":null,"content":"Docker Overview Docker 是一種輕量的 container 技術，不同於 VM (Virtual Machine) 的地方是 Container 是在作業系統層面上實作虛擬化，直接使用本地主機的作業系統， 而傳統方式則是在硬體層面實作。 Virtualization vs. Docker picture: https://philipzheng.gitbooks.io/docker_practice/content/introduction/what.html Why Docker? 作為一種新興的虛擬化方式，Docker 跟傳統的虛擬化方式相比具有眾多的優勢。 首先，Docker 容器的啟動可以在秒級實作，這相比傳統的虛擬機方式要快得多。 其次，Docker 對系統資源的使用率很高，一台主機上可以同時執行數千個 Docker 容器。 容器除了執行其中應用外，基本不消耗額外的系統資源，使得應用的效能很高，同時系統資源消耗更少。傳統虛擬機方式執行 10 個不同的應用就要啟動 10 個虛擬機，而 Docker 只需要啟動 10 個隔離的應用即可。 具體說來，Docker 在以下幾個方面具有較大的優勢。 更快速的交付和部署 對開發和維運（DevOps）人員來說，最希望的就是一次建立或設定，可以在任意地方正常執行。 開發者可以使用一個標準的映像檔來建立一套開發容器，開發完成之後，維運人員可以直接使用這個容器來部署程式碼。 Docker 可以快速建立容器，快速迭代應用程式，並讓整個過程全程可見，使團隊中的其他成員更容易理解應用程式是如何建立和工作的。 Docker 容器很輕很快！容器的啟動時間是秒級的，大量地節約開發、測試、部署的時間。 更有效率的虛擬化 Docker 容器的執行不需要額外的虛擬化支援，它是核心層級的虛擬化，因此可以實作更高的效能和效率。 更輕鬆的遷移和擴展 Docker 容器幾乎可以在任意的平台上執行，包括實體機器、虛擬機、公有雲、私有雲、個人電腦、伺服器等。 這種兼容性可以讓使用者把一個應用程式從一個平台直接遷移到另外一個。 更簡單的管理 使用 Docker，只需要小小的修改，就可以替代以往大量的更新工作。所有的修改都以增量的方式被分發和更新，從而實作自動化並且有效率的管理。 擷錄於 為什麼要用 Docker | 《Docker —— 從入門到實踐 》正體中文版 ","date":"2015-09-30","objectID":"/posts/managed-vms-lab/:1:1","tags":["Golang","GAE","Python","Managed-VMs"],"title":"Managed VMs lab","uri":"/posts/managed-vms-lab/"},{"categories":null,"content":"Managed VMs App Engine + Docker = Managed VMs App Engine 是 Google 一個 PasS 的服務，完全受 Google 管理及控制，開發者只需要專注於 Data 及 Application 的發開。 Docker 則是一個新興的 container 技術，讓發開者可以更快速的交付和部署、更有效率的虛擬化、更輕鬆的遷移和擴展、更簡單的管理。 Why Managed VMs? 開發 App Engine，開發者雖然只要專注於 Data 及 Application 即可，但是也因為為享有諸多的服務而有所限制(目前只有支援 4 種程式語言 Golang, Python, Java, PHP、在 sandbox 中無法寫入檔案等限制) ，而 Managed VMs 中引進了 docker 的元素讓 App Engine 有了更多的彈性。如: 可以進行檔案讀寫、自定 Runtime。 在使用 Managed VMs 時與一般的 App Engine 應用程式無異，差異的部份是在 app.yaml 中多設置了 vm:true 的配置 golang, app.yaml # make sure to replace \"projectid\" below with the project ID configured in the Google Developer Console runtime: go api_version: go1 # The vm setting is what determines if we are using a sandbox or MVM vm: true module: module1 automatic_scaling: min_num_instances: 1 max_num_instances: 5 cool_down_period_sec: 60 cpu_utilization: target_utilization: 0.2 resources: cpu: .5 memory_gb: 1.3 handlers: - url: /.* script: _go_app 上述 app.yaml 除了啟用了 Managed VMs 也配置了自動擴展配置及給予特定的資源(cpu, memory) ","date":"2015-09-30","objectID":"/posts/managed-vms-lab/:2:0","tags":["Golang","GAE","Python","Managed-VMs"],"title":"Managed VMs lab","uri":"/posts/managed-vms-lab/"},{"categories":null,"content":"Demo source code: cage1016/managed-vms-lab Demo Architecture dispatch.yaml dispatch: - url: \"*/favicon.ico\" module: default # appengine sandbox - url: \"your-project-id.appspot.com/\" module: default # managed vms - url: \"*/module1/*\" module: module1 - url: \"*/*\" module: default 本次 demo lab 的架構為一個 sandbox runtime(default module) + managed VMs(module1) with automatic scaling. Route request 可以透過 dispatch.yaml 的設定進行重導[1] golang, file structure (same as python) ├── create_ab_test_instances.sh # ab test instances create shell ├── default # default module │ ├── app.yaml # default moduel app.yaml │ ├── dispatch.yaml # dispatch.yaml │ └── sandbox.go # default module web app code ├── local_run.sh # local run shell ├── module1 # module 1 module │ ├── Dockerfile # auto-gen by gcloud command │ ├── app.yaml # module1 module app.yaml │ └── module1.go # module1 module web app code ├── update_all.sh # app upload shell (default, module1) ","date":"2015-09-30","objectID":"/posts/managed-vms-lab/:3:0","tags":["Golang","GAE","Python","Managed-VMs"],"title":"Managed VMs lab","uri":"/posts/managed-vms-lab/"},{"categories":null,"content":"Run locally 本次 Demo 使用 Google Cloud SDK 0.9.79 # install Google cloud SDK $ curl https://sdk.cloud.google.com | bash # update components $ gcloud components update # clone repo $ git clone https://github.com/cage1016/managed-vms-lab 重新命名 *.yaml.exist –\u003e *.yaml */default/dispatch.yaml.exist –\u003e */default/dispatch.yaml */default/update_all.sh.exist –\u003e */defalt/update_all.sh *default/create_ab_test_instances.sh.exist –\u003e */default/create_ab_test_instances.sh # run locally $ cd golang (or cd python) # execute run bash $ sh local_run.sh ","date":"2015-09-30","objectID":"/posts/managed-vms-lab/:4:0","tags":["Golang","GAE","Python","Managed-VMs"],"title":"Managed VMs lab","uri":"/posts/managed-vms-lab/"},{"categories":null,"content":"Deploy to GAE 在發佈 demo 應用程式至 App Engine 時，需要先配置一些參數. Golang/Python 的配置方式都一樣。 在發佈應用程式至 App Engine 之前，確認你有先在 Google Developers Console 建立專案 設置專案 PROJECT_ID */default/dispatch.yaml */default/update_all.sh */create_ab_test_instances.sh $ sh update_all.sh 就會依序發佈 App Engine sandbox 及 Managed VMs 至 App Engine 訪問 default module: https://your-project-id.appspot.com/ module1: https://your-project-id.appspot.com/module1/ module1 route: https://your-project-id.appspot.com/module1/sayhi ","date":"2015-09-30","objectID":"/posts/managed-vms-lab/:5:0","tags":["Golang","GAE","Python","Managed-VMs"],"title":"Managed VMs lab","uri":"/posts/managed-vms-lab/"},{"categories":null,"content":"Apache ab test 在 module1 的 Managed VMs 中有設定 automatic scaling, 且在 cpu \u003e 0.2 下會自動進行 scaling # cd folder $ cd golang (or cd python) # create test instances $ sh create_ab_test_instances.sh # ssh 至 gce instances $ gcloud compute ssh your-project-id --zone=project-zone-name # gce instances setup $ sudo yum -y upgrade # install Apache ab tset $ yum provides /usr/bin/ab $ sudo yum install httpd-tools # test $ ab -n 10000 http://your-project-id.appspot.com/module1/ 在 Apache ab test 壓測 module1 的模組，就可以透過 $gcloud compute instances list --project=your-project-id 會自動 scale out ","date":"2015-09-30","objectID":"/posts/managed-vms-lab/:6:0","tags":["Golang","GAE","Python","Managed-VMs"],"title":"Managed VMs lab","uri":"/posts/managed-vms-lab/"},{"categories":null,"content":"Reference App Engine Module: App Engine Modules in Python App Engine Modules in Go ","date":"2015-09-30","objectID":"/posts/managed-vms-lab/:7:0","tags":["Golang","GAE","Python","Managed-VMs"],"title":"Managed VMs lab","uri":"/posts/managed-vms-lab/"},{"categories":null,"content":"Chrome extension - A simple and quick way to copy title and url with ease in chrome browser.","date":"2015-08-17","objectID":"/posts/copy-2-clipboard-with-ease/","tags":["chrome","extension"],"title":"copy 2 clipboard with ease","uri":"/posts/copy-2-clipboard-with-ease/"},{"categories":null,"content":"features ","date":"2015-08-17","objectID":"/posts/copy-2-clipboard-with-ease/:0:0","tags":["chrome","extension"],"title":"copy 2 clipboard with ease","uri":"/posts/copy-2-clipboard-with-ease/"},{"categories":null,"content":"There have four options: Copy title url pattern: copy title only copy title and url copy title and shorten url copy url only copy shorten url only ","date":"2015-08-17","objectID":"/posts/copy-2-clipboard-with-ease/:1:0","tags":["chrome","extension"],"title":"copy 2 clipboard with ease","uri":"/posts/copy-2-clipboard-with-ease/"},{"categories":null,"content":"Copy title, url pattern: the default copy patter is url (title), you can change whatever you want but keep url and title keyword. ","date":"2015-08-17","objectID":"/posts/copy-2-clipboard-with-ease/:2:0","tags":["chrome","extension"],"title":"copy 2 clipboard with ease","uri":"/posts/copy-2-clipboard-with-ease/"},{"categories":null,"content":"Change log 1.0.1 - pattern input problem and other bug fixed. 1.0.0 - add options settings sync via Google account between different chrome browser. Change UI themes from Bootstrap to semantic-ui. minors bug fixed. 0.0.110 - add copy link with name feature. 0.0.109 chrome shortcut support. Default extension is “Shift+Alt+C”. You can setup shortcut you want to enable fast copy one option of 5. 0.0.104 contextMenus support. the default copy patter is url (title), you can change whatever you want but keep url and title keyword. Snapshot copy 2 clipboard with ease browser action copy 2 clipboard with ease copy pattern option github cage1016/copy-2-clipboard-with-ease Chrome web store copy 2 clipboard with ease ","date":"2015-08-17","objectID":"/posts/copy-2-clipboard-with-ease/:3:0","tags":["chrome","extension"],"title":"copy 2 clipboard with ease","uri":"/posts/copy-2-clipboard-with-ease/"},{"categories":null,"content":"A simple sample for webpack + es6","date":"2015-08-14","objectID":"/posts/webpack-es6-demo/","tags":["webpack","es6"],"title":"webpack es6 demo","uri":"/posts/webpack-es6-demo/"},{"categories":null,"content":"最近在InfoQ 中看到一篇文章 成為一名優秀的Web前端開發者，裡面提到學習 ECMAScript 2015 這一個部份，又因為在 github 看到越來越多 Javascript 專案始用 ES6 Javascript這個語言，是有「標準規格」的，叫做ECMA-262，這個標準規格，是由ECMA International (European Computer Manufacturers Association International)這個標準組織所制定，所以也稱呼它為ECMAScript。這個規格涵蓋了所有Javascript的核心，是各種Javascript執行環境一定會有的東西。在此之上，瀏覽器內就會額外加入DOM等擴充，而像node.js這樣的伺服器端環境，也有他自己的擴充，不過核心的部份是大家都一樣的。（附帶一提，C#的標準規格也是ECMA制定的） 初探 ES6（1）Harmony 的黑歷史 by fillano | CodeData 2015 年的 ECMAScript 是一個顯著的更新。上一次版本 ES5 的標準是在 2009 年訂定的，AngularJS, Aurelia, ReactJS, Ionic 都是架構在 ES5 的基礎上， 不過 ReactJS 也開始支援了 ES6，身為一個前端的工程師也是時候開始學習了 ECMAScript 2015 (ES6) ES6 包含了很多的新特性，更詳細的說明請參照 Reference - ES6，本次的 Simple 只用到幾個 ES6 最基本用法 arrow classes enhanced object literals template strings destructuring default + rest + spread let + const iterators + for..of generators unicode modules module loaders map + set + weakmap + weakset proxies symbols subclassable built-ins promises math + number + string + object APIs binary and octal literals reflect api tail calls Setting Started # clone webpack-es6 repo $ git clone https://github.com/cage1016/webpack-es6-demo # install node package $ npm install # complie js $ npm run watch # open index.html $ open -a 'Google Chrome' index.html ","date":"2015-08-14","objectID":"/posts/webpack-es6-demo/:0:0","tags":["webpack","es6"],"title":"webpack es6 demo","uri":"/posts/webpack-es6-demo/"},{"categories":null,"content":"webpack 目前 Browser 還沒有全面支援 ES6，所以在使用時候就必需進行轉譯，這邊我們使用的是 shama/es6-loader 的轉譯器 webpack.config.js 進行 webpack.config.js 檔案的配置: 設置 webpack 進入點. ./app/entry.js 設置轉譯後檔案 bundle.js (最後需要在 index.html 中引用 bundle.js) 設置 babel-loader 模組來進行 ES6 的轉譯 var path = require('path'); var webpack = require('webpack'); module.exports = { entry: './app/entry.js', output: { path: __dirname, filename: 'bundle.js', }, module: { loaders: [{ test: path.join(__dirname, 'app'), loader: 'babel-loader', exclude: /node_modules/, }, ], }, plugins: [ // Avoid publishing files when compilation failed new webpack.NoErrorsPlugin(), ], stats: { // Nice colored output colors: true, }, // Create Sourcemaps for the bundle devtool: 'source-map', }; ","date":"2015-08-14","objectID":"/posts/webpack-es6-demo/:1:0","tags":["webpack","es6"],"title":"webpack es6 demo","uri":"/posts/webpack-es6-demo/"},{"categories":null,"content":"Polygon app/Polygon.js 在 app/Polygon.js 中使用到了 ES6 中三個新的特性: classes/inheritance/static module arrow strings class Polygon { constructor(points) { this.points = points; } getArea() { let area = 0; let j = this.points.length - 1; for (let i = 0; i \u003c this.points.length; i++) { area = area + (this.points[j][0] + this.points[i][0]) * (this.points[j][1] - this.points[i][1]); j = i; } return Math.abs(area / 2); } getPoints() { return this.points.map(n =\u003e `(${n[0]},${n[1]})`).join(','); } toString() { return `I am ${this.name}, area = ${this.getArea()}` } } class Rectangle extends Polygon { constructor(points) { super(points, 'Rectanger'); this.name = 'Rectanger' } } class Triangle extends Polygon { constructor(points) { super(points, 'Triangle'); this.name = 'Triangle'; } static create(points) { return new Triangle(points); } } export { Triangle, Polygon, Rectangle } ","date":"2015-08-14","objectID":"/posts/webpack-es6-demo/:2:0","tags":["webpack","es6"],"title":"webpack es6 demo","uri":"/posts/webpack-es6-demo/"},{"categories":null,"content":"Entry app/entry.js 在 app/entry.js 中使用到了 ES6 中新的特性: module 引用的方式 let (類似 ES5 中的 var，不過 let 會把 scope 區隔開來) import { Rectangle, Triangle } from './Polygon'; let r = new Rectangle([ [4, 4], [4, -4], [-4, -4], [-4, 4], ]); let t = Triangle.create([ [4, 6], [4, -4], [8, -4], ]) let body = document.querySelector('body'); body.innerHTML = [ r.toString(), r.getPoints(), t.toString(), t.getPoints(), ].join('\u003cbr/\u003e'); 最後在 Browser 中看到三結果 I am Rectanger, area = 64 (4,4),(4,-4),(-4,-4),(-4,4) I am Triangle, area = 20 (4,6),(4,-4),(8,-4) Reference ","date":"2015-08-14","objectID":"/posts/webpack-es6-demo/:3:0","tags":["webpack","es6"],"title":"webpack es6 demo","uri":"/posts/webpack-es6-demo/"},{"categories":null,"content":"ES6 ECMAScript 6入门 es6-guide - GitBook ES6 In Depth: An Introduction ✩ Mozilla Hacks – the Web developer blog Classes - JavaScript | MDN ","date":"2015-08-14","objectID":"/posts/webpack-es6-demo/:4:0","tags":["webpack","es6"],"title":"webpack es6 demo","uri":"/posts/webpack-es6-demo/"},{"categories":null,"content":"webpack tutorials/getting-started shama/es6-loader Babel · The compiler for writing next generation JavaScript ","date":"2015-08-14","objectID":"/posts/webpack-es6-demo/:5:0","tags":["webpack","es6"],"title":"webpack es6 demo","uri":"/posts/webpack-es6-demo/"},{"categories":null,"content":"最近的專案常常需要在 GAE - Python 跟大 CSV (40MB)檔打交道。在 Python 中利用 `csv.reader` \u0026 `csv.DictReader` 可以很容易的處理 `csv` 讀取的動作。但是在 GAE 平台上一般 Request 時間只有 **60s**，而 Tasks Request 則有 **10mins** 的限制[3]，而在 GAE 上處理超大檔案的時候除了會遇到 `DeadlineExceededErrors` 的雷也會踩到 `Exceeded soft private memory limit` 的問題(預設 instance 的記憶體只有 **128MB**，在處理大 CSV 檔很容易踩到的雷)","date":"2015-07-28","objectID":"/posts/gcsiterator/","tags":["GCS","GAE","csv","Python"],"title":"GCSIterator (Python CSV iterator for Google Cloud Storage) via GAE","uri":"/posts/gcsiterator/"},{"categories":null,"content":"最近的專案常常需要在 GAE - Python 跟大 CSV (40MB)檔打交道。在 Python 中利用 csv.reader \u0026 csv.DictReader 可以很容易的處理 csv 讀取的動作。但是在 GAE 平台上一般 Request 時間只有 60s，而 Tasks Request 則有 10mins 的限制[3]，而在 GAE 上處理超大檔案的時候除了會遇到 DeadlineExceededErrors 的雷也會踩到 Exceeded soft private memory limit 的問題(預設 instance 的記憶體只有 128MB，在處理大 CSV 檔很容易踩到的雷) 所以在處理大 CSV 檔最好不要一次就把所有的資料讀到記憶體中，而 GAE 上又有檔案存取的限制，所以大部份會搭配 GCS 一起使用， 把檔案放在 GCS 上，由 GAE 透過 google-api-python-client 到 GCS 進行檔案的存取 google-api-python-client 中實作了 GCS JSON API 的 chunks 下載(MediaIoBaseDownload [4])，在 chunks 下載時就必需另外處理斷行的問題(實作 Python csv.DictReader iterator 內解決斷行問題) ","date":"2015-07-28","objectID":"/posts/gcsiterator/:0:0","tags":["GCS","GAE","csv","Python"],"title":"GCSIterator (Python CSV iterator for Google Cloud Storage) via GAE","uri":"/posts/gcsiterator/"},{"categories":null,"content":"GCSIterator.py # GCSIterator.py import random import re import logging import time from apiclient.errors import HttpError DEFAULT_CHUNK_SIZE = 512 * 1024 class GCSIterator(object): \"\"\" Reference: Parsing Large CSV Blobs on Google App Engine by Daniel Thompson @ d4nt http://d4nt.com/parsing-large-csv-blobs-on-google-app-engine Implement Google Cloud Storage csv.DictReader Iterator \"\"\" def __init__(self, request, progress=0, chunksize=DEFAULT_CHUNK_SIZE): self._request = request self._uri = request.uri self._chunksize = chunksize self._progress = progress self._init_progress = progress self._total_size = None self._done = False self._last_line = \"\" self._line_num = 0 self._lines = [] self._buffer = None self._done = False self._done_and_last_line = False self._bytes_read = 0 # Stubs for testing. self._sleep = time.sleep self._rand = random.random def __iter__(self): return self def next(self): if (not self._buffer or len(self._lines) == (self._line_num + 1)) and not self._done_and_last_line: if self._lines: self._last_line = self._lines[self._line_num] if not self._done: self._buffer, self._done = self.read(3) else: self._buffer = '' self._lines = re.split('\\r|\\n|\\r\\n', self._buffer) self._line_num = 0 # Handle special case where our block just happens to end on a new line if self._buffer[-1:] == \"\\n\" or self._buffer[-1:] == \"\\r\": self._lines.append(\"\") if not self._buffer: if self._done and not self._last_line: raise StopIteration else: self._done_and_last_line = True if self._line_num == 0 and len(self._last_line) \u003e 0: # print 'fixing' result = self._last_line + self._lines[self._line_num] + \"\\n\" else: result = self._lines[self._line_num] + \"\\n\" # check csv header if self._bytes_read == 0 and self._init_progress == 0: # if not re.match('email', result.lower().replace('\"', '')): # raise ValueError('csv header must contain \"email or EMAIL\" property.') # # else: result = result.lower() self._bytes_read += len(result) if not self._done_and_last_line: self._line_num += 1 else: self._last_line = '' return result def read(self, num_retries=0): \"\"\"Get the next chunk of the download. Args: num_retries: Integer, number of times to retry 500's with randomized exponential backoff. If all retries fail, the raised HttpError represents the last request. If zero (default), we attempt the request only once. Returns: (status, done): (MediaDownloadStatus, boolean) The value of 'done' will be True when the media has been fully downloaded. Raises: apiclient.errors.HttpError if the response was not a 2xx. httplib2.HttpLib2Error if a transport error has occured. \"\"\" try: headers = { 'range': 'bytes=%d-%d' % ( self._progress, self._progress + self._chunksize) } http = self._request.http msg = 'read bytes={:d}-{:d}/{}'.format(self._progress, (self._progress + self._chunksize), str(self._total_size) if self._total_size else '*') logging.info(msg) print msg for retry_num in xrange(num_retries + 1): if retry_num \u003e 0: self._sleep(self._rand() * 2 ** retry_num) logging.warning( 'Retry #%d for media download: GET %s, following status: %d' % (retry_num, self._uri, resp.status)) resp, content = http.request(self._uri, headers=headers) if resp.status \u003c 500: break if resp.status in [200, 206]: if 'content-location' in resp and resp['content-location'] != self._uri: self._uri = resp['content-location'] self._progress += len(content) if 'content-range' in resp: content_range = resp['content-range'] length = content_range.rsplit('/', 1)[1] self._total_size = int(length) if self._progress == self._total_size: self._done = True return content, self._done else: raise HttpError(resp, content, uri=self._uri) except Exception as e: logging.warning('gcs iterator error manual retry') logging.error(e.message) self._sleep(self._rand() * 2 ** 2) self.read() 在 GCSIterator.py 中把 GCS JSON API 的 chunks 下載 csv 資料的程式碼植入 iterator 並解決斷行的問題。 ","date":"2015-07-28","objectID":"/posts/gcsiterator/:1:0","tags":["GCS","GAE","csv","Python"],"title":"GCSIterator (Python CSV iterator for Google Cloud Storage) via GAE","uri":"/posts/gcsiterator/"},{"categories":null,"content":"Getting Started # Get gcloud $ curl https://sdk.cloud.google.com | bash # Get App Engine component $ gcloud components update app $ gcloud components update gae-python # Clone repo from github $ git clone https://github.com/cage1016/GCSIterator # Install pip packages $ sudo pip install -r requirements.txt -t lib Replace your bucket-name and object-name. You may also modify chunksize at line 24 in main.py file. # main.py ... def get_authenticated_service(): credentials = GoogleCredentials.get_application_default() http = credentials.authorize(httplib2.Http()) return discovery_build('storage', 'v1', http=http) gcs_service = get_authenticated_service() bucket_name = '\u003cyour-bucket-name\u003e' # waldo-gcp-file object_name = '\u003cyour-object-name\u003e' # kaichu_1016_00000100.csv request = gcs_service.objects().get_media(bucket=bucket_name, object=object_name.encode('utf8')) iterator = GCSIterator(request, chunksize=512) reader = csv.DictReader(iterator, skipinitialspace=True, delimiter=',') for row in reader: print row Execute main.py # sample output $ python main.py read bytes=0-512/* {'email': 'kaichu_1016+00000000@gmail.com', 'name': 'cage00000000'} {'email': 'kaichu_1016+00000001@gmail.com', 'name': 'cage00000001'} {'email': 'kaichu_1016+00000002@gmail.com', 'name': 'cage00000002'} {'email': 'kaichu_1016+00000003@gmail.com', 'name': 'cage00000003'} {'email': 'kaichu_1016+00000004@gmail.com', 'name': 'cage00000004'} {'email': 'kaichu_1016+00000005@gmail.com', 'name': 'cage00000005'} {'email': 'kaichu_1016+00000006@gmail.com', 'name': 'cage00000006'} {'email': 'kaichu_1016+00000007@gmail.com', 'name': 'cage00000007'} {'email': 'kaichu_1016+00000008@gmail.com', 'name': 'cage00000008'} {'email': 'kaichu_1016+00000009@gmail.com', 'name': 'cage00000009'} {'email': 'kaichu_1016+00000010@gmail.com', 'name': 'cage00000010'} read bytes=513-1025/4411 {'email': 'kaichu_1016+00000011@gmail.com', 'name': 'cage00000011'} {'email': 'kaichu_1016+00000012@gmail.com', 'name': 'cage00000012'} {'email': 'kaichu_1016+00000013@gmail.com', 'name': 'cage00000013'} {'email': 'kaichu_1016+00000014@gmail.com', 'name': 'cage00000014'} {'email': 'kaichu_1016+00000015@gmail.com', 'name': 'cage00000015'} {'email': 'kaichu_1016+00000016@gmail.com', 'name': 'cage00000016'} {'email': 'kaichu_1016+00000017@gmail.com', 'name': 'cage00000017'} {'email': 'kaichu_1016+00000018@gmail.com', 'name': 'cage00000018'} {'email': 'kaichu_1016+00000019@gmail.com', 'name': 'cage00000019'} {'email': 'kaichu_1016+00000020@gmail.com', 'name': 'cage00000020'} {'email': 'kaichu_1016+00000021@gmail.com', 'name': 'cage00000021'} {'email': 'kaichu_1016+00000022@gmail.com', 'name': 'cage00000022'} read bytes=1026-1538/4411 {'email': 'kaichu_1016+00000023@gmail.com', 'name': 'cage00000023'} {'email': 'kaichu_1016+00000024@gmail.com', 'name': 'cage00000024'} ... ","date":"2015-07-28","objectID":"/posts/gcsiterator/:2:0","tags":["GCS","GAE","csv","Python"],"title":"GCSIterator (Python CSV iterator for Google Cloud Storage) via GAE","uri":"/posts/gcsiterator/"},{"categories":null,"content":"Reference GAE - Python 13.1. csv — CSV File Reading and Writing — Python 2.7.10 documentation Dealing with DeadlineExceededErrors - App Engine — Google Cloud Platform google-api-python-client/http.py at 80da1eff23d7dc02d9f66f82754aa86b55f73be6 · google/google-api-python-client cage1016/GCSIterator ","date":"2015-07-28","objectID":"/posts/gcsiterator/:3:0","tags":["GCS","GAE","csv","Python"],"title":"GCSIterator (Python CSV iterator for Google Cloud Storage) via GAE","uri":"/posts/gcsiterator/"},{"categories":null,"content":"最近需要幫內部基於 GAE - Python 平台上導入前端的框架，TodoMVC 是一個非常適合拿來學習前端框架的資源，它以**TodoMVC**的題目實作目前主流的前端框架(**React**、**Angular**、**Vuejs**、**Ember.js**、**Polymer** 等等)，你可以看到不同框架的優缺點，選擇一個最適合你的框架來學習。","date":"2015-07-27","objectID":"/posts/gae-todomvc/","tags":["Front-end","GAE","todomvc"],"title":"GAE-todomvc","uri":"/posts/gae-todomvc/"},{"categories":null,"content":"最近需要幫內部基於GAE - Python平台上導入前端的框架，TodoMVC 是一個非常適合拿來學習前端框架的資源，它以TodoMVC的題目實作目前主流的前端框架(React、Angular、Vuejs、Ember.js、Polymer 等等)， 你可以看到不同框架的優缺點，選擇一個最適合你的框架來學習。 在 cage1016/gae-todomvc 中則選用了 Reactjs (Flux)、AnguarJs、Vue.js 三個前端框架來搭配 GAE-Python + Datastore + Endpoints APIs。 ","date":"2015-07-27","objectID":"/posts/gae-todomvc/:0:0","tags":["Front-end","GAE","todomvc"],"title":"GAE-todomvc","uri":"/posts/gae-todomvc/"},{"categories":null,"content":"Spec Front-end: Reactjs (Flux)、AnguarJs、Vue.js back-end: GAE-Python (webapp2) + Datastore +　Endpoints APIs ","date":"2015-07-27","objectID":"/posts/gae-todomvc/:0:1","tags":["Front-end","GAE","todomvc"],"title":"GAE-todomvc","uri":"/posts/gae-todomvc/"},{"categories":null,"content":"Getting Started 三個前端框架的程式碼都是基於 TodoMVC 版本 clone 後稍作修改 (以符合 Endpoints RESTFul APIs) todomvc/examples/angularjs-perf at gh-pages · tastejs/todomvc flux/examples/flux-todomvc at master · facebook/flux todomvc/examples/vue at gh-pages · tastejs/todomvc GAE todomvc 的 gcloud SDK 為 0.9.64 # Get gcloud $ curl https://sdk.cloud.google.com | bash # Get App Engine component $ gcloud components update app $ gcloud components update gae-python # Clone repo from github $ git clone https://github.com/cage1016/gae-todomvc # Install pip packages $ sudo pip install -r requirements.txt -t lib # Install npm packages $ npm install # Install bower packages $ bower install GAE todomvc 中 Vue.js 範例中使用到了 vue-resource library，因為 vue-resource 模組預設沒有 update: {method: 'put'} method，所以在執行 gulp 時，需自己稍作修改。 # switch to bower_components $ cd bower_components # clone vue-resource repo from github $ git clone https://github.com/vuejs/vue-resource # switch to vue-resource folder $ cd vue-resource # install vue-resource require packages $ npm install # add update method # /bower_components/vue-resource/src/resource.js # add \"update: {method: 'put'}\" at line 109 # rebuild vue-resource $ npm run build # go back $ cd ../.. # Build $ gulp # Run GAE locally $ dev_appserver.py app.yaml 瀏覽 http://localhost:8080 即可以看到結果。 ","date":"2015-07-27","objectID":"/posts/gae-todomvc/:0:2","tags":["Front-end","GAE","todomvc"],"title":"GAE-todomvc","uri":"/posts/gae-todomvc/"},{"categories":null,"content":"Screencapture ","date":"2015-07-27","objectID":"/posts/gae-todomvc/:0:3","tags":["Front-end","GAE","todomvc"],"title":"GAE-todomvc","uri":"/posts/gae-todomvc/"},{"categories":null,"content":"GAE Endpoints APIs GAE Endpoints APIs 詳細的使用方式可以參考 Creating an Endpoints API， GAE-todomvc 則是使用 GoogleCloudPlatform/endpoints-proto-datastore 來直接存取 Datastore 的 Model。另外 GAE Endpoints APIs 也提供了本地開發測試的Url http://localhost:8080/_ah/api/explorer ","date":"2015-07-27","objectID":"/posts/gae-todomvc/:0:4","tags":["Front-end","GAE","todomvc"],"title":"GAE-todomvc","uri":"/posts/gae-todomvc/"},{"categories":null,"content":"Reference TodoMVC Web Starter Kit — Web Fundamentals [React] 資源整理 « Huli’s Blog React \u0026 Flux Workshop Reactjs-JQuery-Vuejs-Extjs-Angularjs对比 - 【当耐特】 - 博客园 深入浅出React（一）：React的设计哲学 - 简单之美 深入浅出React（二）：React开发神器Webpack ","date":"2015-07-27","objectID":"/posts/gae-todomvc/:0:5","tags":["Front-end","GAE","todomvc"],"title":"GAE-todomvc","uri":"/posts/gae-todomvc/"},{"categories":null,"content":"今天 Google 公佈了 Application Default Credentials (ADC), 一個可以讓使用者更方便在 GCP 上去界接其他的需要使用 OAuth 存取的服務","date":"2015-07-21","objectID":"/posts/adc/","tags":["APIs","GCP","ADC","GAE"],"title":"Google Announce Application Default Credentials (ADC)","uri":"/posts/adc/"},{"categories":null,"content":"今天 Google 公佈了 Application Default Credentials (ADC)，一個可以讓使用者更方便在 GCP 上去界接其他的需要使用 OAuth 存取的服務如 Google Cloud Storage、Google BigQuery。這對常常寫 GAE 的我來說又更方便了。 在 GCP 專案建立之後，預設會自動產生 Service Accounts， 這些內建的 Service Accounts 在進行 Server to Server 的存取時只需要應用程式本身的認証，直接使用 AppAssertionCredentials 可以不需透過 Flow 來建立 Credentials物件 import httplib2 from google.appengine.api import memcache from apiclient.discovery import build from oauth2client.appengine import AppAssertionCredentials credentials = AppAssertionCredentials(scope='https://www.googleapis.com/auth/devstorage.full_control') http = credentials.authorize(httplib2.Http(memcache)) gcs_service = build('storage', 'v1', http=http, developerKey=DEVELOPER_KEY) 我們可以直接使用 AppAssertionCredentials 產生的 credentials 來建立 gcs_service 連線，這段程式在上傳到 GAE 上可以跑的很好， 不過如果你想要在本地測試的時候就需要特別指定 Server Accounts 的 credentials ","date":"2015-07-21","objectID":"/posts/adc/:0:0","tags":["APIs","GCP","ADC","GAE"],"title":"Google Announce Application Default Credentials (ADC)","uri":"/posts/adc/"},{"categories":null,"content":"Service Accounts Create Service Account Click APIs \u0026 Auth \u003e credential. Click Click new Client ID. Choose Service Account. Key type : P12 Key Click Create Client ID P12.Key file will be downloaded. You have to convert p12 to pem cause PKCS12 format is not supported by the PyCrypto library. (openssl pkcs12 -in xxxxx.p12 -nodes -nocerts \u003e privatekey.pem) 在本地測試程式時還需將 --appidentity_email_address 及 --appidentity_private_key_path 帶到 dev_appserver.py 參數中。 如果沒有帶入這二個參數本地測試會得到 401 Unauthorized 的錯誤訊息，不過上傳到 GAE 因為會透過應用程式本身的認証所以不會出錯。 # gae run locally. dev_appserver.py yaml_or_war_path --appidentity_email_address=\u003cservice-account-email\u003e --appidentity_private_key_path=\u003cprivatekey.pem-path\u003e ","date":"2015-07-21","objectID":"/posts/adc/:1:0","tags":["APIs","GCP","ADC","GAE"],"title":"Google Announce Application Default Credentials (ADC)","uri":"/posts/adc/"},{"categories":null,"content":"Application Default Credentials (ADC) 而 Application Default Credentials 則提供了更簡便的作法 from oauth2client.client import GoogleCredentials from apiclient.discovery import build credentials = GoogleCredentials.get_application_default() gcs_service = build('storage', 'v1', credentials=credentials) Application Default Credentials (ADC) 的方式在本地測試時因為直接使用了 gcloud auth login 的 credentials，所以在開發上更方便更直覺。 注意事項: Google APIs Client Library for Python 中 1.3 以上才支援 default credentials $ gcloud -v 確認 Google Cloud SDK 版本在 0.9.51 以上，Google App Engine SDK 版本在 1.9.18 以上 ","date":"2015-07-21","objectID":"/posts/adc/:2:0","tags":["APIs","GCP","ADC","GAE"],"title":"Google Announce Application Default Credentials (ADC)","uri":"/posts/adc/"},{"categories":null,"content":"參考資料 Google Cloud Platform Blog: Easier Auth for Google Cloud APIs. Introducing the Application Default Credentials feature. Google Application Default Credentials | Google Identity Platform | Google Developers Using Google App Engine | API Client Library for Python | Google Developers ","date":"2015-07-21","objectID":"/posts/adc/:3:0","tags":["APIs","GCP","ADC","GAE"],"title":"Google Announce Application Default Credentials (ADC)","uri":"/posts/adc/"},{"categories":null,"content":"如在 Github Pages 建立 Hugo 靜態網站","date":"2015-07-12","objectID":"/posts/my-first-post/","tags":["hugo","github"],"title":"如在 Github Pages 建立 Hugo 靜態網站","uri":"/posts/my-first-post/"},{"categories":null,"content":"原由 颱風天那都不能去，只好繼續 Coding 人生、看看 Pocket 未讀的文章。不過也因此發現好幾個不錯的東西 Supercharging the Atom Editor for Go Development · marcio.io，最近也開始用 Atom 也開始學習 Golang 語言。這一篇作者說明了他自己的使用經驗。 使用Hugo搭建免费个人Blog · Ulric Qin 這一篇文章看到 Hugo，發現在他的 Blog 也是用 Hugo 架的 在 Ulric Quin 的文章中得知他自己的 Blog 是架在大陸的GitCafe，Hugo 可以直接發佈到 GitCafe \u0026 Github 的 Page 免費，當然是立刻自己動手玩一玩 在 Hosting on GitHub Pages 的說明文件中有如何把 Hugo 靜態網站佈署到 Github Pages 中。但因為 GitHub Pages 提供了二種不同形態的頁面 User or organization site \u0026 Project Site。其中個人主頁一個帳號只能有一個、而專案頁面則可以很多個。 所以在佈署 Hugo 靜態網站也因為對應到不同的型態的 Github Pages 而有所不同。 第一種方式是將 Hugo 靜態網站佈署到 Github Page Project Site 面頁中. 只需要在 github 上建立一個 repo，但是利用 git 中 subtree 的概念將 public 資料夾連結到 gh-pages 的分支上，git 操作過程較為繁鎖 Url 上的差異 # project site url http://github.com/\u003cyour-github-account\u003e/\u003chugo-project-name\u003e # github pages host url http://\u003cyour-github-account\u003e.github.io Project Site Step1 - 安裝 Hugo 並建立新專案 在安裝(詳細步驟請看這)好 Hugo 後，直接建立新的 Hugo 專案 # 建立 Hugo 新專案，-f 是指定 yaml 格式，預設為 toml:frontmatter format $ hugo new site hugo_blog -f yaml # change directory $ cd hugo_blog # git initialized $ git init $ echo .DS_Store \u003e\u003e .gitignore # add git remote repo $ git remote add origin git@github.com:\u003cyour-github-account\u003e/hugo_blog.git 檢視新專案資料架構 # \u003cproject-name\u003e file structure ├── archetypes ├── config.toml ├── content ├── data ├── layouts └── static Step2 - 安裝新的 Themes Hugo Themes repository 本來安裝 themes 可直接新建 themes 資料夾並使用 git clone \u003cthemes-url\u003e，不過此方法在後面 push 到 Github Pages 出，Github 會回報 The page build failed with the following error: The submodule themes/hyde was not properly initialized with a .gitmodules file. For more information, see \u003ehttps://help.github.com/articles/page-build-failed-missing-submodule. If you have any questions you can contact us by replying to this email. 所以這邊直接使用 git submodule 的方式來安裝 themes # add hugo themes to project as submodule # git submodule add \u003crepository\u003e [\u003cpath\u003e] $ git submodule add https://github.com/spf13/hyde themes/hyde Step3 - 編輯專案設定檔 baseurl : \"http://\u003cyour-github-account\u003e.github.com/hugo_blog\" languageCode : \"en-us\" title : \"My New Hugo Site\" # 新增 theme 的名稱 theme : 'hyde' ... Step4 - 新增新的文章 在 content/posts 建立 first-post.md # 會在專案 content/posts 下產生 first-post.md 檔案 # -f 使用 yaml 檔案格式 $ hugo new posts/first-post.md -f yaml 編輯 first-post.md --- date: 2015-07-16T23:01:57+08:00 title: first post --- This is my first post. Step5 - 預覽 此時就可以在 Local 執行， http://127.0.0.1:1313/hugo_blog/ # -w watch filesystem for changes and recreate as needed # -D include content marked as draft # Press Ctrl+C to stop $ hugo server -w 應該可以看到下面擷圖的樣式 Step6 - 發佈 Hugo 靜態網站至 Github Pages 接下來的動作是一連串的 git 操作，把 Hugo 產生的 public 資料夾推送至 Github Pages # remove, public folder will created later $ rm -rf public $ git add . $ git commit -m 'hugo project init' # push $ git push -u origin master # Create a new orphand branch (no commit history) named gh-pages $ git checkout --orphan gh-pages # Unstage all files # -rf themes/hyde $ git rm -rf --cached $(git ls-files) # Add and commit that file $ git add . $ git commit -m \"INIT: initial commit on gh-pages branch\" # Push to remote gh-pages branch $ git push origin gh-pages # Return to master branch $ git checkout master # Remove the public folder to make room for the gh-pages subtree $ rm -rf public # Add the gh-pages branch of the repository. It will look like a folder named public $ git subtree add --prefix=public git@github.com:\u003cyour-github-account\u003e/hugo_blog.git gh-pages --squash # Pull down the file we just committed. This helps avoid merge conflicts $ git subtree pull --prefix=public git@github.com:\u003cyour-github-account\u003e/hugo_blog.git gh-pages # Run hugo. Generated site will be placed in public directory (or omit -t ThemeName if you're not using a theme) $ hugo # Add everything $ git add -A # Commit and push to master $ git commit -m \"Updating site\" \u0026\u0026 git push origin master # Push the public subtree to the gh-pages branch $ git subtree push --prefix=public git@github.com:\u003cyour-github-account\u003e/hugo_blog.git gh-pages 這時候，訪問 http://your-github-account","date":"2015-07-12","objectID":"/posts/my-first-post/:0:1","tags":["hugo","github"],"title":"如在 Github Pages 建立 Hugo 靜態網站","uri":"/posts/my-first-post/"},{"categories":null,"content":"Organization site Github Pages 除了提供專案主頁(可以多個)之外，也提供了個人主頁(每一個 github 帳號只有一個)的方式。將 Hugo 靜態網站發佈到個人主頁的方式比發佈到專案主頁簡單 在個人主頁中 Github repo 必需取口 .github.io master 分支中的內容會被 Build 及發佈到你的 Github Page中 (專案主頁是利用 gh-pages 分支，這點不太一樣) Step1 - 建立 Hugo repos 建立 \u003cgithub-project\u003e-hugo repo (用來 host Hugo 的內容) 建立 \u003cyour-github-account\u003e.github.io repo (Hugo public 中靜態網頁的內容) Step2 - 建立 Hugo 新專案 $ hugo new site \u003cgithub-project\u003e-hugo -f yaml # change directory $ cd \u003cgithub-project\u003e-hugo # git initialized $ git init $ echo .DS_Store \u003e\u003e .gitignore # add git remote repo $ git remote add origin git@github.com:\u003cyour-github-account\u003e/\u003cgithub-project\u003e-hugo.git Step3 - 安裝 Themes $ git submodule add https://github.com/spf13/hyde themes/hyde Step4 - 編輯專案設定檔 baseurl: 'http://\u003cyour-github-account\u003e.github.com/' languageCode: 'en-us' title: 'My New Hugo Site' theme: 'hyde' ... Step5 - 新增文章 $ hugo new posts/first-post.md -f yaml --- date: 2015-07-19T17:32:25+08:00 title: first post --- This is my first hugo post Step6 - 預覽 此時就可以在 Local 執行， http://127.0.0.1:1313/hugo_blog/ # -w watch filesystem for changes and recreate as needed # -D include content marked as draft # Press Ctrl+C to stop $ hugo server -w Step7 - 移除 public # it will created by `hugo` command after we executed `deploy.sh` $ rm -rf public ","date":"2015-07-12","objectID":"/posts/my-first-post/:0:2","tags":["hugo","github"],"title":"如在 Github Pages 建立 Hugo 靜態網站","uri":"/posts/my-first-post/"},{"categories":null,"content":"Step8 - 新增 .github.io public as submodule $ git submodule add git@github.com:\u003cyour-github-account\u003e/\u003cyour-github-account\u003e.github.io.git public Step8 - 發佈 #deploy.sh #!/bin/bash echo -e \"\\033[0;32mDeploying updates to GitHub...\\033[0m\" # Build the project. hugo # if using a theme, replace by `hugo -t \u003cyourtheme\u003e` # Go To Public folder cd public # Add changes to git. git add -A # Commit changes. msg=\"rebuilding site `date`\" if [ $# -eq 1 ] then msg=\"$1\" fi git commit -m \"$msg\" # Push source and build repos. git push origin master # Come Back cd .. 執行發佈shell後，內容會被推送到 \u003cyour-github-account\u003e-hugo，而 public 會被推送到 \u003cyour-github-account\u003e.github.io $ deploy.sh 'your commit message' 待 Github Page 編譯發佈後，訪問 http://your-github-account.github.io 就會看到結果! ","date":"2015-07-12","objectID":"/posts/my-first-post/:1:0","tags":["hugo","github"],"title":"如在 Github Pages 建立 Hugo 靜態網站","uri":"/posts/my-first-post/"},{"categories":null,"content":"參考資料 快速搭建gohugo博客 · Mac Zealot - A.C Che Hosting on GitHub Pages GitHub Pages + GoDaddy — Medium ","date":"2015-07-12","objectID":"/posts/my-first-post/:1:1","tags":["hugo","github"],"title":"如在 Github Pages 建立 Hugo 靜態網站","uri":"/posts/my-first-post/"},{"categories":null,"content":"Facebook 許多人都有轉載一些文章，看到有些不錯的文章，會想保存到 Evernote 上，Evernote 提供了 Evernote Web Clipper - Chrome Web Store 及 Clearly - Chrome Web Store 可以方便使用直接把面頁的文章快速的存到自己的 Notebook 中。 life.com 是網友滿常轉載的一個媒體之一。不過後來發現 Life.com 把文章內容的選取及複製功能都關閉了。 查看原始碼發現文章內容被包在iframe中 \u003ciframe src=\"about:blank\" frameborder=\"0\" border=\"0\" cellspacing=\"0\" style=\"width: 600px; border: 0px; height: 4887px;\"\u003e \u003chtml\u003e \u003chead\u003e \u003cstyle type=\"text/css\"\u003e...\u003c/style\u003e \u003c/head\u003e \u003cbody\u003e .... \u003c/body\u003e \u003c/html\u003e \u003c/iframe\u003e ","date":"2015-07-05","objectID":"/posts/life-dot-com-text-copy/:0:0","tags":["chrome","extension"],"title":"Life.com text copy","uri":"/posts/life-dot-com-text-copy/"},{"categories":null,"content":"快速的解決方法 由於網頁本身有戴入 jQuery，所以在 Chrome 的 console 中直接執行 // enable iframe select and contextmenu feature. jQuery('iframe[src=\"about:blank\"]')[0].contentDocument.oncontextmenu = function(){return true;} jQuery('iframe[src=\"about:blank\"]')[0].contentDocument.onselectstart = function(){return true;} 以上的方法雖然可以解決選取及複製，不過 Evernote-web-clipper 及 Clearly 還是沒有讀取 iframe 中的內容。 ","date":"2015-07-05","objectID":"/posts/life-dot-com-text-copy/:0:1","tags":["chrome","extension"],"title":"Life.com text copy","uri":"/posts/life-dot-com-text-copy/"},{"categories":null,"content":"Chrome extension 解決方法 一勞永逸的方式就是透過程式把 iframe 中的內容 unwrap 出來 (Trick: 前提是 iframe 中 src=“about:blank”，iframe 有其他的限制)。 原來的 html \u003cdiv aricle-detail-main=\"\" class=\"aricle-detail-mainin\" id=\"mainContent\"\u003e \u003ciframe src=\"about:blank\" frameborder=\"0\" border=\"0\" cellspacing=\"0\" style=\"width: 600px; border: 0px; height: 4887px;\"\u003e \u003chtml\u003e \u003chead\u003e \u003cstyle type=\"text/css\"\u003e...\u003c/style\u003e \u003c/head\u003e \u003cbody\u003e .... \u003c/body\u003e \u003c/html\u003e \u003c/iframe\u003e \u003c/div\u003e unwrap 後的 html，iframe 中的 style 則寫到 head 中。 \u003cdiv aricle-detail-main=\"\" class=\"aricle-detail-mainin\" id=\"mainContent\"\u003e \u003cdiv id=\"life-dot-com-copy\"\u003e ...原來 iframe 中 body 的內容... \u003c/div\u003e \u003c/div\u003e 結果 Evernote-web-clipper 及 Clearly 都可以正常的讀到內容。 ","date":"2015-07-05","objectID":"/posts/life-dot-com-text-copy/:0:2","tags":["chrome","extension"],"title":"Life.com text copy","uri":"/posts/life-dot-com-text-copy/"},{"categories":null,"content":"Installing life.com text copy - Chrome Web Store ","date":"2015-07-05","objectID":"/posts/life-dot-com-text-copy/:0:3","tags":["chrome","extension"],"title":"Life.com text copy","uri":"/posts/life-dot-com-text-copy/"},{"categories":null,"content":"Contribute # Clone repo from github $ git clone https://github.com/cage1016/life.com-text-copy # Install npm package $ npm install # debug $ grunt debug # build extension $ grunt ","date":"2015-07-05","objectID":"/posts/life-dot-com-text-copy/:0:4","tags":["chrome","extension"],"title":"Life.com text copy","uri":"/posts/life-dot-com-text-copy/"}]